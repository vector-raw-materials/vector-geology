{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\nfrom pyvista import set_plot_theme\nset_plot_theme('document')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# Predicting P-Wave Velocity from Hyperspectral Data\n\nThis example demonstrates the prediction of P-Wave velocities from hyperspectral data using machine learning techniques. Hyperspectral data provides detailed information on rock mineralogy, which influences its petrophysical properties. This script aims to explore and quantify the relationship between spectral features and various petrophysical properties, specifically focusing on P-Wave velocity.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Importing Necessary Libraries\n\nFirst, we import the required Python packages. We use `dotenv` to manage environment variables, `numpy` and `sklearn` for numerical operations and machine learning, and custom packages `hklearn` and `hycore` for handling hyperspectral data and machine learning workflows.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from dotenv import dotenv_values\nimport numpy as np\nimport sklearn\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.neural_network import MLPRegressor\nfrom tqdm import tqdm\n\n# Custom packages for handling hyperspectral data\n# Note: As of January 2024, these packages are not publicly available. Please contact the author for more information.\nfrom vector_geology.Packages import hklearn\nfrom vector_geology.Packages import hycore"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Loading Data with `hycore.Shed`\n\nThe `hycore` package, which organizes hyperspectral data in a structure called Shed, is used here. A Shed makes it convenient to categorize and store hyperspectral data. We use HyLibraries (a data structure within `hylite` for storing spectral libraries) within a Shed to store the hyperspectral data. The corresponding P-Wave velocity measurements are stored as numpy arrays.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Load the train and test sheds\nconfig = dotenv_values()\npath_to_train = config.get(\"PATH_TO_HSI_TRAINING\")\npath_to_test = config.get(\"PATH_TO_HSI_TESTING\")\n\ntrain_shed = hycore.loadShed(path_to_train)\ntest_shed = hycore.loadShed(path_to_test)\n\n# Load the train and test spectral libraries and P-Wave velocities\ntrain_fx50 = train_shed.results.FX50Lib\ntrain_fenix = train_shed.results.FENIXLib\ntrain_lwir = train_shed.results.LWIRLib\ntrain_vp = train_shed.results.Vp\n\ntest_fx50 = test_shed.results.FX50Lib\ntest_fenix = test_shed.results.FENIXLib\ntest_lwir = test_shed.results.LWIRLib\ntest_vp = test_shed.results.Vp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Creating a `hklearn.Stack` Object\n\nThe `hklearn` package, designed to handle hyperspectral data, is used to organize spectral libraries into a structure called Stack. A Stack can manage multiple spectral libraries and integrate data from multiple sensors. We perform hull corrections on the spectra to enhance features of interest.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Create Stack objects and apply hull correction to the spectra\nhsi_train = hklearn.Stack(\n    names=['FENIX', 'FX50', 'LWIR'],\n    data=[train_fenix, train_fx50, train_lwir]).hc(\n    ranges={'FENIX': (450., 2500.), 'FX50': (10, -10), 'LWIR': (10, -10)},\n    hull={'FENIX': 'upper', 'FX50': 'lower', 'LWIR': 'lower'}\n)\n\nhsi_test = hklearn.Stack(\n    names=['FENIX', 'FX50', 'LWIR'],\n    data=[test_fenix, test_fx50, test_lwir]).hc(\n    ranges={'FENIX': (450., 2500.), 'FX50': (10, -10), 'LWIR': (10, -10)},\n    hull={'FENIX': 'upper', 'FX50': 'lower', 'LWIR': 'lower'}\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Scaling the Dependent Variable (Y)\n\nThe P-Wave velocities are scaled to facilitate the convergence of the loss function during model training. We use the `StandardScaler` from scikit-learn for this purpose.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Scale Y Variable (P-Wave velocity)\ny_scaler = sklearn.preprocessing.StandardScaler()\n_ = y_scaler.fit(train_vp[:, None])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Transforming the Independent Variable (X)\n\nHyperspectral data often contains a large number of bands, many of which might be redundant. We apply Principal Component Analysis (PCA) to extract the most significant components. A two-step PCA is performed to ensure that there isn't any inter-sensor correlation. The `Stack` object stores the PCA, which is also applied to the test set.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Apply PCA to the X variable (spectral data)\nPCA_X = hsi_train.fit_pca(n_components=10, normalise=True)\nhsi_test.set_transform(PCA_X)\n\n# Set the Y-Variable (P-Wave velocity)\nhsi_train.set_y(train_vp[:, None, None])\nhsi_test.set_y(test_vp[:, None, None])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Initializing and Training Models\n\nDifferent machine learning models are initialized and trained. In this example, we use a simple linear regression (`LinearRegression`) and a Multilayer Perceptron (`MLPRegressor`) from scikit-learn. A dictionary with the parameters for optimization is also initialized.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Initialize models\nmodels = dict(\n    Linear=LinearRegression(),\n    MLP=MLPRegressor(\n        hidden_layer_sizes=(180,),\n        max_iter=1000,\n        solver='sgd',\n        learning_rate='adaptive'\n    )\n)\n\n# Define parameter ranges for each model\nparams = dict(Linear={'fit_intercept': [True, False]},\n              MLP={\"alpha\": np.linspace(1e-4, 1e0)})\n\n# Train the models\nfor name, model in tqdm(models.items(), 'Fitting models', leave=True):\n    hsi_train.fit_model(name, model, xtransform=True, ytransform=y_scaler, grid_search_cv=params[name], n_jobs=-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Scoring and Evaluating Models\n\nFinally, the trained models are scored and evaluated. The `Stack.get_score_table()` method is used to display a table with the training, cross-validation, and test scores of the best-performing model.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Evaluate models and display score table\nhsi_train.get_score_table(hsi_test, y_test=None, style=True)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}