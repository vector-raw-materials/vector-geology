<!DOCTYPE html>

<html lang="en" data-content_root="../../">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Multiphysics property prediction from hyperspectral drill core data &#8212; Vector Geology 0.3.dev17+g93b9dad.d20241008 documentation</title>
    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=649a27d8" />
    <link rel="stylesheet" type="text/css" href="../../_static/alabaster.css?v=039e1c02" />
    <link rel="stylesheet" type="text/css" href="../../_static/graphviz.css?v=eafc0fe6" />
    <link rel="stylesheet" type="text/css" href="../../_static/style.css?v=0ca0a429" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery.css?v=61a4c737" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-binder.css?v=f4aeca0c" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-dataframe.css?v=2082cf3c" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-rendered-html.css?v=1277b6f3" />
    <link rel="stylesheet" type="text/css" href="../../_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css?v=0a3b3ea7" />
    <script src="../../_static/documentation_options.js?v=8b60b743"></script>
    <script src="../../_static/doctools.js?v=888ff710"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/design-tabs.js?v=36754332"></script>
    <link rel="icon" href="../../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Probabilistic Modeling" href="../04_probabilistic_modeling/index.html" />
    <link rel="prev" title="Predicting P-Wave Velocity from Hyperspectral Data" href="03_HSI_To_Petrophysics.html" />
   
  <link rel="stylesheet" href="../../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p><a class="reference internal" href="#sphx-glr-download-examples-03-forward-engines-04-vectorgeology-hytorch-py"><span class="std std-ref">Go to the end</span></a>
to download the full example code</p>
</div>
<section class="sphx-glr-example-title" id="multiphysics-property-prediction-from-hyperspectral-drill-core-data">
<span id="sphx-glr-examples-03-forward-engines-04-vectorgeology-hytorch-py"></span><h1>Multiphysics property prediction from hyperspectral drill core data<a class="headerlink" href="#multiphysics-property-prediction-from-hyperspectral-drill-core-data" title="Link to this heading">¶</a></h1>
<p>This notebook uses drill core data to train a model that predicts petrophysical properties from hyperspectral data.j</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">dotenv</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">from</span> <span class="nn">mpl_toolkits.axes_grid1.inset_locator</span> <span class="kn">import</span> <span class="n">inset_axes</span>
<span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">HDBSCAN</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">StratifiedShuffleSplit</span>
<span class="kn">from</span> <span class="nn">tqdm</span> <span class="kn">import</span> <span class="n">tqdm</span>

<span class="kn">import</span> <span class="nn">hklearn</span>
</pre></div>
</div>
<p>We have prepared a Stack object with the hyperspectral and petrophysical data integrated into it
Load the Stack</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">dotenv</span><span class="o">.</span><span class="n">load_dotenv</span><span class="p">()</span>
<span class="n">base_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s2">&quot;PATH_TO_HyTorch&quot;</span><span class="p">)</span>

<span class="n">S</span> <span class="o">=</span> <span class="n">hklearn</span><span class="o">.</span><span class="n">Stack</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">base_path</span><span class="si">}</span><span class="s2">/Training_Stack&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Python-dotenv could not parse statement starting at line 13
Python-dotenv could not parse statement starting at line 14
Python-dotenv could not parse statement starting at line 15
Python-dotenv could not parse statement starting at line 16
Python-dotenv could not parse statement starting at line 17
</pre></div>
</div>
<p>Get the spectra and properties (hklearn filters out the NaNs)</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">S</span><span class="o">.</span><span class="n">X</span><span class="p">()</span> <span class="c1"># Spectra</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">S</span><span class="o">.</span><span class="n">y</span><span class="p">()</span> <span class="c1"># Properties and their standard deviations</span>
</pre></div>
</div>
<p>Visualize a single spectrum</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">S</span><span class="o">.</span><span class="n">get_wavelengths</span><span class="p">(</span><span class="s2">&quot;SWIR&quot;</span><span class="p">)</span><span class="o">/</span><span class="mf">1e3</span><span class="p">,</span> <span class="n">S</span><span class="o">.</span><span class="n">X</span><span class="p">(</span><span class="s2">&quot;SWIR&quot;</span><span class="p">)[</span><span class="mi">550</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">S</span><span class="o">.</span><span class="n">get_wavelengths</span><span class="p">(</span><span class="s2">&quot;MWIR&quot;</span><span class="p">)</span><span class="o">/</span><span class="mf">1e3</span><span class="p">,</span> <span class="n">S</span><span class="o">.</span><span class="n">X</span><span class="p">(</span><span class="s2">&quot;MWIR&quot;</span><span class="p">)[</span><span class="mi">550</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">S</span><span class="o">.</span><span class="n">get_wavelengths</span><span class="p">(</span><span class="s2">&quot;LWIR&quot;</span><span class="p">)</span><span class="o">/</span><span class="mf">1e3</span><span class="p">,</span> <span class="n">S</span><span class="o">.</span><span class="n">X</span><span class="p">(</span><span class="s2">&quot;LWIR&quot;</span><span class="p">)[</span><span class="mi">550</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;Wavelength $(\mu m)$&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s2">&quot;VNIR-SWIR&quot;</span><span class="p">,</span> <span class="s2">&quot;MWIR&quot;</span><span class="p">,</span> <span class="s2">&quot;LWIR&quot;</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<img src="../../_images/sphx_glr_04_VectorGeology_HyTorch_001.png" srcset="../../_images/sphx_glr_04_VectorGeology_HyTorch_001.png" alt="04 VectorGeology HyTorch" class = "sphx-glr-single-img"/><section id="step-1-filtering">
<h2>Step 1: Filtering<a class="headerlink" href="#step-1-filtering" title="Link to this heading">¶</a></h2>
<p>We do two steps of filtering:
1. We use the standard deviations to eliminate points with lithological contacts.
2. We use HDBSCAN to generate clusters based on the PCA of the spectra, which eliminates ‘noisy’ spectra that aren’t spectrally abundant</p>
<p>High variance filtering
Remove the high variance points (Using the rolling standard deviations)</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">keep_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">logical_and</span><span class="p">(</span><span class="n">S</span><span class="o">.</span><span class="n">y</span><span class="p">()[:,</span> <span class="mi">4</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mi">5</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">logical_and</span><span class="p">(</span><span class="n">S</span><span class="o">.</span><span class="n">y</span><span class="p">()[:,</span> <span class="mi">5</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mf">5e-2</span><span class="p">,</span> <span class="n">S</span><span class="o">.</span><span class="n">y</span><span class="p">()[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mi">1000</span><span class="p">))</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">keep_idx</span><span class="p">]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">keep_idx</span><span class="p">,</span> <span class="p">:</span><span class="mi">4</span><span class="p">]</span>
</pre></div>
</div>
<p>Clustering
Fit a PCA</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">hylite.filter</span> <span class="kn">import</span> <span class="n">PCA</span>
<span class="n">pca</span><span class="p">,</span> <span class="n">loadings</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">bands</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>
<span class="n">pca</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">data</span><span class="o">/</span><span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">pca</span><span class="o">.</span><span class="n">data</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:]</span>

<span class="c1"># Init</span>
<span class="n">clustering</span> <span class="o">=</span> <span class="n">HDBSCAN</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>

<span class="c1"># Fit + Predict</span>
<span class="n">labels</span> <span class="o">=</span> <span class="n">clustering</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">c_</span><span class="p">[</span><span class="n">y</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="mf">1e-2</span><span class="p">,</span> <span class="n">pca</span><span class="o">.</span><span class="n">data</span><span class="p">])</span>
<span class="n">un_l</span><span class="p">,</span> <span class="n">un_cts</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">return_counts</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<p>Using <cite>matplotlib.pyplot</cite> to visualize the effect of the filtering and clustering</p>
<p>Plot the properties</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplot_mosaic</span><span class="p">([[</span><span class="s1">&#39;A)&#39;</span><span class="p">,</span> <span class="s1">&#39;B)&#39;</span><span class="p">,</span> <span class="s1">&#39;C)&#39;</span><span class="p">]],</span> <span class="n">layout</span><span class="o">=</span><span class="s1">&#39;constrained&#39;</span><span class="p">,</span> <span class="n">sharey</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">sharex</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>

<span class="c1"># Original Data</span>
<span class="n">label</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">axs</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
<span class="n">ax</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">axs</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>
<span class="n">m</span> <span class="o">=</span> <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">S</span><span class="o">.</span><span class="n">y</span><span class="p">()[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">S</span><span class="o">.</span><span class="n">y</span><span class="p">()[:,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">S</span><span class="o">.</span><span class="n">y</span><span class="p">()[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">/</span><span class="mf">1e3</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;Original Data&quot;</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span> <span class="o">+</span> <span class="sa">r</span><span class="s2">&quot;$(N = </span><span class="si">%d</span><span class="s2">)$&quot;</span> <span class="o">%</span> <span class="n">S</span><span class="o">.</span><span class="n">y</span><span class="p">()</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;Density $(g.cm^{-3})$&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">label</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">loc</span><span class="o">=</span><span class="s1">&#39;left&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="s1">&#39;medium&#39;</span><span class="p">)</span>
<span class="n">cbaxes</span> <span class="o">=</span> <span class="n">inset_axes</span><span class="p">(</span><span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">width</span><span class="o">=</span><span class="s2">&quot;3%&quot;</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="s2">&quot;37%&quot;</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">cbaxes</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span><span class="n">labelsize</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">cax</span><span class="o">=</span><span class="n">cbaxes</span><span class="p">,</span> <span class="n">mappable</span><span class="o">=</span><span class="n">m</span><span class="p">)</span>
<span class="n">cbaxes</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;Depths $(km)$&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>

<span class="c1"># Cleaned data</span>
<span class="n">m1</span> <span class="o">=</span> <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">y</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">y</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">y</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">s</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;cool&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;Cleaned Data&quot;</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span> <span class="o">+</span> <span class="sa">r</span><span class="s2">&quot;$(N = </span><span class="si">%d</span><span class="s2">)$&quot;</span> <span class="o">%</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;Slowness $(\mu s.m^{-1})$&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">label</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">loc</span><span class="o">=</span><span class="s1">&#39;left&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="s1">&#39;medium&#39;</span><span class="p">)</span>
<span class="n">cbaxes</span> <span class="o">=</span> <span class="n">inset_axes</span><span class="p">(</span><span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">width</span><span class="o">=</span><span class="s2">&quot;3%&quot;</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="s2">&quot;37%&quot;</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">cbaxes</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span><span class="n">labelsize</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">cax</span><span class="o">=</span><span class="n">cbaxes</span><span class="p">,</span> <span class="n">mappable</span><span class="o">=</span><span class="n">m1</span><span class="p">)</span>
<span class="n">cbaxes</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;$\gamma$ $(API)$&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>

<span class="c1"># Labeled data</span>
<span class="n">m2</span> <span class="o">=</span> <span class="n">ax</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">y</span><span class="p">[</span><span class="n">labels</span> <span class="o">&gt;=</span> <span class="mf">0.</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">labels</span> <span class="o">&gt;=</span> <span class="mf">0.</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">labels</span><span class="p">[</span><span class="n">labels</span> <span class="o">&gt;=</span> <span class="mf">0.</span><span class="p">],</span> <span class="n">s</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;turbo&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;Clustered Data&quot;</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span> <span class="o">+</span> <span class="sa">r</span><span class="s2">&quot;$(N = </span><span class="si">%d</span><span class="s2">, N_c = </span><span class="si">%d</span><span class="s2">)$&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">labels</span> <span class="o">&gt;=</span> <span class="mf">0.</span><span class="p">),</span> <span class="n">un_l</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">label</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">loc</span><span class="o">=</span><span class="s1">&#39;left&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="s1">&#39;medium&#39;</span><span class="p">)</span>
<span class="n">cbaxes</span> <span class="o">=</span> <span class="n">inset_axes</span><span class="p">(</span><span class="n">ax</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">width</span><span class="o">=</span><span class="s2">&quot;3%&quot;</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="s2">&quot;37%&quot;</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">cbaxes</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span><span class="n">labelsize</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">cax</span><span class="o">=</span><span class="n">cbaxes</span><span class="p">,</span> <span class="n">mappable</span><span class="o">=</span><span class="n">m2</span><span class="p">)</span>
<span class="n">cbaxes</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;Class&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<img src="../../_images/sphx_glr_04_VectorGeology_HyTorch_002.png" srcset="../../_images/sphx_glr_04_VectorGeology_HyTorch_002.png" alt="A), Original Data $(N = 4834)$, B), Cleaned Data $(N = 3620)$, C), Clustered Data $(N = 2945, N_c = 24)$" class = "sphx-glr-single-img"/></section>
<section id="step-2-extract-the-hyperspectral-data">
<h2>Step 2: Extract the hyperspectral data<a class="headerlink" href="#step-2-extract-the-hyperspectral-data" title="Link to this heading">¶</a></h2>
<p>Save the labeled data (Drop the NaNs)</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">fin_idx</span> <span class="o">=</span> <span class="n">labels</span> <span class="o">&gt;=</span> <span class="mf">0.</span>
<span class="c1"># Complete spectrum</span>
<span class="n">fin_X</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">S</span><span class="o">.</span><span class="n">X</span><span class="p">()[</span><span class="n">keep_idx</span><span class="p">][</span><span class="n">fin_idx</span><span class="p">]</span>
<span class="c1"># SWIR</span>
<span class="n">fin_swir</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">S</span><span class="o">.</span><span class="n">X</span><span class="p">(</span><span class="n">sensor</span><span class="o">=</span><span class="s2">&quot;SWIR&quot;</span><span class="p">)[</span><span class="n">keep_idx</span><span class="p">][</span><span class="n">fin_idx</span><span class="p">]</span>
<span class="c1"># MWIR</span>
<span class="n">fin_mwir</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">S</span><span class="o">.</span><span class="n">X</span><span class="p">(</span><span class="n">sensor</span><span class="o">=</span><span class="s2">&quot;MWIR&quot;</span><span class="p">)[</span><span class="n">keep_idx</span><span class="p">][</span><span class="n">fin_idx</span><span class="p">]</span>
<span class="c1"># LWIR</span>
<span class="n">fin_lwir</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">S</span><span class="o">.</span><span class="n">X</span><span class="p">(</span><span class="n">sensor</span><span class="o">=</span><span class="s2">&quot;LWIR&quot;</span><span class="p">)[</span><span class="n">keep_idx</span><span class="p">][</span><span class="n">fin_idx</span><span class="p">]</span>
<span class="c1"># Scale the properties to keep the order of magnitude the same</span>
<span class="n">fin_y</span> <span class="o">=</span> <span class="n">S</span><span class="o">.</span><span class="n">y</span><span class="p">()[</span><span class="n">keep_idx</span><span class="p">][</span><span class="n">fin_idx</span><span class="p">,</span> <span class="mi">1</span><span class="p">:</span><span class="mi">4</span><span class="p">]</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">1e-3</span><span class="p">,</span> <span class="mf">1e-1</span><span class="p">,</span> <span class="mf">1e-3</span><span class="p">])[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:]</span>
<span class="c1"># Labels</span>
<span class="n">fin_lbls</span> <span class="o">=</span> <span class="n">labels</span><span class="p">[</span><span class="n">fin_idx</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="step-3-define-a-shuffled-train-validation-split">
<h2>Step 3: Define a shuffled Train + Validation split<a class="headerlink" href="#step-3-define-a-shuffled-train-validation-split" title="Link to this heading">¶</a></h2>
<p>Use stratified shuffle splitting</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">n_splits</span> <span class="o">=</span> <span class="mi">6</span>
<span class="n">test_size</span> <span class="o">=</span> <span class="mf">0.25</span>
<span class="n">sss</span> <span class="o">=</span> <span class="n">StratifiedShuffleSplit</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="n">n_splits</span><span class="p">,</span>
                             <span class="n">test_size</span><span class="o">=</span><span class="n">test_size</span><span class="p">,</span>
                             <span class="n">random_state</span><span class="o">=</span><span class="mi">404</span><span class="p">)</span>

<span class="n">idxs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">fin_lbls</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">train_idxs</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">valid_idxs</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">train_idx</span><span class="p">,</span> <span class="n">valid_idx</span> <span class="ow">in</span> <span class="n">sss</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">idxs</span><span class="p">,</span> <span class="n">fin_lbls</span><span class="p">):</span>
    <span class="n">train_idxs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">train_idx</span><span class="p">)</span>
    <span class="n">valid_idxs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">valid_idx</span><span class="p">)</span>

<span class="c1"># Stack</span>
<span class="n">train_idxs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">(</span><span class="n">train_idxs</span><span class="p">)</span>
<span class="n">valid_idxs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">(</span><span class="n">valid_idxs</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="step-4-define-a-pytorch-model">
<h2>Step 4: Define a <cite>pytorch</cite> model<a class="headerlink" href="#step-4-define-a-pytorch-model" title="Link to this heading">¶</a></h2>
<p>Torch</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="nn">optim</span>
<span class="kn">from</span> <span class="nn">torcheval.metrics</span> <span class="kn">import</span> <span class="n">R2Score</span><span class="p">,</span> <span class="n">MeanSquaredError</span>
<span class="kn">import</span> <span class="nn">copy</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">Dataset</span><span class="p">,</span> <span class="n">DataLoader</span>

<span class="c1"># Classes</span>
<span class="c1"># Dataset</span>
<span class="k">class</span> <span class="nc">MultimodalDataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">swir</span><span class="p">,</span> <span class="n">mwir</span><span class="p">,</span> <span class="n">lwir</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">targets</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">swir</span> <span class="o">=</span> <span class="n">swir</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mwir</span> <span class="o">=</span> <span class="n">mwir</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lwir</span> <span class="o">=</span> <span class="n">lwir</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">labels</span> <span class="o">=</span> <span class="n">labels</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">targets</span> <span class="o">=</span> <span class="n">targets</span>

    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">targets</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">swir</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">mwir</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">lwir</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">targets</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>


<span class="k">class</span> <span class="nc">WeightedMSELoss</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">non_neg_penalty_weight</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">WeightedMSELoss</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">non_neg_penalty_weight</span> <span class="o">=</span> <span class="n">non_neg_penalty_weight</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">weights</span><span class="p">,</span> <span class="n">targets</span><span class="p">):</span>
        <span class="c1"># Calculate the MSE loss for each example in the batch</span>
        <span class="n">mse_loss</span> <span class="o">=</span> <span class="p">(</span><span class="n">inputs</span> <span class="o">-</span> <span class="n">targets</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span>
        <span class="c1"># Apply weights to the MSE loss</span>
        <span class="n">weighted_mse_loss</span> <span class="o">=</span> <span class="n">mse_loss</span> <span class="o">*</span> <span class="n">weights</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]</span>
        <span class="c1"># Calculate the mean loss</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">weighted_mse_loss</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

        <span class="c1"># Add non-negativity penalty</span>
        <span class="n">non_neg_penalty</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">non_neg_penalty_weight</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="o">-</span><span class="n">inputs</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">total_loss</span> <span class="o">=</span> <span class="n">loss</span> <span class="o">+</span> <span class="n">non_neg_penalty</span>

        <span class="k">return</span> <span class="n">total_loss</span>

<span class="k">class</span> <span class="nc">MultiHeadedMLP</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_sizes</span><span class="p">,</span> <span class="n">hidden_sizes</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">conv_kernel_size</span><span class="o">=</span><span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">conv_stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">conv_padding</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">MultiHeadedMLP</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="c1"># Calculate output sizes after convolution</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">swir_conv_output_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_calculate_conv_output_size</span><span class="p">(</span><span class="n">in_sizes</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">conv_kernel_size</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">conv_stride</span><span class="p">,</span> <span class="n">conv_padding</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mwir_conv_output_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_calculate_conv_output_size</span><span class="p">(</span><span class="n">in_sizes</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">conv_kernel_size</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">conv_stride</span><span class="p">,</span> <span class="n">conv_padding</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lwir_conv_output_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_calculate_conv_output_size</span><span class="p">(</span><span class="n">in_sizes</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">conv_kernel_size</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">conv_stride</span><span class="p">,</span> <span class="n">conv_padding</span><span class="p">)</span>

        <span class="c1"># Define separate input heads for each band type with a conv layer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">swir_head</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv1d</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="n">out_channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="n">conv_kernel_size</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">stride</span><span class="o">=</span><span class="n">conv_stride</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="n">conv_padding</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">swir_conv_output_size</span> <span class="o">*</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">hidden_sizes</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mwir_head</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv1d</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="n">out_channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="n">conv_kernel_size</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">stride</span><span class="o">=</span><span class="n">conv_stride</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="n">conv_padding</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mwir_conv_output_size</span> <span class="o">*</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">hidden_sizes</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lwir_head</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv1d</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="n">out_channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="n">conv_kernel_size</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">stride</span><span class="o">=</span><span class="n">conv_stride</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="n">conv_padding</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lwir_conv_output_size</span> <span class="o">*</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">hidden_sizes</span><span class="p">[</span><span class="mi">2</span><span class="p">]),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
        <span class="p">)</span>

        <span class="c1"># Define a shared hidden layer after combining the inputs</span>
        <span class="n">combined_input_size</span> <span class="o">=</span> <span class="n">hidden_sizes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">hidden_sizes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">hidden_sizes</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">shared_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">combined_input_size</span><span class="p">,</span> <span class="n">combined_input_size</span> <span class="o">*</span> <span class="mi">2</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">combined_input_size</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="n">combined_input_size</span> <span class="o">//</span> <span class="mi">2</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">combined_input_size</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">16</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="n">output_size</span><span class="p">),</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">_calculate_conv_output_size</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">input_size</span> <span class="o">-</span> <span class="n">kernel_size</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">padding</span><span class="p">)</span> <span class="o">//</span> <span class="n">stride</span> <span class="o">+</span> <span class="mi">1</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">swir</span><span class="p">,</span> <span class="n">mwir</span><span class="p">,</span> <span class="n">lwir</span><span class="p">):</span>
        <span class="c1"># Add channel dimension for conv layer</span>
        <span class="n">swir</span> <span class="o">=</span> <span class="n">swir</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">mwir</span> <span class="o">=</span> <span class="n">mwir</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">lwir</span> <span class="o">=</span> <span class="n">lwir</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

        <span class="n">swir_out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">swir_head</span><span class="p">(</span><span class="n">swir</span><span class="p">)</span>
        <span class="n">mwir_out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mwir_head</span><span class="p">(</span><span class="n">mwir</span><span class="p">)</span>
        <span class="n">lwir_out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lwir_head</span><span class="p">(</span><span class="n">lwir</span><span class="p">)</span>

        <span class="c1"># Concatenate the outputs from each head</span>
        <span class="n">combined</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">swir_out</span><span class="p">,</span> <span class="n">mwir_out</span><span class="p">,</span> <span class="n">lwir_out</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># Pass through the shared layer</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">shared_layer</span><span class="p">(</span><span class="n">combined</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">output</span>
</pre></div>
</div>
<p>Initialize the model and prepare for training</p>
<p>Make datasets</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">10</span>

<span class="c1"># Initialize a model</span>
<span class="n">hidden_sizes</span> <span class="o">=</span> <span class="p">[</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">]</span>
<span class="n">in_sizes</span> <span class="o">=</span> <span class="p">[</span><span class="n">S</span><span class="o">.</span><span class="n">X</span><span class="p">(</span><span class="n">sensor</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">sensor</span> <span class="ow">in</span> <span class="n">S</span><span class="o">.</span><span class="n">get_sensors</span><span class="p">()]</span>
<span class="n">output_size</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">conv_kernel_size</span> <span class="o">=</span> <span class="p">[</span><span class="mi">60</span><span class="p">,</span> <span class="mi">40</span><span class="p">,</span> <span class="mi">20</span><span class="p">]</span>
<span class="n">conv_stride</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">conv_padding</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">out_channels</span> <span class="o">=</span> <span class="mi">4</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">MultiHeadedMLP</span><span class="p">(</span><span class="n">in_sizes</span><span class="p">,</span> <span class="n">hidden_sizes</span><span class="p">,</span>
                       <span class="n">out_channels</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span>
                       <span class="n">conv_kernel_size</span><span class="p">,</span> <span class="n">conv_stride</span><span class="p">,</span>
                       <span class="n">conv_padding</span><span class="p">)</span>

<span class="c1"># Loss Function</span>
<span class="n">wt_loss_fn</span> <span class="o">=</span> <span class="n">WeightedMSELoss</span><span class="p">(</span><span class="n">non_neg_penalty_weight</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">loss_fn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span>
<span class="c1"># Optimizer</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">)</span>

<span class="c1"># Number of training epochs (Per fold)</span>
<span class="n">n_epochs</span> <span class="o">=</span> <span class="mi">100</span>

<span class="c1"># Initialize parameters</span>
<span class="n">best_mse</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span>
<span class="n">best_weights</span> <span class="o">=</span> <span class="kc">None</span>
<span class="n">train_history</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">history</span> <span class="o">=</span> <span class="p">[]</span>
</pre></div>
</div>
</section>
<section id="training">
<h2>Training<a class="headerlink" href="#training" title="Link to this heading">¶</a></h2>
<p>Begin Training</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_splits</span><span class="p">):</span>
    <span class="c1"># Fold training</span>
    <span class="n">train_idx</span> <span class="o">=</span> <span class="n">train_idxs</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>
    <span class="c1"># Fold Validation</span>
    <span class="n">valid_idx</span> <span class="o">=</span> <span class="n">valid_idxs</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>

    <span class="c1"># Get the separated datasets</span>
    <span class="c1"># Training</span>
    <span class="n">train_X</span><span class="p">,</span> <span class="n">train_swir</span><span class="p">,</span> <span class="n">train_mwir</span><span class="p">,</span> <span class="n">train_lwir</span><span class="p">,</span> <span class="n">train_y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">fin_X</span><span class="p">[</span><span class="n">train_idx</span><span class="p">]),</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">fin_swir</span><span class="p">[</span><span class="n">train_idx</span><span class="p">]),</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">fin_mwir</span><span class="p">[</span><span class="n">train_idx</span><span class="p">]),</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">fin_lwir</span><span class="p">[</span><span class="n">train_idx</span><span class="p">]),</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">fin_y</span><span class="p">[</span><span class="n">train_idx</span><span class="p">])</span>
    <span class="c1"># Validation</span>
    <span class="n">valid_X</span><span class="p">,</span> <span class="n">valid_swir</span><span class="p">,</span> <span class="n">valid_mwir</span><span class="p">,</span> <span class="n">valid_lwir</span><span class="p">,</span> <span class="n">valid_y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">fin_X</span><span class="p">[</span><span class="n">valid_idx</span><span class="p">]),</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">fin_swir</span><span class="p">[</span><span class="n">valid_idx</span><span class="p">]),</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">fin_mwir</span><span class="p">[</span><span class="n">valid_idx</span><span class="p">]),</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">fin_lwir</span><span class="p">[</span><span class="n">valid_idx</span><span class="p">]),</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">fin_y</span><span class="p">[</span><span class="n">valid_idx</span><span class="p">])</span>

    <span class="c1"># Compute the weights</span>
    <span class="n">fold_idxs</span> <span class="o">=</span> <span class="p">[</span><span class="n">train_idx</span><span class="p">,</span> <span class="n">valid_idx</span><span class="p">]</span>
    <span class="n">weights</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">):</span>
        <span class="c1"># Define the weights</span>
        <span class="n">lbls</span><span class="p">,</span> <span class="n">counts</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">fin_lbls</span><span class="p">[</span><span class="n">fold_idxs</span><span class="p">[</span><span class="n">i</span><span class="p">]],</span> <span class="n">return_counts</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">counts</span> <span class="o">=</span> <span class="mi">1</span><span class="o">/</span><span class="n">counts</span>
        <span class="n">class_weights</span> <span class="o">=</span> <span class="n">counts</span><span class="o">/</span><span class="n">counts</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
        <span class="c1"># Assign the weights</span>
        <span class="n">loss_weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">class_weights</span><span class="p">[</span><span class="n">fin_lbls</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="n">lbls</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">fin_lbls</span><span class="p">[</span><span class="n">fold_idxs</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])])</span>
        <span class="n">weights</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">loss_weights</span><span class="p">))</span>

    <span class="n">train_dataset</span> <span class="o">=</span> <span class="n">MultimodalDataset</span><span class="p">(</span><span class="n">train_swir</span><span class="p">,</span> <span class="n">train_mwir</span><span class="p">,</span> <span class="n">train_lwir</span><span class="p">,</span> <span class="n">weights</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">train_y</span><span class="p">)</span>
    <span class="n">train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="k">with</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">n_epochs</span><span class="p">),</span> <span class="n">unit</span><span class="o">=</span><span class="s2">&quot; epochs&quot;</span><span class="p">,</span> <span class="n">mininterval</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">disable</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="k">as</span> <span class="n">bar_</span><span class="p">:</span>
        <span class="n">bar_</span><span class="o">.</span><span class="n">set_description</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Training Fold </span><span class="si">{</span><span class="n">j</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="n">bar_</span><span class="p">:</span>
            <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>

            <span class="k">with</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">train_loader</span><span class="p">,</span> <span class="n">unit</span><span class="o">=</span><span class="s2">&quot;batch&quot;</span><span class="p">,</span> <span class="n">mininterval</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">disable</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="k">as</span> <span class="n">bar</span><span class="p">:</span>
                <span class="n">bar</span><span class="o">.</span><span class="n">set_description</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">batch_swir</span><span class="p">,</span> <span class="n">batch_mwir</span><span class="p">,</span> <span class="n">batch_lwir</span><span class="p">,</span> <span class="n">batch_weights</span><span class="p">,</span> <span class="n">y_batch</span> <span class="ow">in</span> <span class="n">bar</span><span class="p">:</span>

                    <span class="c1"># Forward pass</span>
                    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">batch_swir</span><span class="p">,</span> <span class="n">batch_mwir</span><span class="p">,</span> <span class="n">batch_lwir</span><span class="p">)</span>

                    <span class="c1"># Calculate Loss</span>
                    <span class="n">loss</span> <span class="o">=</span> <span class="n">wt_loss_fn</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">batch_weights</span><span class="p">,</span> <span class="n">y_batch</span><span class="p">)</span>

                    <span class="c1"># Backward pass</span>
                    <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
                    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

                    <span class="c1"># Update weights</span>
                    <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

            <span class="c1"># Log training loss for the epoch</span>
            <span class="n">train_pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">train_swir</span><span class="p">,</span> <span class="n">train_mwir</span><span class="p">,</span> <span class="n">train_lwir</span><span class="p">)</span>
            <span class="n">train_mse</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">train_pred</span><span class="p">,</span> <span class="n">train_y</span><span class="p">)</span>
            <span class="n">train_history</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">train_mse</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>

            <span class="c1"># Validation Loss</span>
            <span class="n">valid_pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">valid_swir</span><span class="p">,</span> <span class="n">valid_mwir</span><span class="p">,</span> <span class="n">valid_lwir</span><span class="p">)</span>
            <span class="n">mse</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">valid_pred</span><span class="p">,</span> <span class="n">valid_y</span><span class="p">)</span>
            <span class="n">history</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">mse</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>

            <span class="k">if</span> <span class="n">mse</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">&lt;</span> <span class="n">best_mse</span><span class="p">:</span>
                <span class="n">best_mse</span> <span class="o">=</span> <span class="n">mse</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
                <span class="n">best_weights</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">())</span>

            <span class="c1"># Print progress</span>
            <span class="n">bar_</span><span class="o">.</span><span class="n">set_postfix</span><span class="p">({</span><span class="s2">&quot;Training Loss&quot;</span> <span class="p">:</span> <span class="n">train_mse</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="s2">&quot;Validation Loss&quot;</span><span class="p">:</span> <span class="n">mse</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="s2">&quot;Best Loss&quot;</span><span class="p">:</span> <span class="n">best_mse</span><span class="p">})</span>

<span class="c1"># Restore model with best weights</span>
<span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">best_weights</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>  0%|          | 0/100 [00:00&lt;?, ? epochs/s]
Training Fold 1:   0%|          | 0/100 [00:00&lt;?, ? epochs/s]
Training Fold 1:   0%|          | 0/100 [00:01&lt;?, ? epochs/s, Training Loss=0.000802, Validation Loss=0.000815, Best Loss=0.000815]
Training Fold 1:   1%|          | 1/100 [00:01&lt;02:24,  1.46s/ epochs, Training Loss=0.000802, Validation Loss=0.000815, Best Loss=0.000815]
Training Fold 1:   1%|          | 1/100 [00:02&lt;02:24,  1.46s/ epochs, Training Loss=0.000271, Validation Loss=0.000268, Best Loss=0.000268]
Training Fold 1:   2%|▏         | 2/100 [00:02&lt;01:32,  1.05 epochs/s, Training Loss=0.000271, Validation Loss=0.000268, Best Loss=0.000268]
Training Fold 1:   2%|▏         | 2/100 [00:02&lt;01:32,  1.05 epochs/s, Training Loss=0.000143, Validation Loss=0.000136, Best Loss=0.000136]
Training Fold 1:   3%|▎         | 3/100 [00:02&lt;01:12,  1.34 epochs/s, Training Loss=0.000143, Validation Loss=0.000136, Best Loss=0.000136]
Training Fold 1:   3%|▎         | 3/100 [00:03&lt;01:12,  1.34 epochs/s, Training Loss=0.000147, Validation Loss=0.00014, Best Loss=0.000136]
Training Fold 1:   4%|▍         | 4/100 [00:03&lt;01:01,  1.55 epochs/s, Training Loss=0.000147, Validation Loss=0.00014, Best Loss=0.000136]
Training Fold 1:   4%|▍         | 4/100 [00:03&lt;01:01,  1.55 epochs/s, Training Loss=0.00011, Validation Loss=0.000107, Best Loss=0.000107]
Training Fold 1:   5%|▌         | 5/100 [00:03&lt;00:56,  1.68 epochs/s, Training Loss=0.00011, Validation Loss=0.000107, Best Loss=0.000107]
Training Fold 1:   5%|▌         | 5/100 [00:04&lt;00:56,  1.68 epochs/s, Training Loss=0.000105, Validation Loss=0.000101, Best Loss=0.000101]
Training Fold 1:   6%|▌         | 6/100 [00:04&lt;00:52,  1.80 epochs/s, Training Loss=0.000105, Validation Loss=0.000101, Best Loss=0.000101]
Training Fold 1:   6%|▌         | 6/100 [00:04&lt;00:52,  1.80 epochs/s, Training Loss=0.000109, Validation Loss=0.000104, Best Loss=0.000101]
Training Fold 1:   7%|▋         | 7/100 [00:04&lt;00:49,  1.89 epochs/s, Training Loss=0.000109, Validation Loss=0.000104, Best Loss=0.000101]
Training Fold 1:   7%|▋         | 7/100 [00:05&lt;00:49,  1.89 epochs/s, Training Loss=9.32e-5, Validation Loss=8.96e-5, Best Loss=8.96e-5]
Training Fold 1:   8%|▊         | 8/100 [00:05&lt;00:48,  1.89 epochs/s, Training Loss=9.32e-5, Validation Loss=8.96e-5, Best Loss=8.96e-5]
Training Fold 1:   8%|▊         | 8/100 [00:05&lt;00:48,  1.89 epochs/s, Training Loss=9.39e-5, Validation Loss=9.16e-5, Best Loss=8.96e-5]
Training Fold 1:   9%|▉         | 9/100 [00:05&lt;00:46,  1.95 epochs/s, Training Loss=9.39e-5, Validation Loss=9.16e-5, Best Loss=8.96e-5]
Training Fold 1:   9%|▉         | 9/100 [00:06&lt;00:46,  1.95 epochs/s, Training Loss=8.68e-5, Validation Loss=8.29e-5, Best Loss=8.29e-5]
Training Fold 1:  10%|█         | 10/100 [00:06&lt;00:45,  1.96 epochs/s, Training Loss=8.68e-5, Validation Loss=8.29e-5, Best Loss=8.29e-5]
Training Fold 1:  10%|█         | 10/100 [00:06&lt;00:45,  1.96 epochs/s, Training Loss=8.41e-5, Validation Loss=8.12e-5, Best Loss=8.12e-5]
Training Fold 1:  11%|█         | 11/100 [00:06&lt;00:44,  2.00 epochs/s, Training Loss=8.41e-5, Validation Loss=8.12e-5, Best Loss=8.12e-5]
Training Fold 1:  11%|█         | 11/100 [00:06&lt;00:44,  2.00 epochs/s, Training Loss=8.33e-5, Validation Loss=8e-5, Best Loss=8e-5]
Training Fold 1:  12%|█▏        | 12/100 [00:06&lt;00:43,  2.01 epochs/s, Training Loss=8.33e-5, Validation Loss=8e-5, Best Loss=8e-5]
Training Fold 1:  12%|█▏        | 12/100 [00:07&lt;00:43,  2.01 epochs/s, Training Loss=8.09e-5, Validation Loss=7.81e-5, Best Loss=7.81e-5]
Training Fold 1:  13%|█▎        | 13/100 [00:07&lt;00:44,  1.97 epochs/s, Training Loss=8.09e-5, Validation Loss=7.81e-5, Best Loss=7.81e-5]
Training Fold 1:  13%|█▎        | 13/100 [00:08&lt;00:44,  1.97 epochs/s, Training Loss=7.53e-5, Validation Loss=7.2e-5, Best Loss=7.2e-5]
Training Fold 1:  14%|█▍        | 14/100 [00:08&lt;00:43,  1.98 epochs/s, Training Loss=7.53e-5, Validation Loss=7.2e-5, Best Loss=7.2e-5]
Training Fold 1:  14%|█▍        | 14/100 [00:08&lt;00:43,  1.98 epochs/s, Training Loss=7.43e-5, Validation Loss=7.04e-5, Best Loss=7.04e-5]
Training Fold 1:  15%|█▌        | 15/100 [00:08&lt;00:43,  1.95 epochs/s, Training Loss=7.43e-5, Validation Loss=7.04e-5, Best Loss=7.04e-5]
Training Fold 1:  15%|█▌        | 15/100 [00:09&lt;00:43,  1.95 epochs/s, Training Loss=7.05e-5, Validation Loss=6.7e-5, Best Loss=6.7e-5]
Training Fold 1:  16%|█▌        | 16/100 [00:09&lt;00:42,  1.97 epochs/s, Training Loss=7.05e-5, Validation Loss=6.7e-5, Best Loss=6.7e-5]
Training Fold 1:  16%|█▌        | 16/100 [00:09&lt;00:42,  1.97 epochs/s, Training Loss=6.82e-5, Validation Loss=6.46e-5, Best Loss=6.46e-5]
Training Fold 1:  17%|█▋        | 17/100 [00:09&lt;00:41,  2.01 epochs/s, Training Loss=6.82e-5, Validation Loss=6.46e-5, Best Loss=6.46e-5]
Training Fold 1:  17%|█▋        | 17/100 [00:09&lt;00:41,  2.01 epochs/s, Training Loss=6.48e-5, Validation Loss=6.08e-5, Best Loss=6.08e-5]
Training Fold 1:  18%|█▊        | 18/100 [00:09&lt;00:40,  2.04 epochs/s, Training Loss=6.48e-5, Validation Loss=6.08e-5, Best Loss=6.08e-5]
Training Fold 1:  18%|█▊        | 18/100 [00:10&lt;00:40,  2.04 epochs/s, Training Loss=0.000147, Validation Loss=0.000139, Best Loss=6.08e-5]
Training Fold 1:  19%|█▉        | 19/100 [00:10&lt;00:40,  2.02 epochs/s, Training Loss=0.000147, Validation Loss=0.000139, Best Loss=6.08e-5]
Training Fold 1:  19%|█▉        | 19/100 [00:10&lt;00:40,  2.02 epochs/s, Training Loss=0.00012, Validation Loss=0.000118, Best Loss=6.08e-5]
Training Fold 1:  20%|██        | 20/100 [00:10&lt;00:39,  2.03 epochs/s, Training Loss=0.00012, Validation Loss=0.000118, Best Loss=6.08e-5]
Training Fold 1:  20%|██        | 20/100 [00:11&lt;00:39,  2.03 epochs/s, Training Loss=6.28e-5, Validation Loss=5.97e-5, Best Loss=5.97e-5]
Training Fold 1:  21%|██        | 21/100 [00:11&lt;00:39,  2.01 epochs/s, Training Loss=6.28e-5, Validation Loss=5.97e-5, Best Loss=5.97e-5]
Training Fold 1:  21%|██        | 21/100 [00:11&lt;00:39,  2.01 epochs/s, Training Loss=5.98e-5, Validation Loss=5.61e-5, Best Loss=5.61e-5]
Training Fold 1:  22%|██▏       | 22/100 [00:11&lt;00:38,  2.01 epochs/s, Training Loss=5.98e-5, Validation Loss=5.61e-5, Best Loss=5.61e-5]
Training Fold 1:  22%|██▏       | 22/100 [00:12&lt;00:38,  2.01 epochs/s, Training Loss=5.81e-5, Validation Loss=5.5e-5, Best Loss=5.5e-5]
Training Fold 1:  23%|██▎       | 23/100 [00:12&lt;00:38,  2.00 epochs/s, Training Loss=5.81e-5, Validation Loss=5.5e-5, Best Loss=5.5e-5]
Training Fold 1:  23%|██▎       | 23/100 [00:12&lt;00:38,  2.00 epochs/s, Training Loss=0.000189, Validation Loss=0.000185, Best Loss=5.5e-5]
Training Fold 1:  24%|██▍       | 24/100 [00:12&lt;00:37,  2.02 epochs/s, Training Loss=0.000189, Validation Loss=0.000185, Best Loss=5.5e-5]
Training Fold 1:  24%|██▍       | 24/100 [00:13&lt;00:37,  2.02 epochs/s, Training Loss=5.55e-5, Validation Loss=5.37e-5, Best Loss=5.37e-5]
Training Fold 1:  25%|██▌       | 25/100 [00:13&lt;00:36,  2.06 epochs/s, Training Loss=5.55e-5, Validation Loss=5.37e-5, Best Loss=5.37e-5]
Training Fold 1:  25%|██▌       | 25/100 [00:13&lt;00:36,  2.06 epochs/s, Training Loss=5.22e-5, Validation Loss=4.87e-5, Best Loss=4.87e-5]
Training Fold 1:  26%|██▌       | 26/100 [00:13&lt;00:36,  2.03 epochs/s, Training Loss=5.22e-5, Validation Loss=4.87e-5, Best Loss=4.87e-5]
Training Fold 1:  26%|██▌       | 26/100 [00:14&lt;00:36,  2.03 epochs/s, Training Loss=4.91e-5, Validation Loss=4.53e-5, Best Loss=4.53e-5]
Training Fold 1:  27%|██▋       | 27/100 [00:14&lt;00:36,  2.03 epochs/s, Training Loss=4.91e-5, Validation Loss=4.53e-5, Best Loss=4.53e-5]
Training Fold 1:  27%|██▋       | 27/100 [00:14&lt;00:36,  2.03 epochs/s, Training Loss=4.82e-5, Validation Loss=4.47e-5, Best Loss=4.47e-5]
Training Fold 1:  28%|██▊       | 28/100 [00:14&lt;00:36,  1.99 epochs/s, Training Loss=4.82e-5, Validation Loss=4.47e-5, Best Loss=4.47e-5]
Training Fold 1:  28%|██▊       | 28/100 [00:15&lt;00:36,  1.99 epochs/s, Training Loss=4.66e-5, Validation Loss=4.42e-5, Best Loss=4.42e-5]
Training Fold 1:  29%|██▉       | 29/100 [00:15&lt;00:35,  2.01 epochs/s, Training Loss=4.66e-5, Validation Loss=4.42e-5, Best Loss=4.42e-5]
Training Fold 1:  29%|██▉       | 29/100 [00:15&lt;00:35,  2.01 epochs/s, Training Loss=4.38e-5, Validation Loss=4.25e-5, Best Loss=4.25e-5]
Training Fold 1:  30%|███       | 30/100 [00:15&lt;00:34,  2.03 epochs/s, Training Loss=4.38e-5, Validation Loss=4.25e-5, Best Loss=4.25e-5]
Training Fold 1:  30%|███       | 30/100 [00:16&lt;00:34,  2.03 epochs/s, Training Loss=4.45e-5, Validation Loss=4.35e-5, Best Loss=4.25e-5]
Training Fold 1:  31%|███       | 31/100 [00:16&lt;00:33,  2.04 epochs/s, Training Loss=4.45e-5, Validation Loss=4.35e-5, Best Loss=4.25e-5]
Training Fold 1:  31%|███       | 31/100 [00:16&lt;00:33,  2.04 epochs/s, Training Loss=4.45e-5, Validation Loss=4.43e-5, Best Loss=4.25e-5]
Training Fold 1:  32%|███▏      | 32/100 [00:16&lt;00:33,  2.05 epochs/s, Training Loss=4.45e-5, Validation Loss=4.43e-5, Best Loss=4.25e-5]
Training Fold 1:  32%|███▏      | 32/100 [00:17&lt;00:33,  2.05 epochs/s, Training Loss=4.24e-5, Validation Loss=4.01e-5, Best Loss=4.01e-5]
Training Fold 1:  33%|███▎      | 33/100 [00:17&lt;00:32,  2.09 epochs/s, Training Loss=4.24e-5, Validation Loss=4.01e-5, Best Loss=4.01e-5]
Training Fold 1:  33%|███▎      | 33/100 [00:17&lt;00:32,  2.09 epochs/s, Training Loss=4.63e-5, Validation Loss=4.6e-5, Best Loss=4.01e-5]
Training Fold 1:  34%|███▍      | 34/100 [00:17&lt;00:31,  2.10 epochs/s, Training Loss=4.63e-5, Validation Loss=4.6e-5, Best Loss=4.01e-5]
Training Fold 1:  34%|███▍      | 34/100 [00:18&lt;00:31,  2.10 epochs/s, Training Loss=4.22e-5, Validation Loss=3.92e-5, Best Loss=3.92e-5]
Training Fold 1:  35%|███▌      | 35/100 [00:18&lt;00:31,  2.09 epochs/s, Training Loss=4.22e-5, Validation Loss=3.92e-5, Best Loss=3.92e-5]
Training Fold 1:  35%|███▌      | 35/100 [00:18&lt;00:31,  2.09 epochs/s, Training Loss=4.24e-5, Validation Loss=4.21e-5, Best Loss=3.92e-5]
Training Fold 1:  36%|███▌      | 36/100 [00:18&lt;00:30,  2.10 epochs/s, Training Loss=4.24e-5, Validation Loss=4.21e-5, Best Loss=3.92e-5]
Training Fold 1:  36%|███▌      | 36/100 [00:19&lt;00:30,  2.10 epochs/s, Training Loss=3.89e-5, Validation Loss=3.67e-5, Best Loss=3.67e-5]
Training Fold 1:  37%|███▋      | 37/100 [00:19&lt;00:29,  2.11 epochs/s, Training Loss=3.89e-5, Validation Loss=3.67e-5, Best Loss=3.67e-5]
Training Fold 1:  37%|███▋      | 37/100 [00:19&lt;00:29,  2.11 epochs/s, Training Loss=4.47e-5, Validation Loss=4.27e-5, Best Loss=3.67e-5]
Training Fold 1:  38%|███▊      | 38/100 [00:19&lt;00:29,  2.07 epochs/s, Training Loss=4.47e-5, Validation Loss=4.27e-5, Best Loss=3.67e-5]
Training Fold 1:  38%|███▊      | 38/100 [00:20&lt;00:29,  2.07 epochs/s, Training Loss=3.83e-5, Validation Loss=3.72e-5, Best Loss=3.67e-5]
Training Fold 1:  39%|███▉      | 39/100 [00:20&lt;00:29,  2.08 epochs/s, Training Loss=3.83e-5, Validation Loss=3.72e-5, Best Loss=3.67e-5]
Training Fold 1:  39%|███▉      | 39/100 [00:20&lt;00:29,  2.08 epochs/s, Training Loss=4.31e-5, Validation Loss=4.02e-5, Best Loss=3.67e-5]
Training Fold 1:  40%|████      | 40/100 [00:20&lt;00:29,  2.06 epochs/s, Training Loss=4.31e-5, Validation Loss=4.02e-5, Best Loss=3.67e-5]
Training Fold 1:  40%|████      | 40/100 [00:21&lt;00:29,  2.06 epochs/s, Training Loss=6.61e-5, Validation Loss=6.25e-5, Best Loss=3.67e-5]
Training Fold 1:  41%|████      | 41/100 [00:21&lt;00:28,  2.08 epochs/s, Training Loss=6.61e-5, Validation Loss=6.25e-5, Best Loss=3.67e-5]
Training Fold 1:  41%|████      | 41/100 [00:21&lt;00:28,  2.08 epochs/s, Training Loss=3.37e-5, Validation Loss=3.15e-5, Best Loss=3.15e-5]
Training Fold 1:  42%|████▏     | 42/100 [00:21&lt;00:27,  2.10 epochs/s, Training Loss=3.37e-5, Validation Loss=3.15e-5, Best Loss=3.15e-5]
Training Fold 1:  42%|████▏     | 42/100 [00:22&lt;00:27,  2.10 epochs/s, Training Loss=3.53e-5, Validation Loss=3.34e-5, Best Loss=3.15e-5]
Training Fold 1:  43%|████▎     | 43/100 [00:22&lt;00:27,  2.05 epochs/s, Training Loss=3.53e-5, Validation Loss=3.34e-5, Best Loss=3.15e-5]
Training Fold 1:  43%|████▎     | 43/100 [00:22&lt;00:27,  2.05 epochs/s, Training Loss=4.34e-5, Validation Loss=4.21e-5, Best Loss=3.15e-5]
Training Fold 1:  44%|████▍     | 44/100 [00:22&lt;00:27,  2.07 epochs/s, Training Loss=4.34e-5, Validation Loss=4.21e-5, Best Loss=3.15e-5]
Training Fold 1:  44%|████▍     | 44/100 [00:23&lt;00:27,  2.07 epochs/s, Training Loss=9.39e-5, Validation Loss=9.12e-5, Best Loss=3.15e-5]
Training Fold 1:  45%|████▌     | 45/100 [00:23&lt;00:26,  2.08 epochs/s, Training Loss=9.39e-5, Validation Loss=9.12e-5, Best Loss=3.15e-5]
Training Fold 1:  45%|████▌     | 45/100 [00:23&lt;00:26,  2.08 epochs/s, Training Loss=3.4e-5, Validation Loss=3.3e-5, Best Loss=3.15e-5]
Training Fold 1:  46%|████▌     | 46/100 [00:23&lt;00:26,  2.05 epochs/s, Training Loss=3.4e-5, Validation Loss=3.3e-5, Best Loss=3.15e-5]
Training Fold 1:  46%|████▌     | 46/100 [00:24&lt;00:26,  2.05 epochs/s, Training Loss=3.34e-5, Validation Loss=2.96e-5, Best Loss=2.96e-5]
Training Fold 1:  47%|████▋     | 47/100 [00:24&lt;00:25,  2.09 epochs/s, Training Loss=3.34e-5, Validation Loss=2.96e-5, Best Loss=2.96e-5]
Training Fold 1:  47%|████▋     | 47/100 [00:24&lt;00:25,  2.09 epochs/s, Training Loss=3.26e-5, Validation Loss=3.06e-5, Best Loss=2.96e-5]
Training Fold 1:  48%|████▊     | 48/100 [00:24&lt;00:24,  2.09 epochs/s, Training Loss=3.26e-5, Validation Loss=3.06e-5, Best Loss=2.96e-5]
Training Fold 1:  48%|████▊     | 48/100 [00:25&lt;00:24,  2.09 epochs/s, Training Loss=3.58e-5, Validation Loss=3.62e-5, Best Loss=2.96e-5]
Training Fold 1:  49%|████▉     | 49/100 [00:25&lt;00:24,  2.12 epochs/s, Training Loss=3.58e-5, Validation Loss=3.62e-5, Best Loss=2.96e-5]
Training Fold 1:  49%|████▉     | 49/100 [00:25&lt;00:24,  2.12 epochs/s, Training Loss=3.76e-5, Validation Loss=3.81e-5, Best Loss=2.96e-5]
Training Fold 1:  50%|█████     | 50/100 [00:25&lt;00:23,  2.09 epochs/s, Training Loss=3.76e-5, Validation Loss=3.81e-5, Best Loss=2.96e-5]
Training Fold 1:  50%|█████     | 50/100 [00:26&lt;00:23,  2.09 epochs/s, Training Loss=3.39e-5, Validation Loss=3.02e-5, Best Loss=2.96e-5]
Training Fold 1:  51%|█████     | 51/100 [00:26&lt;00:23,  2.07 epochs/s, Training Loss=3.39e-5, Validation Loss=3.02e-5, Best Loss=2.96e-5]
Training Fold 1:  51%|█████     | 51/100 [00:26&lt;00:23,  2.07 epochs/s, Training Loss=3.26e-5, Validation Loss=3.22e-5, Best Loss=2.96e-5]
Training Fold 1:  52%|█████▏    | 52/100 [00:26&lt;00:23,  2.07 epochs/s, Training Loss=3.26e-5, Validation Loss=3.22e-5, Best Loss=2.96e-5]
Training Fold 1:  52%|█████▏    | 52/100 [00:26&lt;00:23,  2.07 epochs/s, Training Loss=5.04e-5, Validation Loss=4.76e-5, Best Loss=2.96e-5]
Training Fold 1:  53%|█████▎    | 53/100 [00:26&lt;00:22,  2.05 epochs/s, Training Loss=5.04e-5, Validation Loss=4.76e-5, Best Loss=2.96e-5]
Training Fold 1:  53%|█████▎    | 53/100 [00:27&lt;00:22,  2.05 epochs/s, Training Loss=3.24e-5, Validation Loss=2.75e-5, Best Loss=2.75e-5]
Training Fold 1:  54%|█████▍    | 54/100 [00:27&lt;00:21,  2.11 epochs/s, Training Loss=3.24e-5, Validation Loss=2.75e-5, Best Loss=2.75e-5]
Training Fold 1:  54%|█████▍    | 54/100 [00:27&lt;00:21,  2.11 epochs/s, Training Loss=2.9e-5, Validation Loss=2.75e-5, Best Loss=2.75e-5]
Training Fold 1:  55%|█████▌    | 55/100 [00:27&lt;00:21,  2.09 epochs/s, Training Loss=2.9e-5, Validation Loss=2.75e-5, Best Loss=2.75e-5]
Training Fold 1:  55%|█████▌    | 55/100 [00:28&lt;00:21,  2.09 epochs/s, Training Loss=2.91e-5, Validation Loss=2.84e-5, Best Loss=2.75e-5]
Training Fold 1:  56%|█████▌    | 56/100 [00:28&lt;00:20,  2.13 epochs/s, Training Loss=2.91e-5, Validation Loss=2.84e-5, Best Loss=2.75e-5]
Training Fold 1:  56%|█████▌    | 56/100 [00:28&lt;00:20,  2.13 epochs/s, Training Loss=3.75e-5, Validation Loss=3.64e-5, Best Loss=2.75e-5]
Training Fold 1:  57%|█████▋    | 57/100 [00:28&lt;00:20,  2.10 epochs/s, Training Loss=3.75e-5, Validation Loss=3.64e-5, Best Loss=2.75e-5]
Training Fold 1:  57%|█████▋    | 57/100 [00:29&lt;00:20,  2.10 epochs/s, Training Loss=2.95e-5, Validation Loss=2.68e-5, Best Loss=2.68e-5]
Training Fold 1:  58%|█████▊    | 58/100 [00:29&lt;00:19,  2.10 epochs/s, Training Loss=2.95e-5, Validation Loss=2.68e-5, Best Loss=2.68e-5]
Training Fold 1:  58%|█████▊    | 58/100 [00:29&lt;00:19,  2.10 epochs/s, Training Loss=2.88e-5, Validation Loss=2.94e-5, Best Loss=2.68e-5]
Training Fold 1:  59%|█████▉    | 59/100 [00:29&lt;00:20,  2.00 epochs/s, Training Loss=2.88e-5, Validation Loss=2.94e-5, Best Loss=2.68e-5]
Training Fold 1:  59%|█████▉    | 59/100 [00:30&lt;00:20,  2.00 epochs/s, Training Loss=2.91e-5, Validation Loss=2.68e-5, Best Loss=2.68e-5]
Training Fold 1:  60%|██████    | 60/100 [00:30&lt;00:20,  1.97 epochs/s, Training Loss=2.91e-5, Validation Loss=2.68e-5, Best Loss=2.68e-5]
Training Fold 1:  60%|██████    | 60/100 [00:30&lt;00:20,  1.97 epochs/s, Training Loss=2.93e-5, Validation Loss=2.85e-5, Best Loss=2.68e-5]
Training Fold 1:  61%|██████    | 61/100 [00:30&lt;00:19,  1.97 epochs/s, Training Loss=2.93e-5, Validation Loss=2.85e-5, Best Loss=2.68e-5]
Training Fold 1:  61%|██████    | 61/100 [00:31&lt;00:19,  1.97 epochs/s, Training Loss=3.23e-5, Validation Loss=3.16e-5, Best Loss=2.68e-5]
Training Fold 1:  62%|██████▏   | 62/100 [00:31&lt;00:19,  1.93 epochs/s, Training Loss=3.23e-5, Validation Loss=3.16e-5, Best Loss=2.68e-5]
Training Fold 1:  62%|██████▏   | 62/100 [00:31&lt;00:19,  1.93 epochs/s, Training Loss=3.05e-5, Validation Loss=2.68e-5, Best Loss=2.68e-5]
Training Fold 1:  63%|██████▎   | 63/100 [00:31&lt;00:18,  1.98 epochs/s, Training Loss=3.05e-5, Validation Loss=2.68e-5, Best Loss=2.68e-5]
Training Fold 1:  63%|██████▎   | 63/100 [00:32&lt;00:18,  1.98 epochs/s, Training Loss=2.72e-5, Validation Loss=2.68e-5, Best Loss=2.68e-5]
Training Fold 1:  64%|██████▍   | 64/100 [00:32&lt;00:17,  2.03 epochs/s, Training Loss=2.72e-5, Validation Loss=2.68e-5, Best Loss=2.68e-5]
Training Fold 1:  64%|██████▍   | 64/100 [00:32&lt;00:17,  2.03 epochs/s, Training Loss=3.55e-5, Validation Loss=3.67e-5, Best Loss=2.68e-5]
Training Fold 1:  65%|██████▌   | 65/100 [00:32&lt;00:17,  2.03 epochs/s, Training Loss=3.55e-5, Validation Loss=3.67e-5, Best Loss=2.68e-5]
Training Fold 1:  65%|██████▌   | 65/100 [00:33&lt;00:17,  2.03 epochs/s, Training Loss=2.93e-5, Validation Loss=2.83e-5, Best Loss=2.68e-5]
Training Fold 1:  66%|██████▌   | 66/100 [00:33&lt;00:16,  2.01 epochs/s, Training Loss=2.93e-5, Validation Loss=2.83e-5, Best Loss=2.68e-5]
Training Fold 1:  66%|██████▌   | 66/100 [00:33&lt;00:16,  2.01 epochs/s, Training Loss=2.68e-5, Validation Loss=2.59e-5, Best Loss=2.59e-5]
Training Fold 1:  67%|██████▋   | 67/100 [00:33&lt;00:16,  2.01 epochs/s, Training Loss=2.68e-5, Validation Loss=2.59e-5, Best Loss=2.59e-5]
Training Fold 1:  67%|██████▋   | 67/100 [00:34&lt;00:16,  2.01 epochs/s, Training Loss=2.64e-5, Validation Loss=2.51e-5, Best Loss=2.51e-5]
Training Fold 1:  68%|██████▊   | 68/100 [00:34&lt;00:15,  2.03 epochs/s, Training Loss=2.64e-5, Validation Loss=2.51e-5, Best Loss=2.51e-5]
Training Fold 1:  68%|██████▊   | 68/100 [00:34&lt;00:15,  2.03 epochs/s, Training Loss=6.17e-5, Validation Loss=6.24e-5, Best Loss=2.51e-5]
Training Fold 1:  69%|██████▉   | 69/100 [00:34&lt;00:15,  2.03 epochs/s, Training Loss=6.17e-5, Validation Loss=6.24e-5, Best Loss=2.51e-5]
Training Fold 1:  69%|██████▉   | 69/100 [00:35&lt;00:15,  2.03 epochs/s, Training Loss=3.05e-5, Validation Loss=3.05e-5, Best Loss=2.51e-5]
Training Fold 1:  70%|███████   | 70/100 [00:35&lt;00:14,  2.06 epochs/s, Training Loss=3.05e-5, Validation Loss=3.05e-5, Best Loss=2.51e-5]
Training Fold 1:  70%|███████   | 70/100 [00:35&lt;00:14,  2.06 epochs/s, Training Loss=2.72e-5, Validation Loss=2.62e-5, Best Loss=2.51e-5]
Training Fold 1:  71%|███████   | 71/100 [00:35&lt;00:14,  2.06 epochs/s, Training Loss=2.72e-5, Validation Loss=2.62e-5, Best Loss=2.51e-5]
Training Fold 1:  71%|███████   | 71/100 [00:36&lt;00:14,  2.06 epochs/s, Training Loss=2.53e-5, Validation Loss=2.51e-5, Best Loss=2.51e-5]
Training Fold 1:  72%|███████▏  | 72/100 [00:36&lt;00:13,  2.05 epochs/s, Training Loss=2.53e-5, Validation Loss=2.51e-5, Best Loss=2.51e-5]
Training Fold 1:  72%|███████▏  | 72/100 [00:36&lt;00:13,  2.05 epochs/s, Training Loss=2.57e-5, Validation Loss=2.62e-5, Best Loss=2.51e-5]
Training Fold 1:  73%|███████▎  | 73/100 [00:36&lt;00:13,  2.04 epochs/s, Training Loss=2.57e-5, Validation Loss=2.62e-5, Best Loss=2.51e-5]
Training Fold 1:  73%|███████▎  | 73/100 [00:37&lt;00:13,  2.04 epochs/s, Training Loss=2.76e-5, Validation Loss=2.65e-5, Best Loss=2.51e-5]
Training Fold 1:  74%|███████▍  | 74/100 [00:37&lt;00:12,  2.08 epochs/s, Training Loss=2.76e-5, Validation Loss=2.65e-5, Best Loss=2.51e-5]
Training Fold 1:  74%|███████▍  | 74/100 [00:37&lt;00:12,  2.08 epochs/s, Training Loss=2.59e-5, Validation Loss=2.3e-5, Best Loss=2.3e-5]
Training Fold 1:  75%|███████▌  | 75/100 [00:37&lt;00:12,  2.07 epochs/s, Training Loss=2.59e-5, Validation Loss=2.3e-5, Best Loss=2.3e-5]
Training Fold 1:  75%|███████▌  | 75/100 [00:38&lt;00:12,  2.07 epochs/s, Training Loss=2.36e-5, Validation Loss=2.39e-5, Best Loss=2.3e-5]
Training Fold 1:  76%|███████▌  | 76/100 [00:38&lt;00:11,  2.09 epochs/s, Training Loss=2.36e-5, Validation Loss=2.39e-5, Best Loss=2.3e-5]
Training Fold 1:  76%|███████▌  | 76/100 [00:38&lt;00:11,  2.09 epochs/s, Training Loss=2.76e-5, Validation Loss=2.63e-5, Best Loss=2.3e-5]
Training Fold 1:  77%|███████▋  | 77/100 [00:38&lt;00:10,  2.11 epochs/s, Training Loss=2.76e-5, Validation Loss=2.63e-5, Best Loss=2.3e-5]
Training Fold 1:  77%|███████▋  | 77/100 [00:39&lt;00:10,  2.11 epochs/s, Training Loss=2.54e-5, Validation Loss=2.36e-5, Best Loss=2.3e-5]
Training Fold 1:  78%|███████▊  | 78/100 [00:39&lt;00:10,  2.10 epochs/s, Training Loss=2.54e-5, Validation Loss=2.36e-5, Best Loss=2.3e-5]
Training Fold 1:  78%|███████▊  | 78/100 [00:39&lt;00:10,  2.10 epochs/s, Training Loss=2.26e-5, Validation Loss=2.28e-5, Best Loss=2.28e-5]
Training Fold 1:  79%|███████▉  | 79/100 [00:39&lt;00:10,  2.08 epochs/s, Training Loss=2.26e-5, Validation Loss=2.28e-5, Best Loss=2.28e-5]
Training Fold 1:  79%|███████▉  | 79/100 [00:40&lt;00:10,  2.08 epochs/s, Training Loss=2.44e-5, Validation Loss=2.15e-5, Best Loss=2.15e-5]
Training Fold 1:  80%|████████  | 80/100 [00:40&lt;00:09,  2.08 epochs/s, Training Loss=2.44e-5, Validation Loss=2.15e-5, Best Loss=2.15e-5]
Training Fold 1:  80%|████████  | 80/100 [00:40&lt;00:09,  2.08 epochs/s, Training Loss=2.26e-5, Validation Loss=2.15e-5, Best Loss=2.15e-5]
Training Fold 1:  81%|████████  | 81/100 [00:40&lt;00:09,  1.97 epochs/s, Training Loss=2.26e-5, Validation Loss=2.15e-5, Best Loss=2.15e-5]
Training Fold 1:  81%|████████  | 81/100 [00:41&lt;00:09,  1.97 epochs/s, Training Loss=2.74e-5, Validation Loss=2.88e-5, Best Loss=2.15e-5]
Training Fold 1:  82%|████████▏ | 82/100 [00:41&lt;00:09,  1.98 epochs/s, Training Loss=2.74e-5, Validation Loss=2.88e-5, Best Loss=2.15e-5]
Training Fold 1:  82%|████████▏ | 82/100 [00:41&lt;00:09,  1.98 epochs/s, Training Loss=2.28e-5, Validation Loss=2.35e-5, Best Loss=2.15e-5]
Training Fold 1:  83%|████████▎ | 83/100 [00:41&lt;00:08,  1.99 epochs/s, Training Loss=2.28e-5, Validation Loss=2.35e-5, Best Loss=2.15e-5]
Training Fold 1:  83%|████████▎ | 83/100 [00:42&lt;00:08,  1.99 epochs/s, Training Loss=2.06e-5, Validation Loss=1.93e-5, Best Loss=1.93e-5]
Training Fold 1:  84%|████████▍ | 84/100 [00:42&lt;00:07,  2.03 epochs/s, Training Loss=2.06e-5, Validation Loss=1.93e-5, Best Loss=1.93e-5]
Training Fold 1:  84%|████████▍ | 84/100 [00:42&lt;00:07,  2.03 epochs/s, Training Loss=2.07e-5, Validation Loss=1.94e-5, Best Loss=1.93e-5]
Training Fold 1:  85%|████████▌ | 85/100 [00:42&lt;00:07,  2.02 epochs/s, Training Loss=2.07e-5, Validation Loss=1.94e-5, Best Loss=1.93e-5]
Training Fold 1:  85%|████████▌ | 85/100 [00:43&lt;00:07,  2.02 epochs/s, Training Loss=2.19e-5, Validation Loss=2.16e-5, Best Loss=1.93e-5]
Training Fold 1:  86%|████████▌ | 86/100 [00:43&lt;00:06,  2.06 epochs/s, Training Loss=2.19e-5, Validation Loss=2.16e-5, Best Loss=1.93e-5]
Training Fold 1:  86%|████████▌ | 86/100 [00:43&lt;00:06,  2.06 epochs/s, Training Loss=2.37e-5, Validation Loss=2.44e-5, Best Loss=1.93e-5]
Training Fold 1:  87%|████████▋ | 87/100 [00:43&lt;00:06,  2.05 epochs/s, Training Loss=2.37e-5, Validation Loss=2.44e-5, Best Loss=1.93e-5]
Training Fold 1:  87%|████████▋ | 87/100 [00:44&lt;00:06,  2.05 epochs/s, Training Loss=2.58e-5, Validation Loss=2.8e-5, Best Loss=1.93e-5]
Training Fold 1:  88%|████████▊ | 88/100 [00:44&lt;00:05,  2.07 epochs/s, Training Loss=2.58e-5, Validation Loss=2.8e-5, Best Loss=1.93e-5]
Training Fold 1:  88%|████████▊ | 88/100 [00:44&lt;00:05,  2.07 epochs/s, Training Loss=2.07e-5, Validation Loss=2.09e-5, Best Loss=1.93e-5]
Training Fold 1:  89%|████████▉ | 89/100 [00:44&lt;00:05,  2.08 epochs/s, Training Loss=2.07e-5, Validation Loss=2.09e-5, Best Loss=1.93e-5]
Training Fold 1:  89%|████████▉ | 89/100 [00:45&lt;00:05,  2.08 epochs/s, Training Loss=2.07e-5, Validation Loss=1.96e-5, Best Loss=1.93e-5]
Training Fold 1:  90%|█████████ | 90/100 [00:45&lt;00:04,  2.07 epochs/s, Training Loss=2.07e-5, Validation Loss=1.96e-5, Best Loss=1.93e-5]
Training Fold 1:  90%|█████████ | 90/100 [00:45&lt;00:04,  2.07 epochs/s, Training Loss=2.43e-5, Validation Loss=2.56e-5, Best Loss=1.93e-5]
Training Fold 1:  91%|█████████ | 91/100 [00:45&lt;00:04,  2.08 epochs/s, Training Loss=2.43e-5, Validation Loss=2.56e-5, Best Loss=1.93e-5]
Training Fold 1:  91%|█████████ | 91/100 [00:46&lt;00:04,  2.08 epochs/s, Training Loss=2.16e-5, Validation Loss=2.26e-5, Best Loss=1.93e-5]
Training Fold 1:  92%|█████████▏| 92/100 [00:46&lt;00:03,  2.08 epochs/s, Training Loss=2.16e-5, Validation Loss=2.26e-5, Best Loss=1.93e-5]
Training Fold 1:  92%|█████████▏| 92/100 [00:46&lt;00:03,  2.08 epochs/s, Training Loss=2.09e-5, Validation Loss=2.18e-5, Best Loss=1.93e-5]
Training Fold 1:  93%|█████████▎| 93/100 [00:46&lt;00:03,  2.07 epochs/s, Training Loss=2.09e-5, Validation Loss=2.18e-5, Best Loss=1.93e-5]
Training Fold 1:  93%|█████████▎| 93/100 [00:47&lt;00:03,  2.07 epochs/s, Training Loss=2.08e-5, Validation Loss=2.17e-5, Best Loss=1.93e-5]
Training Fold 1:  94%|█████████▍| 94/100 [00:47&lt;00:02,  2.07 epochs/s, Training Loss=2.08e-5, Validation Loss=2.17e-5, Best Loss=1.93e-5]
Training Fold 1:  94%|█████████▍| 94/100 [00:47&lt;00:02,  2.07 epochs/s, Training Loss=2.54e-5, Validation Loss=2.4e-5, Best Loss=1.93e-5]
Training Fold 1:  95%|█████████▌| 95/100 [00:47&lt;00:02,  2.05 epochs/s, Training Loss=2.54e-5, Validation Loss=2.4e-5, Best Loss=1.93e-5]
Training Fold 1:  95%|█████████▌| 95/100 [00:47&lt;00:02,  2.05 epochs/s, Training Loss=2.13e-5, Validation Loss=2.03e-5, Best Loss=1.93e-5]
Training Fold 1:  96%|█████████▌| 96/100 [00:47&lt;00:01,  2.09 epochs/s, Training Loss=2.13e-5, Validation Loss=2.03e-5, Best Loss=1.93e-5]
Training Fold 1:  96%|█████████▌| 96/100 [00:48&lt;00:01,  2.09 epochs/s, Training Loss=2.11e-5, Validation Loss=2.11e-5, Best Loss=1.93e-5]
Training Fold 1:  97%|█████████▋| 97/100 [00:48&lt;00:01,  2.09 epochs/s, Training Loss=2.11e-5, Validation Loss=2.11e-5, Best Loss=1.93e-5]
Training Fold 1:  97%|█████████▋| 97/100 [00:48&lt;00:01,  2.09 epochs/s, Training Loss=1.94e-5, Validation Loss=1.88e-5, Best Loss=1.88e-5]
Training Fold 1:  98%|█████████▊| 98/100 [00:48&lt;00:00,  2.08 epochs/s, Training Loss=1.94e-5, Validation Loss=1.88e-5, Best Loss=1.88e-5]
Training Fold 1:  98%|█████████▊| 98/100 [00:49&lt;00:00,  2.08 epochs/s, Training Loss=2.19e-5, Validation Loss=1.85e-5, Best Loss=1.85e-5]
Training Fold 1:  99%|█████████▉| 99/100 [00:49&lt;00:00,  2.10 epochs/s, Training Loss=2.19e-5, Validation Loss=1.85e-5, Best Loss=1.85e-5]
Training Fold 1:  99%|█████████▉| 99/100 [00:49&lt;00:00,  2.10 epochs/s, Training Loss=1.94e-5, Validation Loss=2.06e-5, Best Loss=1.85e-5]
Training Fold 1: 100%|██████████| 100/100 [00:49&lt;00:00,  2.11 epochs/s, Training Loss=1.94e-5, Validation Loss=2.06e-5, Best Loss=1.85e-5]
Training Fold 1: 100%|██████████| 100/100 [00:49&lt;00:00,  2.01 epochs/s, Training Loss=1.94e-5, Validation Loss=2.06e-5, Best Loss=1.85e-5]

  0%|          | 0/100 [00:00&lt;?, ? epochs/s]
Training Fold 2:   0%|          | 0/100 [00:00&lt;?, ? epochs/s]
Training Fold 2:   0%|          | 0/100 [00:00&lt;?, ? epochs/s, Training Loss=3.02e-5, Validation Loss=2.37e-5, Best Loss=1.85e-5]
Training Fold 2:   1%|          | 1/100 [00:00&lt;00:44,  2.25 epochs/s, Training Loss=3.02e-5, Validation Loss=2.37e-5, Best Loss=1.85e-5]
Training Fold 2:   1%|          | 1/100 [00:00&lt;00:44,  2.25 epochs/s, Training Loss=2.8e-5, Validation Loss=2.42e-5, Best Loss=1.85e-5]
Training Fold 2:   2%|▏         | 2/100 [00:00&lt;00:45,  2.18 epochs/s, Training Loss=2.8e-5, Validation Loss=2.42e-5, Best Loss=1.85e-5]
Training Fold 2:   2%|▏         | 2/100 [00:01&lt;00:45,  2.18 epochs/s, Training Loss=2.11e-5, Validation Loss=1.77e-5, Best Loss=1.77e-5]
Training Fold 2:   3%|▎         | 3/100 [00:01&lt;00:44,  2.19 epochs/s, Training Loss=2.11e-5, Validation Loss=1.77e-5, Best Loss=1.77e-5]
Training Fold 2:   3%|▎         | 3/100 [00:01&lt;00:44,  2.19 epochs/s, Training Loss=2.06e-5, Validation Loss=1.67e-5, Best Loss=1.67e-5]
Training Fold 2:   4%|▍         | 4/100 [00:01&lt;00:44,  2.17 epochs/s, Training Loss=2.06e-5, Validation Loss=1.67e-5, Best Loss=1.67e-5]
Training Fold 2:   4%|▍         | 4/100 [00:02&lt;00:44,  2.17 epochs/s, Training Loss=2.63e-5, Validation Loss=2.22e-5, Best Loss=1.67e-5]
Training Fold 2:   5%|▌         | 5/100 [00:02&lt;00:44,  2.15 epochs/s, Training Loss=2.63e-5, Validation Loss=2.22e-5, Best Loss=1.67e-5]
Training Fold 2:   5%|▌         | 5/100 [00:02&lt;00:44,  2.15 epochs/s, Training Loss=2.33e-5, Validation Loss=2.09e-5, Best Loss=1.67e-5]
Training Fold 2:   6%|▌         | 6/100 [00:02&lt;00:44,  2.09 epochs/s, Training Loss=2.33e-5, Validation Loss=2.09e-5, Best Loss=1.67e-5]
Training Fold 2:   6%|▌         | 6/100 [00:03&lt;00:44,  2.09 epochs/s, Training Loss=1.93e-5, Validation Loss=1.54e-5, Best Loss=1.54e-5]
Training Fold 2:   7%|▋         | 7/100 [00:03&lt;00:44,  2.11 epochs/s, Training Loss=1.93e-5, Validation Loss=1.54e-5, Best Loss=1.54e-5]
Training Fold 2:   7%|▋         | 7/100 [00:03&lt;00:44,  2.11 epochs/s, Training Loss=1.87e-5, Validation Loss=1.54e-5, Best Loss=1.54e-5]
Training Fold 2:   8%|▊         | 8/100 [00:03&lt;00:44,  2.08 epochs/s, Training Loss=1.87e-5, Validation Loss=1.54e-5, Best Loss=1.54e-5]
Training Fold 2:   8%|▊         | 8/100 [00:04&lt;00:44,  2.08 epochs/s, Training Loss=2.12e-5, Validation Loss=1.93e-5, Best Loss=1.54e-5]
Training Fold 2:   9%|▉         | 9/100 [00:04&lt;00:44,  2.04 epochs/s, Training Loss=2.12e-5, Validation Loss=1.93e-5, Best Loss=1.54e-5]
Training Fold 2:   9%|▉         | 9/100 [00:04&lt;00:44,  2.04 epochs/s, Training Loss=1.81e-5, Validation Loss=1.53e-5, Best Loss=1.53e-5]
Training Fold 2:  10%|█         | 10/100 [00:04&lt;00:44,  2.03 epochs/s, Training Loss=1.81e-5, Validation Loss=1.53e-5, Best Loss=1.53e-5]
Training Fold 2:  10%|█         | 10/100 [00:05&lt;00:44,  2.03 epochs/s, Training Loss=2.04e-5, Validation Loss=1.78e-5, Best Loss=1.53e-5]
Training Fold 2:  11%|█         | 11/100 [00:05&lt;00:42,  2.07 epochs/s, Training Loss=2.04e-5, Validation Loss=1.78e-5, Best Loss=1.53e-5]
Training Fold 2:  11%|█         | 11/100 [00:05&lt;00:42,  2.07 epochs/s, Training Loss=1.82e-5, Validation Loss=1.56e-5, Best Loss=1.53e-5]
Training Fold 2:  12%|█▏        | 12/100 [00:05&lt;00:43,  2.03 epochs/s, Training Loss=1.82e-5, Validation Loss=1.56e-5, Best Loss=1.53e-5]
Training Fold 2:  12%|█▏        | 12/100 [00:06&lt;00:43,  2.03 epochs/s, Training Loss=1.87e-5, Validation Loss=1.64e-5, Best Loss=1.53e-5]
Training Fold 2:  13%|█▎        | 13/100 [00:06&lt;00:42,  2.03 epochs/s, Training Loss=1.87e-5, Validation Loss=1.64e-5, Best Loss=1.53e-5]
Training Fold 2:  13%|█▎        | 13/100 [00:06&lt;00:42,  2.03 epochs/s, Training Loss=2.53e-5, Validation Loss=2.12e-5, Best Loss=1.53e-5]
Training Fold 2:  14%|█▍        | 14/100 [00:06&lt;00:41,  2.08 epochs/s, Training Loss=2.53e-5, Validation Loss=2.12e-5, Best Loss=1.53e-5]
Training Fold 2:  14%|█▍        | 14/100 [00:07&lt;00:41,  2.08 epochs/s, Training Loss=1.87e-5, Validation Loss=1.61e-5, Best Loss=1.53e-5]
Training Fold 2:  15%|█▌        | 15/100 [00:07&lt;00:41,  2.03 epochs/s, Training Loss=1.87e-5, Validation Loss=1.61e-5, Best Loss=1.53e-5]
Training Fold 2:  15%|█▌        | 15/100 [00:07&lt;00:41,  2.03 epochs/s, Training Loss=1.84e-5, Validation Loss=1.63e-5, Best Loss=1.53e-5]
Training Fold 2:  16%|█▌        | 16/100 [00:07&lt;00:41,  2.03 epochs/s, Training Loss=1.84e-5, Validation Loss=1.63e-5, Best Loss=1.53e-5]
Training Fold 2:  16%|█▌        | 16/100 [00:08&lt;00:41,  2.03 epochs/s, Training Loss=2.1e-5, Validation Loss=1.89e-5, Best Loss=1.53e-5]
Training Fold 2:  17%|█▋        | 17/100 [00:08&lt;00:40,  2.07 epochs/s, Training Loss=2.1e-5, Validation Loss=1.89e-5, Best Loss=1.53e-5]
Training Fold 2:  17%|█▋        | 17/100 [00:08&lt;00:40,  2.07 epochs/s, Training Loss=1.83e-5, Validation Loss=1.68e-5, Best Loss=1.53e-5]
Training Fold 2:  18%|█▊        | 18/100 [00:08&lt;00:40,  2.04 epochs/s, Training Loss=1.83e-5, Validation Loss=1.68e-5, Best Loss=1.53e-5]
Training Fold 2:  18%|█▊        | 18/100 [00:09&lt;00:40,  2.04 epochs/s, Training Loss=1.85e-5, Validation Loss=1.61e-5, Best Loss=1.53e-5]
Training Fold 2:  19%|█▉        | 19/100 [00:09&lt;00:39,  2.04 epochs/s, Training Loss=1.85e-5, Validation Loss=1.61e-5, Best Loss=1.53e-5]
Training Fold 2:  19%|█▉        | 19/100 [00:09&lt;00:39,  2.04 epochs/s, Training Loss=1.79e-5, Validation Loss=1.64e-5, Best Loss=1.53e-5]
Training Fold 2:  20%|██        | 20/100 [00:09&lt;00:39,  2.01 epochs/s, Training Loss=1.79e-5, Validation Loss=1.64e-5, Best Loss=1.53e-5]
Training Fold 2:  20%|██        | 20/100 [00:10&lt;00:39,  2.01 epochs/s, Training Loss=1.96e-5, Validation Loss=1.85e-5, Best Loss=1.53e-5]
Training Fold 2:  21%|██        | 21/100 [00:10&lt;00:39,  2.02 epochs/s, Training Loss=1.96e-5, Validation Loss=1.85e-5, Best Loss=1.53e-5]
Training Fold 2:  21%|██        | 21/100 [00:10&lt;00:39,  2.02 epochs/s, Training Loss=2.01e-5, Validation Loss=1.75e-5, Best Loss=1.53e-5]
Training Fold 2:  22%|██▏       | 22/100 [00:10&lt;00:37,  2.05 epochs/s, Training Loss=2.01e-5, Validation Loss=1.75e-5, Best Loss=1.53e-5]
Training Fold 2:  22%|██▏       | 22/100 [00:11&lt;00:37,  2.05 epochs/s, Training Loss=1.85e-5, Validation Loss=1.65e-5, Best Loss=1.53e-5]
Training Fold 2:  23%|██▎       | 23/100 [00:11&lt;00:36,  2.10 epochs/s, Training Loss=1.85e-5, Validation Loss=1.65e-5, Best Loss=1.53e-5]
Training Fold 2:  23%|██▎       | 23/100 [00:11&lt;00:36,  2.10 epochs/s, Training Loss=1.84e-5, Validation Loss=1.65e-5, Best Loss=1.53e-5]
Training Fold 2:  24%|██▍       | 24/100 [00:11&lt;00:36,  2.09 epochs/s, Training Loss=1.84e-5, Validation Loss=1.65e-5, Best Loss=1.53e-5]
Training Fold 2:  24%|██▍       | 24/100 [00:12&lt;00:36,  2.09 epochs/s, Training Loss=1.67e-5, Validation Loss=1.52e-5, Best Loss=1.52e-5]
Training Fold 2:  25%|██▌       | 25/100 [00:12&lt;00:35,  2.11 epochs/s, Training Loss=1.67e-5, Validation Loss=1.52e-5, Best Loss=1.52e-5]
Training Fold 2:  25%|██▌       | 25/100 [00:12&lt;00:35,  2.11 epochs/s, Training Loss=1.79e-5, Validation Loss=1.77e-5, Best Loss=1.52e-5]
Training Fold 2:  26%|██▌       | 26/100 [00:12&lt;00:35,  2.09 epochs/s, Training Loss=1.79e-5, Validation Loss=1.77e-5, Best Loss=1.52e-5]
Training Fold 2:  26%|██▌       | 26/100 [00:12&lt;00:35,  2.09 epochs/s, Training Loss=1.76e-5, Validation Loss=1.54e-5, Best Loss=1.52e-5]
Training Fold 2:  27%|██▋       | 27/100 [00:12&lt;00:34,  2.12 epochs/s, Training Loss=1.76e-5, Validation Loss=1.54e-5, Best Loss=1.52e-5]
Training Fold 2:  27%|██▋       | 27/100 [00:13&lt;00:34,  2.12 epochs/s, Training Loss=1.68e-5, Validation Loss=1.47e-5, Best Loss=1.47e-5]
Training Fold 2:  28%|██▊       | 28/100 [00:13&lt;00:34,  2.12 epochs/s, Training Loss=1.68e-5, Validation Loss=1.47e-5, Best Loss=1.47e-5]
Training Fold 2:  28%|██▊       | 28/100 [00:14&lt;00:34,  2.12 epochs/s, Training Loss=2.1e-5, Validation Loss=2.17e-5, Best Loss=1.47e-5]
Training Fold 2:  29%|██▉       | 29/100 [00:14&lt;00:35,  2.03 epochs/s, Training Loss=2.1e-5, Validation Loss=2.17e-5, Best Loss=1.47e-5]
Training Fold 2:  29%|██▉       | 29/100 [00:14&lt;00:35,  2.03 epochs/s, Training Loss=1.88e-5, Validation Loss=1.7e-5, Best Loss=1.47e-5]
Training Fold 2:  30%|███       | 30/100 [00:14&lt;00:35,  1.98 epochs/s, Training Loss=1.88e-5, Validation Loss=1.7e-5, Best Loss=1.47e-5]
Training Fold 2:  30%|███       | 30/100 [00:15&lt;00:35,  1.98 epochs/s, Training Loss=1.98e-5, Validation Loss=1.91e-5, Best Loss=1.47e-5]
Training Fold 2:  31%|███       | 31/100 [00:15&lt;00:34,  1.97 epochs/s, Training Loss=1.98e-5, Validation Loss=1.91e-5, Best Loss=1.47e-5]
Training Fold 2:  31%|███       | 31/100 [00:15&lt;00:34,  1.97 epochs/s, Training Loss=1.71e-5, Validation Loss=1.59e-5, Best Loss=1.47e-5]
Training Fold 2:  32%|███▏      | 32/100 [00:15&lt;00:34,  1.98 epochs/s, Training Loss=1.71e-5, Validation Loss=1.59e-5, Best Loss=1.47e-5]
Training Fold 2:  32%|███▏      | 32/100 [00:16&lt;00:34,  1.98 epochs/s, Training Loss=1.68e-5, Validation Loss=1.56e-5, Best Loss=1.47e-5]
Training Fold 2:  33%|███▎      | 33/100 [00:16&lt;00:33,  2.00 epochs/s, Training Loss=1.68e-5, Validation Loss=1.56e-5, Best Loss=1.47e-5]
Training Fold 2:  33%|███▎      | 33/100 [00:16&lt;00:33,  2.00 epochs/s, Training Loss=1.72e-5, Validation Loss=1.57e-5, Best Loss=1.47e-5]
Training Fold 2:  34%|███▍      | 34/100 [00:16&lt;00:32,  2.01 epochs/s, Training Loss=1.72e-5, Validation Loss=1.57e-5, Best Loss=1.47e-5]
Training Fold 2:  34%|███▍      | 34/100 [00:16&lt;00:32,  2.01 epochs/s, Training Loss=1.79e-5, Validation Loss=1.68e-5, Best Loss=1.47e-5]
Training Fold 2:  35%|███▌      | 35/100 [00:16&lt;00:31,  2.05 epochs/s, Training Loss=1.79e-5, Validation Loss=1.68e-5, Best Loss=1.47e-5]
Training Fold 2:  35%|███▌      | 35/100 [00:17&lt;00:31,  2.05 epochs/s, Training Loss=1.75e-5, Validation Loss=1.63e-5, Best Loss=1.47e-5]
Training Fold 2:  36%|███▌      | 36/100 [00:17&lt;00:30,  2.07 epochs/s, Training Loss=1.75e-5, Validation Loss=1.63e-5, Best Loss=1.47e-5]
Training Fold 2:  36%|███▌      | 36/100 [00:17&lt;00:30,  2.07 epochs/s, Training Loss=1.91e-5, Validation Loss=1.84e-5, Best Loss=1.47e-5]
Training Fold 2:  37%|███▋      | 37/100 [00:17&lt;00:31,  2.01 epochs/s, Training Loss=1.91e-5, Validation Loss=1.84e-5, Best Loss=1.47e-5]
Training Fold 2:  37%|███▋      | 37/100 [00:18&lt;00:31,  2.01 epochs/s, Training Loss=1.55e-5, Validation Loss=1.48e-5, Best Loss=1.47e-5]
Training Fold 2:  38%|███▊      | 38/100 [00:18&lt;00:31,  1.98 epochs/s, Training Loss=1.55e-5, Validation Loss=1.48e-5, Best Loss=1.47e-5]
Training Fold 2:  38%|███▊      | 38/100 [00:19&lt;00:31,  1.98 epochs/s, Training Loss=1.59e-5, Validation Loss=1.5e-5, Best Loss=1.47e-5]
Training Fold 2:  39%|███▉      | 39/100 [00:19&lt;00:30,  1.99 epochs/s, Training Loss=1.59e-5, Validation Loss=1.5e-5, Best Loss=1.47e-5]
Training Fold 2:  39%|███▉      | 39/100 [00:19&lt;00:30,  1.99 epochs/s, Training Loss=1.78e-5, Validation Loss=1.62e-5, Best Loss=1.47e-5]
Training Fold 2:  40%|████      | 40/100 [00:19&lt;00:30,  1.98 epochs/s, Training Loss=1.78e-5, Validation Loss=1.62e-5, Best Loss=1.47e-5]
Training Fold 2:  40%|████      | 40/100 [00:19&lt;00:30,  1.98 epochs/s, Training Loss=1.6e-5, Validation Loss=1.52e-5, Best Loss=1.47e-5]
Training Fold 2:  41%|████      | 41/100 [00:19&lt;00:28,  2.04 epochs/s, Training Loss=1.6e-5, Validation Loss=1.52e-5, Best Loss=1.47e-5]
Training Fold 2:  41%|████      | 41/100 [00:20&lt;00:28,  2.04 epochs/s, Training Loss=1.7e-5, Validation Loss=1.6e-5, Best Loss=1.47e-5]
Training Fold 2:  42%|████▏     | 42/100 [00:20&lt;00:28,  2.05 epochs/s, Training Loss=1.7e-5, Validation Loss=1.6e-5, Best Loss=1.47e-5]
Training Fold 2:  42%|████▏     | 42/100 [00:20&lt;00:28,  2.05 epochs/s, Training Loss=2.05e-5, Validation Loss=2.03e-5, Best Loss=1.47e-5]
Training Fold 2:  43%|████▎     | 43/100 [00:20&lt;00:27,  2.07 epochs/s, Training Loss=2.05e-5, Validation Loss=2.03e-5, Best Loss=1.47e-5]
Training Fold 2:  43%|████▎     | 43/100 [00:21&lt;00:27,  2.07 epochs/s, Training Loss=4.19e-5, Validation Loss=4.14e-5, Best Loss=1.47e-5]
Training Fold 2:  44%|████▍     | 44/100 [00:21&lt;00:26,  2.10 epochs/s, Training Loss=4.19e-5, Validation Loss=4.14e-5, Best Loss=1.47e-5]
Training Fold 2:  44%|████▍     | 44/100 [00:21&lt;00:26,  2.10 epochs/s, Training Loss=1.59e-5, Validation Loss=1.58e-5, Best Loss=1.47e-5]
Training Fold 2:  45%|████▌     | 45/100 [00:21&lt;00:25,  2.12 epochs/s, Training Loss=1.59e-5, Validation Loss=1.58e-5, Best Loss=1.47e-5]
Training Fold 2:  45%|████▌     | 45/100 [00:22&lt;00:25,  2.12 epochs/s, Training Loss=1.54e-5, Validation Loss=1.49e-5, Best Loss=1.47e-5]
Training Fold 2:  46%|████▌     | 46/100 [00:22&lt;00:25,  2.12 epochs/s, Training Loss=1.54e-5, Validation Loss=1.49e-5, Best Loss=1.47e-5]
Training Fold 2:  46%|████▌     | 46/100 [00:22&lt;00:25,  2.12 epochs/s, Training Loss=1.55e-5, Validation Loss=1.46e-5, Best Loss=1.46e-5]
Training Fold 2:  47%|████▋     | 47/100 [00:22&lt;00:25,  2.04 epochs/s, Training Loss=1.55e-5, Validation Loss=1.46e-5, Best Loss=1.46e-5]
Training Fold 2:  47%|████▋     | 47/100 [00:23&lt;00:25,  2.04 epochs/s, Training Loss=1.67e-5, Validation Loss=1.67e-5, Best Loss=1.46e-5]
Training Fold 2:  48%|████▊     | 48/100 [00:23&lt;00:25,  2.03 epochs/s, Training Loss=1.67e-5, Validation Loss=1.67e-5, Best Loss=1.46e-5]
Training Fold 2:  48%|████▊     | 48/100 [00:23&lt;00:25,  2.03 epochs/s, Training Loss=1.58e-5, Validation Loss=1.52e-5, Best Loss=1.46e-5]
Training Fold 2:  49%|████▉     | 49/100 [00:23&lt;00:25,  2.02 epochs/s, Training Loss=1.58e-5, Validation Loss=1.52e-5, Best Loss=1.46e-5]
Training Fold 2:  49%|████▉     | 49/100 [00:24&lt;00:25,  2.02 epochs/s, Training Loss=1.55e-5, Validation Loss=1.55e-5, Best Loss=1.46e-5]
Training Fold 2:  50%|█████     | 50/100 [00:24&lt;00:24,  2.02 epochs/s, Training Loss=1.55e-5, Validation Loss=1.55e-5, Best Loss=1.46e-5]
Training Fold 2:  50%|█████     | 50/100 [00:24&lt;00:24,  2.02 epochs/s, Training Loss=1.56e-5, Validation Loss=1.61e-5, Best Loss=1.46e-5]
Training Fold 2:  51%|█████     | 51/100 [00:24&lt;00:24,  2.01 epochs/s, Training Loss=1.56e-5, Validation Loss=1.61e-5, Best Loss=1.46e-5]
Training Fold 2:  51%|█████     | 51/100 [00:25&lt;00:24,  2.01 epochs/s, Training Loss=1.77e-5, Validation Loss=1.8e-5, Best Loss=1.46e-5]
Training Fold 2:  52%|█████▏    | 52/100 [00:25&lt;00:23,  2.04 epochs/s, Training Loss=1.77e-5, Validation Loss=1.8e-5, Best Loss=1.46e-5]
Training Fold 2:  52%|█████▏    | 52/100 [00:25&lt;00:23,  2.04 epochs/s, Training Loss=1.55e-5, Validation Loss=1.62e-5, Best Loss=1.46e-5]
Training Fold 2:  53%|█████▎    | 53/100 [00:25&lt;00:23,  1.99 epochs/s, Training Loss=1.55e-5, Validation Loss=1.62e-5, Best Loss=1.46e-5]
Training Fold 2:  53%|█████▎    | 53/100 [00:26&lt;00:23,  1.99 epochs/s, Training Loss=1.63e-5, Validation Loss=1.67e-5, Best Loss=1.46e-5]
Training Fold 2:  54%|█████▍    | 54/100 [00:26&lt;00:22,  2.01 epochs/s, Training Loss=1.63e-5, Validation Loss=1.67e-5, Best Loss=1.46e-5]
Training Fold 2:  54%|█████▍    | 54/100 [00:26&lt;00:22,  2.01 epochs/s, Training Loss=1.59e-5, Validation Loss=1.6e-5, Best Loss=1.46e-5]
Training Fold 2:  55%|█████▌    | 55/100 [00:26&lt;00:22,  2.05 epochs/s, Training Loss=1.59e-5, Validation Loss=1.6e-5, Best Loss=1.46e-5]
Training Fold 2:  55%|█████▌    | 55/100 [00:27&lt;00:22,  2.05 epochs/s, Training Loss=1.6e-5, Validation Loss=1.66e-5, Best Loss=1.46e-5]
Training Fold 2:  56%|█████▌    | 56/100 [00:27&lt;00:21,  2.07 epochs/s, Training Loss=1.6e-5, Validation Loss=1.66e-5, Best Loss=1.46e-5]
Training Fold 2:  56%|█████▌    | 56/100 [00:27&lt;00:21,  2.07 epochs/s, Training Loss=1.47e-5, Validation Loss=1.49e-5, Best Loss=1.46e-5]
Training Fold 2:  57%|█████▋    | 57/100 [00:27&lt;00:20,  2.05 epochs/s, Training Loss=1.47e-5, Validation Loss=1.49e-5, Best Loss=1.46e-5]
Training Fold 2:  57%|█████▋    | 57/100 [00:28&lt;00:20,  2.05 epochs/s, Training Loss=1.69e-5, Validation Loss=1.86e-5, Best Loss=1.46e-5]
Training Fold 2:  58%|█████▊    | 58/100 [00:28&lt;00:20,  2.06 epochs/s, Training Loss=1.69e-5, Validation Loss=1.86e-5, Best Loss=1.46e-5]
Training Fold 2:  58%|█████▊    | 58/100 [00:28&lt;00:20,  2.06 epochs/s, Training Loss=1.68e-5, Validation Loss=1.77e-5, Best Loss=1.46e-5]
Training Fold 2:  59%|█████▉    | 59/100 [00:28&lt;00:19,  2.05 epochs/s, Training Loss=1.68e-5, Validation Loss=1.77e-5, Best Loss=1.46e-5]
Training Fold 2:  59%|█████▉    | 59/100 [00:29&lt;00:19,  2.05 epochs/s, Training Loss=1.45e-5, Validation Loss=1.52e-5, Best Loss=1.46e-5]
Training Fold 2:  60%|██████    | 60/100 [00:29&lt;00:19,  2.07 epochs/s, Training Loss=1.45e-5, Validation Loss=1.52e-5, Best Loss=1.46e-5]
Training Fold 2:  60%|██████    | 60/100 [00:29&lt;00:19,  2.07 epochs/s, Training Loss=1.61e-5, Validation Loss=1.7e-5, Best Loss=1.46e-5]
Training Fold 2:  61%|██████    | 61/100 [00:29&lt;00:18,  2.07 epochs/s, Training Loss=1.61e-5, Validation Loss=1.7e-5, Best Loss=1.46e-5]
Training Fold 2:  61%|██████    | 61/100 [00:30&lt;00:18,  2.07 epochs/s, Training Loss=1.56e-5, Validation Loss=1.61e-5, Best Loss=1.46e-5]
Training Fold 2:  62%|██████▏   | 62/100 [00:30&lt;00:18,  2.07 epochs/s, Training Loss=1.56e-5, Validation Loss=1.61e-5, Best Loss=1.46e-5]
Training Fold 2:  62%|██████▏   | 62/100 [00:30&lt;00:18,  2.07 epochs/s, Training Loss=1.47e-5, Validation Loss=1.5e-5, Best Loss=1.46e-5]
Training Fold 2:  63%|██████▎   | 63/100 [00:30&lt;00:17,  2.06 epochs/s, Training Loss=1.47e-5, Validation Loss=1.5e-5, Best Loss=1.46e-5]
Training Fold 2:  63%|██████▎   | 63/100 [00:31&lt;00:17,  2.06 epochs/s, Training Loss=1.44e-5, Validation Loss=1.53e-5, Best Loss=1.46e-5]
Training Fold 2:  64%|██████▍   | 64/100 [00:31&lt;00:17,  2.05 epochs/s, Training Loss=1.44e-5, Validation Loss=1.53e-5, Best Loss=1.46e-5]
Training Fold 2:  64%|██████▍   | 64/100 [00:31&lt;00:17,  2.05 epochs/s, Training Loss=1.46e-5, Validation Loss=1.51e-5, Best Loss=1.46e-5]
Training Fold 2:  65%|██████▌   | 65/100 [00:31&lt;00:16,  2.09 epochs/s, Training Loss=1.46e-5, Validation Loss=1.51e-5, Best Loss=1.46e-5]
Training Fold 2:  65%|██████▌   | 65/100 [00:32&lt;00:16,  2.09 epochs/s, Training Loss=1.49e-5, Validation Loss=1.52e-5, Best Loss=1.46e-5]
Training Fold 2:  66%|██████▌   | 66/100 [00:32&lt;00:16,  2.05 epochs/s, Training Loss=1.49e-5, Validation Loss=1.52e-5, Best Loss=1.46e-5]
Training Fold 2:  66%|██████▌   | 66/100 [00:32&lt;00:16,  2.05 epochs/s, Training Loss=1.99e-5, Validation Loss=1.83e-5, Best Loss=1.46e-5]
Training Fold 2:  67%|██████▋   | 67/100 [00:32&lt;00:16,  2.05 epochs/s, Training Loss=1.99e-5, Validation Loss=1.83e-5, Best Loss=1.46e-5]
Training Fold 2:  67%|██████▋   | 67/100 [00:33&lt;00:16,  2.05 epochs/s, Training Loss=1.55e-5, Validation Loss=1.51e-5, Best Loss=1.46e-5]
Training Fold 2:  68%|██████▊   | 68/100 [00:33&lt;00:15,  2.07 epochs/s, Training Loss=1.55e-5, Validation Loss=1.51e-5, Best Loss=1.46e-5]
Training Fold 2:  68%|██████▊   | 68/100 [00:33&lt;00:15,  2.07 epochs/s, Training Loss=1.49e-5, Validation Loss=1.56e-5, Best Loss=1.46e-5]
Training Fold 2:  69%|██████▉   | 69/100 [00:33&lt;00:15,  2.00 epochs/s, Training Loss=1.49e-5, Validation Loss=1.56e-5, Best Loss=1.46e-5]
Training Fold 2:  69%|██████▉   | 69/100 [00:34&lt;00:15,  2.00 epochs/s, Training Loss=1.42e-5, Validation Loss=1.42e-5, Best Loss=1.42e-5]
Training Fold 2:  70%|███████   | 70/100 [00:34&lt;00:14,  2.01 epochs/s, Training Loss=1.42e-5, Validation Loss=1.42e-5, Best Loss=1.42e-5]
Training Fold 2:  70%|███████   | 70/100 [00:34&lt;00:14,  2.01 epochs/s, Training Loss=1.61e-5, Validation Loss=1.7e-5, Best Loss=1.42e-5]
Training Fold 2:  71%|███████   | 71/100 [00:34&lt;00:14,  2.00 epochs/s, Training Loss=1.61e-5, Validation Loss=1.7e-5, Best Loss=1.42e-5]
Training Fold 2:  71%|███████   | 71/100 [00:35&lt;00:14,  2.00 epochs/s, Training Loss=1.51e-5, Validation Loss=1.5e-5, Best Loss=1.42e-5]
Training Fold 2:  72%|███████▏  | 72/100 [00:35&lt;00:14,  1.99 epochs/s, Training Loss=1.51e-5, Validation Loss=1.5e-5, Best Loss=1.42e-5]
Training Fold 2:  72%|███████▏  | 72/100 [00:35&lt;00:14,  1.99 epochs/s, Training Loss=1.47e-5, Validation Loss=1.42e-5, Best Loss=1.42e-5]
Training Fold 2:  73%|███████▎  | 73/100 [00:35&lt;00:13,  1.97 epochs/s, Training Loss=1.47e-5, Validation Loss=1.42e-5, Best Loss=1.42e-5]
Training Fold 2:  73%|███████▎  | 73/100 [00:36&lt;00:13,  1.97 epochs/s, Training Loss=1.39e-5, Validation Loss=1.41e-5, Best Loss=1.41e-5]
Training Fold 2:  74%|███████▍  | 74/100 [00:36&lt;00:13,  1.97 epochs/s, Training Loss=1.39e-5, Validation Loss=1.41e-5, Best Loss=1.41e-5]
Training Fold 2:  74%|███████▍  | 74/100 [00:36&lt;00:13,  1.97 epochs/s, Training Loss=2.03e-5, Validation Loss=2.13e-5, Best Loss=1.41e-5]
Training Fold 2:  75%|███████▌  | 75/100 [00:36&lt;00:13,  1.89 epochs/s, Training Loss=2.03e-5, Validation Loss=2.13e-5, Best Loss=1.41e-5]
Training Fold 2:  75%|███████▌  | 75/100 [00:37&lt;00:13,  1.89 epochs/s, Training Loss=1.62e-5, Validation Loss=1.69e-5, Best Loss=1.41e-5]
Training Fold 2:  76%|███████▌  | 76/100 [00:37&lt;00:12,  1.89 epochs/s, Training Loss=1.62e-5, Validation Loss=1.69e-5, Best Loss=1.41e-5]
Training Fold 2:  76%|███████▌  | 76/100 [00:37&lt;00:12,  1.89 epochs/s, Training Loss=1.61e-5, Validation Loss=1.79e-5, Best Loss=1.41e-5]
Training Fold 2:  77%|███████▋  | 77/100 [00:37&lt;00:11,  1.92 epochs/s, Training Loss=1.61e-5, Validation Loss=1.79e-5, Best Loss=1.41e-5]
Training Fold 2:  77%|███████▋  | 77/100 [00:38&lt;00:11,  1.92 epochs/s, Training Loss=1.5e-5, Validation Loss=1.67e-5, Best Loss=1.41e-5]
Training Fold 2:  78%|███████▊  | 78/100 [00:38&lt;00:11,  1.92 epochs/s, Training Loss=1.5e-5, Validation Loss=1.67e-5, Best Loss=1.41e-5]
Training Fold 2:  78%|███████▊  | 78/100 [00:38&lt;00:11,  1.92 epochs/s, Training Loss=1.48e-5, Validation Loss=1.61e-5, Best Loss=1.41e-5]
Training Fold 2:  79%|███████▉  | 79/100 [00:38&lt;00:10,  1.94 epochs/s, Training Loss=1.48e-5, Validation Loss=1.61e-5, Best Loss=1.41e-5]
Training Fold 2:  79%|███████▉  | 79/100 [00:39&lt;00:10,  1.94 epochs/s, Training Loss=2.05e-5, Validation Loss=2.24e-5, Best Loss=1.41e-5]
Training Fold 2:  80%|████████  | 80/100 [00:39&lt;00:10,  1.96 epochs/s, Training Loss=2.05e-5, Validation Loss=2.24e-5, Best Loss=1.41e-5]
Training Fold 2:  80%|████████  | 80/100 [00:39&lt;00:10,  1.96 epochs/s, Training Loss=1.44e-5, Validation Loss=1.55e-5, Best Loss=1.41e-5]
Training Fold 2:  81%|████████  | 81/100 [00:39&lt;00:09,  1.97 epochs/s, Training Loss=1.44e-5, Validation Loss=1.55e-5, Best Loss=1.41e-5]
Training Fold 2:  81%|████████  | 81/100 [00:40&lt;00:09,  1.97 epochs/s, Training Loss=1.39e-5, Validation Loss=1.47e-5, Best Loss=1.41e-5]
Training Fold 2:  82%|████████▏ | 82/100 [00:40&lt;00:09,  2.00 epochs/s, Training Loss=1.39e-5, Validation Loss=1.47e-5, Best Loss=1.41e-5]
Training Fold 2:  82%|████████▏ | 82/100 [00:40&lt;00:09,  2.00 epochs/s, Training Loss=1.87e-5, Validation Loss=2.34e-5, Best Loss=1.41e-5]
Training Fold 2:  83%|████████▎ | 83/100 [00:40&lt;00:08,  2.00 epochs/s, Training Loss=1.87e-5, Validation Loss=2.34e-5, Best Loss=1.41e-5]
Training Fold 2:  83%|████████▎ | 83/100 [00:41&lt;00:08,  2.00 epochs/s, Training Loss=1.4e-5, Validation Loss=1.49e-5, Best Loss=1.41e-5]
Training Fold 2:  84%|████████▍ | 84/100 [00:41&lt;00:07,  2.01 epochs/s, Training Loss=1.4e-5, Validation Loss=1.49e-5, Best Loss=1.41e-5]
Training Fold 2:  84%|████████▍ | 84/100 [00:41&lt;00:07,  2.01 epochs/s, Training Loss=1.41e-5, Validation Loss=1.57e-5, Best Loss=1.41e-5]
Training Fold 2:  85%|████████▌ | 85/100 [00:41&lt;00:07,  2.03 epochs/s, Training Loss=1.41e-5, Validation Loss=1.57e-5, Best Loss=1.41e-5]
Training Fold 2:  85%|████████▌ | 85/100 [00:42&lt;00:07,  2.03 epochs/s, Training Loss=1.39e-5, Validation Loss=1.45e-5, Best Loss=1.41e-5]
Training Fold 2:  86%|████████▌ | 86/100 [00:42&lt;00:06,  2.03 epochs/s, Training Loss=1.39e-5, Validation Loss=1.45e-5, Best Loss=1.41e-5]
Training Fold 2:  86%|████████▌ | 86/100 [00:42&lt;00:06,  2.03 epochs/s, Training Loss=1.34e-5, Validation Loss=1.42e-5, Best Loss=1.41e-5]
Training Fold 2:  87%|████████▋ | 87/100 [00:42&lt;00:06,  2.01 epochs/s, Training Loss=1.34e-5, Validation Loss=1.42e-5, Best Loss=1.41e-5]
Training Fold 2:  87%|████████▋ | 87/100 [00:43&lt;00:06,  2.01 epochs/s, Training Loss=1.47e-5, Validation Loss=1.69e-5, Best Loss=1.41e-5]
Training Fold 2:  88%|████████▊ | 88/100 [00:43&lt;00:05,  2.06 epochs/s, Training Loss=1.47e-5, Validation Loss=1.69e-5, Best Loss=1.41e-5]
Training Fold 2:  88%|████████▊ | 88/100 [00:43&lt;00:05,  2.06 epochs/s, Training Loss=1.76e-5, Validation Loss=1.98e-5, Best Loss=1.41e-5]
Training Fold 2:  89%|████████▉ | 89/100 [00:43&lt;00:05,  2.05 epochs/s, Training Loss=1.76e-5, Validation Loss=1.98e-5, Best Loss=1.41e-5]
Training Fold 2:  89%|████████▉ | 89/100 [00:44&lt;00:05,  2.05 epochs/s, Training Loss=1.39e-5, Validation Loss=1.46e-5, Best Loss=1.41e-5]
Training Fold 2:  90%|█████████ | 90/100 [00:44&lt;00:04,  2.06 epochs/s, Training Loss=1.39e-5, Validation Loss=1.46e-5, Best Loss=1.41e-5]
Training Fold 2:  90%|█████████ | 90/100 [00:44&lt;00:04,  2.06 epochs/s, Training Loss=1.69e-5, Validation Loss=1.89e-5, Best Loss=1.41e-5]
Training Fold 2:  91%|█████████ | 91/100 [00:44&lt;00:04,  2.08 epochs/s, Training Loss=1.69e-5, Validation Loss=1.89e-5, Best Loss=1.41e-5]
Training Fold 2:  91%|█████████ | 91/100 [00:45&lt;00:04,  2.08 epochs/s, Training Loss=1.34e-5, Validation Loss=1.43e-5, Best Loss=1.41e-5]
Training Fold 2:  92%|█████████▏| 92/100 [00:45&lt;00:03,  2.09 epochs/s, Training Loss=1.34e-5, Validation Loss=1.43e-5, Best Loss=1.41e-5]
Training Fold 2:  92%|█████████▏| 92/100 [00:45&lt;00:03,  2.09 epochs/s, Training Loss=1.4e-5, Validation Loss=1.51e-5, Best Loss=1.41e-5]
Training Fold 2:  93%|█████████▎| 93/100 [00:45&lt;00:03,  2.07 epochs/s, Training Loss=1.4e-5, Validation Loss=1.51e-5, Best Loss=1.41e-5]
Training Fold 2:  93%|█████████▎| 93/100 [00:46&lt;00:03,  2.07 epochs/s, Training Loss=1.43e-5, Validation Loss=1.53e-5, Best Loss=1.41e-5]
Training Fold 2:  94%|█████████▍| 94/100 [00:46&lt;00:02,  2.09 epochs/s, Training Loss=1.43e-5, Validation Loss=1.53e-5, Best Loss=1.41e-5]
Training Fold 2:  94%|█████████▍| 94/100 [00:46&lt;00:02,  2.09 epochs/s, Training Loss=1.38e-5, Validation Loss=1.54e-5, Best Loss=1.41e-5]
Training Fold 2:  95%|█████████▌| 95/100 [00:46&lt;00:02,  2.07 epochs/s, Training Loss=1.38e-5, Validation Loss=1.54e-5, Best Loss=1.41e-5]
Training Fold 2:  95%|█████████▌| 95/100 [00:47&lt;00:02,  2.07 epochs/s, Training Loss=1.52e-5, Validation Loss=1.62e-5, Best Loss=1.41e-5]
Training Fold 2:  96%|█████████▌| 96/100 [00:47&lt;00:01,  2.05 epochs/s, Training Loss=1.52e-5, Validation Loss=1.62e-5, Best Loss=1.41e-5]
Training Fold 2:  96%|█████████▌| 96/100 [00:47&lt;00:01,  2.05 epochs/s, Training Loss=1.32e-5, Validation Loss=1.47e-5, Best Loss=1.41e-5]
Training Fold 2:  97%|█████████▋| 97/100 [00:47&lt;00:01,  2.10 epochs/s, Training Loss=1.32e-5, Validation Loss=1.47e-5, Best Loss=1.41e-5]
Training Fold 2:  97%|█████████▋| 97/100 [00:48&lt;00:01,  2.10 epochs/s, Training Loss=1.43e-5, Validation Loss=1.47e-5, Best Loss=1.41e-5]
Training Fold 2:  98%|█████████▊| 98/100 [00:48&lt;00:00,  2.11 epochs/s, Training Loss=1.43e-5, Validation Loss=1.47e-5, Best Loss=1.41e-5]
Training Fold 2:  98%|█████████▊| 98/100 [00:48&lt;00:00,  2.11 epochs/s, Training Loss=1.3e-5, Validation Loss=1.51e-5, Best Loss=1.41e-5]
Training Fold 2:  99%|█████████▉| 99/100 [00:48&lt;00:00,  2.10 epochs/s, Training Loss=1.3e-5, Validation Loss=1.51e-5, Best Loss=1.41e-5]
Training Fold 2:  99%|█████████▉| 99/100 [00:49&lt;00:00,  2.10 epochs/s, Training Loss=1.37e-5, Validation Loss=1.54e-5, Best Loss=1.41e-5]
Training Fold 2: 100%|██████████| 100/100 [00:49&lt;00:00,  2.05 epochs/s, Training Loss=1.37e-5, Validation Loss=1.54e-5, Best Loss=1.41e-5]
Training Fold 2: 100%|██████████| 100/100 [00:49&lt;00:00,  2.04 epochs/s, Training Loss=1.37e-5, Validation Loss=1.54e-5, Best Loss=1.41e-5]

  0%|          | 0/100 [00:00&lt;?, ? epochs/s]
Training Fold 3:   0%|          | 0/100 [00:00&lt;?, ? epochs/s]
Training Fold 3:   0%|          | 0/100 [00:00&lt;?, ? epochs/s, Training Loss=1.42e-5, Validation Loss=1.1e-5, Best Loss=1.1e-5]
Training Fold 3:   1%|          | 1/100 [00:00&lt;00:46,  2.15 epochs/s, Training Loss=1.42e-5, Validation Loss=1.1e-5, Best Loss=1.1e-5]
Training Fold 3:   1%|          | 1/100 [00:00&lt;00:46,  2.15 epochs/s, Training Loss=1.5e-5, Validation Loss=1.17e-5, Best Loss=1.1e-5]
Training Fold 3:   2%|▏         | 2/100 [00:00&lt;00:45,  2.17 epochs/s, Training Loss=1.5e-5, Validation Loss=1.17e-5, Best Loss=1.1e-5]
Training Fold 3:   2%|▏         | 2/100 [00:01&lt;00:45,  2.17 epochs/s, Training Loss=1.49e-5, Validation Loss=1.16e-5, Best Loss=1.1e-5]
Training Fold 3:   3%|▎         | 3/100 [00:01&lt;00:44,  2.16 epochs/s, Training Loss=1.49e-5, Validation Loss=1.16e-5, Best Loss=1.1e-5]
Training Fold 3:   3%|▎         | 3/100 [00:01&lt;00:44,  2.16 epochs/s, Training Loss=1.36e-5, Validation Loss=1.01e-5, Best Loss=1.01e-5]
Training Fold 3:   4%|▍         | 4/100 [00:01&lt;00:45,  2.12 epochs/s, Training Loss=1.36e-5, Validation Loss=1.01e-5, Best Loss=1.01e-5]
Training Fold 3:   4%|▍         | 4/100 [00:02&lt;00:45,  2.12 epochs/s, Training Loss=1.4e-5, Validation Loss=1.07e-5, Best Loss=1.01e-5]
Training Fold 3:   5%|▌         | 5/100 [00:02&lt;00:44,  2.14 epochs/s, Training Loss=1.4e-5, Validation Loss=1.07e-5, Best Loss=1.01e-5]
Training Fold 3:   5%|▌         | 5/100 [00:02&lt;00:44,  2.14 epochs/s, Training Loss=1.44e-5, Validation Loss=1.19e-5, Best Loss=1.01e-5]
Training Fold 3:   6%|▌         | 6/100 [00:02&lt;00:47,  1.99 epochs/s, Training Loss=1.44e-5, Validation Loss=1.19e-5, Best Loss=1.01e-5]
Training Fold 3:   6%|▌         | 6/100 [00:03&lt;00:47,  1.99 epochs/s, Training Loss=1.56e-5, Validation Loss=1.38e-5, Best Loss=1.01e-5]
Training Fold 3:   7%|▋         | 7/100 [00:03&lt;00:48,  1.94 epochs/s, Training Loss=1.56e-5, Validation Loss=1.38e-5, Best Loss=1.01e-5]
Training Fold 3:   7%|▋         | 7/100 [00:03&lt;00:48,  1.94 epochs/s, Training Loss=1.58e-5, Validation Loss=1.37e-5, Best Loss=1.01e-5]
Training Fold 3:   8%|▊         | 8/100 [00:03&lt;00:47,  1.93 epochs/s, Training Loss=1.58e-5, Validation Loss=1.37e-5, Best Loss=1.01e-5]
Training Fold 3:   8%|▊         | 8/100 [00:04&lt;00:47,  1.93 epochs/s, Training Loss=1.44e-5, Validation Loss=1.25e-5, Best Loss=1.01e-5]
Training Fold 3:   9%|▉         | 9/100 [00:04&lt;00:49,  1.85 epochs/s, Training Loss=1.44e-5, Validation Loss=1.25e-5, Best Loss=1.01e-5]
Training Fold 3:   9%|▉         | 9/100 [00:05&lt;00:49,  1.85 epochs/s, Training Loss=1.33e-5, Validation Loss=1.1e-5, Best Loss=1.01e-5]
Training Fold 3:  10%|█         | 10/100 [00:05&lt;00:47,  1.88 epochs/s, Training Loss=1.33e-5, Validation Loss=1.1e-5, Best Loss=1.01e-5]
Training Fold 3:  10%|█         | 10/100 [00:05&lt;00:47,  1.88 epochs/s, Training Loss=1.53e-5, Validation Loss=1.36e-5, Best Loss=1.01e-5]
Training Fold 3:  11%|█         | 11/100 [00:05&lt;00:46,  1.93 epochs/s, Training Loss=1.53e-5, Validation Loss=1.36e-5, Best Loss=1.01e-5]
Training Fold 3:  11%|█         | 11/100 [00:06&lt;00:46,  1.93 epochs/s, Training Loss=2.35e-5, Validation Loss=2.19e-5, Best Loss=1.01e-5]
Training Fold 3:  12%|█▏        | 12/100 [00:06&lt;00:44,  1.97 epochs/s, Training Loss=2.35e-5, Validation Loss=2.19e-5, Best Loss=1.01e-5]
Training Fold 3:  12%|█▏        | 12/100 [00:06&lt;00:44,  1.97 epochs/s, Training Loss=2.2e-5, Validation Loss=2.32e-5, Best Loss=1.01e-5]
Training Fold 3:  13%|█▎        | 13/100 [00:06&lt;00:43,  2.00 epochs/s, Training Loss=2.2e-5, Validation Loss=2.32e-5, Best Loss=1.01e-5]
Training Fold 3:  13%|█▎        | 13/100 [00:06&lt;00:43,  2.00 epochs/s, Training Loss=1.36e-5, Validation Loss=1.12e-5, Best Loss=1.01e-5]
Training Fold 3:  14%|█▍        | 14/100 [00:06&lt;00:42,  2.03 epochs/s, Training Loss=1.36e-5, Validation Loss=1.12e-5, Best Loss=1.01e-5]
Training Fold 3:  14%|█▍        | 14/100 [00:07&lt;00:42,  2.03 epochs/s, Training Loss=1.34e-5, Validation Loss=1.07e-5, Best Loss=1.01e-5]
Training Fold 3:  15%|█▌        | 15/100 [00:07&lt;00:41,  2.05 epochs/s, Training Loss=1.34e-5, Validation Loss=1.07e-5, Best Loss=1.01e-5]
Training Fold 3:  15%|█▌        | 15/100 [00:08&lt;00:41,  2.05 epochs/s, Training Loss=1.38e-5, Validation Loss=1.31e-5, Best Loss=1.01e-5]
Training Fold 3:  16%|█▌        | 16/100 [00:08&lt;00:42,  1.99 epochs/s, Training Loss=1.38e-5, Validation Loss=1.31e-5, Best Loss=1.01e-5]
Training Fold 3:  16%|█▌        | 16/100 [00:08&lt;00:42,  1.99 epochs/s, Training Loss=1.43e-5, Validation Loss=1.43e-5, Best Loss=1.01e-5]
Training Fold 3:  17%|█▋        | 17/100 [00:08&lt;00:41,  2.01 epochs/s, Training Loss=1.43e-5, Validation Loss=1.43e-5, Best Loss=1.01e-5]
Training Fold 3:  17%|█▋        | 17/100 [00:08&lt;00:41,  2.01 epochs/s, Training Loss=1.44e-5, Validation Loss=1.22e-5, Best Loss=1.01e-5]
Training Fold 3:  18%|█▊        | 18/100 [00:08&lt;00:40,  2.02 epochs/s, Training Loss=1.44e-5, Validation Loss=1.22e-5, Best Loss=1.01e-5]
Training Fold 3:  18%|█▊        | 18/100 [00:09&lt;00:40,  2.02 epochs/s, Training Loss=1.41e-5, Validation Loss=1.2e-5, Best Loss=1.01e-5]
Training Fold 3:  19%|█▉        | 19/100 [00:09&lt;00:39,  2.04 epochs/s, Training Loss=1.41e-5, Validation Loss=1.2e-5, Best Loss=1.01e-5]
Training Fold 3:  19%|█▉        | 19/100 [00:09&lt;00:39,  2.04 epochs/s, Training Loss=1.36e-5, Validation Loss=1.2e-5, Best Loss=1.01e-5]
Training Fold 3:  20%|██        | 20/100 [00:09&lt;00:40,  2.00 epochs/s, Training Loss=1.36e-5, Validation Loss=1.2e-5, Best Loss=1.01e-5]
Training Fold 3:  20%|██        | 20/100 [00:10&lt;00:40,  2.00 epochs/s, Training Loss=1.64e-5, Validation Loss=1.34e-5, Best Loss=1.01e-5]
Training Fold 3:  21%|██        | 21/100 [00:10&lt;00:39,  2.03 epochs/s, Training Loss=1.64e-5, Validation Loss=1.34e-5, Best Loss=1.01e-5]
Training Fold 3:  21%|██        | 21/100 [00:10&lt;00:39,  2.03 epochs/s, Training Loss=1.3e-5, Validation Loss=1.12e-5, Best Loss=1.01e-5]
Training Fold 3:  22%|██▏       | 22/100 [00:10&lt;00:38,  2.03 epochs/s, Training Loss=1.3e-5, Validation Loss=1.12e-5, Best Loss=1.01e-5]
Training Fold 3:  22%|██▏       | 22/100 [00:11&lt;00:38,  2.03 epochs/s, Training Loss=1.72e-5, Validation Loss=1.67e-5, Best Loss=1.01e-5]
Training Fold 3:  23%|██▎       | 23/100 [00:11&lt;00:38,  2.02 epochs/s, Training Loss=1.72e-5, Validation Loss=1.67e-5, Best Loss=1.01e-5]
Training Fold 3:  23%|██▎       | 23/100 [00:11&lt;00:38,  2.02 epochs/s, Training Loss=1.41e-5, Validation Loss=1.35e-5, Best Loss=1.01e-5]
Training Fold 3:  24%|██▍       | 24/100 [00:11&lt;00:37,  2.04 epochs/s, Training Loss=1.41e-5, Validation Loss=1.35e-5, Best Loss=1.01e-5]
Training Fold 3:  24%|██▍       | 24/100 [00:12&lt;00:37,  2.04 epochs/s, Training Loss=1.49e-5, Validation Loss=1.31e-5, Best Loss=1.01e-5]
Training Fold 3:  25%|██▌       | 25/100 [00:12&lt;00:36,  2.07 epochs/s, Training Loss=1.49e-5, Validation Loss=1.31e-5, Best Loss=1.01e-5]
Training Fold 3:  25%|██▌       | 25/100 [00:12&lt;00:36,  2.07 epochs/s, Training Loss=1.37e-5, Validation Loss=1.19e-5, Best Loss=1.01e-5]
Training Fold 3:  26%|██▌       | 26/100 [00:12&lt;00:36,  2.04 epochs/s, Training Loss=1.37e-5, Validation Loss=1.19e-5, Best Loss=1.01e-5]
Training Fold 3:  26%|██▌       | 26/100 [00:13&lt;00:36,  2.04 epochs/s, Training Loss=1.5e-5, Validation Loss=1.34e-5, Best Loss=1.01e-5]
Training Fold 3:  27%|██▋       | 27/100 [00:13&lt;00:36,  2.02 epochs/s, Training Loss=1.5e-5, Validation Loss=1.34e-5, Best Loss=1.01e-5]
Training Fold 3:  27%|██▋       | 27/100 [00:13&lt;00:36,  2.02 epochs/s, Training Loss=1.32e-5, Validation Loss=1.09e-5, Best Loss=1.01e-5]
Training Fold 3:  28%|██▊       | 28/100 [00:13&lt;00:35,  2.04 epochs/s, Training Loss=1.32e-5, Validation Loss=1.09e-5, Best Loss=1.01e-5]
Training Fold 3:  28%|██▊       | 28/100 [00:14&lt;00:35,  2.04 epochs/s, Training Loss=1.75e-5, Validation Loss=1.74e-5, Best Loss=1.01e-5]
Training Fold 3:  29%|██▉       | 29/100 [00:14&lt;00:35,  2.00 epochs/s, Training Loss=1.75e-5, Validation Loss=1.74e-5, Best Loss=1.01e-5]
Training Fold 3:  29%|██▉       | 29/100 [00:14&lt;00:35,  2.00 epochs/s, Training Loss=1.31e-5, Validation Loss=1.21e-5, Best Loss=1.01e-5]
Training Fold 3:  30%|███       | 30/100 [00:14&lt;00:34,  2.06 epochs/s, Training Loss=1.31e-5, Validation Loss=1.21e-5, Best Loss=1.01e-5]
Training Fold 3:  30%|███       | 30/100 [00:15&lt;00:34,  2.06 epochs/s, Training Loss=1.22e-5, Validation Loss=1.18e-5, Best Loss=1.01e-5]
Training Fold 3:  31%|███       | 31/100 [00:15&lt;00:33,  2.07 epochs/s, Training Loss=1.22e-5, Validation Loss=1.18e-5, Best Loss=1.01e-5]
Training Fold 3:  31%|███       | 31/100 [00:15&lt;00:33,  2.07 epochs/s, Training Loss=1.26e-5, Validation Loss=1.13e-5, Best Loss=1.01e-5]
Training Fold 3:  32%|███▏      | 32/100 [00:15&lt;00:33,  2.03 epochs/s, Training Loss=1.26e-5, Validation Loss=1.13e-5, Best Loss=1.01e-5]
Training Fold 3:  32%|███▏      | 32/100 [00:16&lt;00:33,  2.03 epochs/s, Training Loss=2.07e-5, Validation Loss=2.22e-5, Best Loss=1.01e-5]
Training Fold 3:  33%|███▎      | 33/100 [00:16&lt;00:33,  2.01 epochs/s, Training Loss=2.07e-5, Validation Loss=2.22e-5, Best Loss=1.01e-5]
Training Fold 3:  33%|███▎      | 33/100 [00:16&lt;00:33,  2.01 epochs/s, Training Loss=3.14e-5, Validation Loss=2.82e-5, Best Loss=1.01e-5]
Training Fold 3:  34%|███▍      | 34/100 [00:16&lt;00:32,  2.03 epochs/s, Training Loss=3.14e-5, Validation Loss=2.82e-5, Best Loss=1.01e-5]
Training Fold 3:  34%|███▍      | 34/100 [00:17&lt;00:32,  2.03 epochs/s, Training Loss=1.48e-5, Validation Loss=1.47e-5, Best Loss=1.01e-5]
Training Fold 3:  35%|███▌      | 35/100 [00:17&lt;00:31,  2.06 epochs/s, Training Loss=1.48e-5, Validation Loss=1.47e-5, Best Loss=1.01e-5]
Training Fold 3:  35%|███▌      | 35/100 [00:17&lt;00:31,  2.06 epochs/s, Training Loss=1.34e-5, Validation Loss=1.33e-5, Best Loss=1.01e-5]
Training Fold 3:  36%|███▌      | 36/100 [00:17&lt;00:31,  2.04 epochs/s, Training Loss=1.34e-5, Validation Loss=1.33e-5, Best Loss=1.01e-5]
Training Fold 3:  36%|███▌      | 36/100 [00:18&lt;00:31,  2.04 epochs/s, Training Loss=1.45e-5, Validation Loss=1.29e-5, Best Loss=1.01e-5]
Training Fold 3:  37%|███▋      | 37/100 [00:18&lt;00:30,  2.06 epochs/s, Training Loss=1.45e-5, Validation Loss=1.29e-5, Best Loss=1.01e-5]
Training Fold 3:  37%|███▋      | 37/100 [00:18&lt;00:30,  2.06 epochs/s, Training Loss=1.26e-5, Validation Loss=1.13e-5, Best Loss=1.01e-5]
Training Fold 3:  38%|███▊      | 38/100 [00:18&lt;00:30,  2.03 epochs/s, Training Loss=1.26e-5, Validation Loss=1.13e-5, Best Loss=1.01e-5]
Training Fold 3:  38%|███▊      | 38/100 [00:19&lt;00:30,  2.03 epochs/s, Training Loss=1.3e-5, Validation Loss=1.15e-5, Best Loss=1.01e-5]
Training Fold 3:  39%|███▉      | 39/100 [00:19&lt;00:30,  2.03 epochs/s, Training Loss=1.3e-5, Validation Loss=1.15e-5, Best Loss=1.01e-5]
Training Fold 3:  39%|███▉      | 39/100 [00:19&lt;00:30,  2.03 epochs/s, Training Loss=1.47e-5, Validation Loss=1.6e-5, Best Loss=1.01e-5]
Training Fold 3:  40%|████      | 40/100 [00:19&lt;00:29,  2.04 epochs/s, Training Loss=1.47e-5, Validation Loss=1.6e-5, Best Loss=1.01e-5]
Training Fold 3:  40%|████      | 40/100 [00:20&lt;00:29,  2.04 epochs/s, Training Loss=1.51e-5, Validation Loss=1.29e-5, Best Loss=1.01e-5]
Training Fold 3:  41%|████      | 41/100 [00:20&lt;00:29,  2.03 epochs/s, Training Loss=1.51e-5, Validation Loss=1.29e-5, Best Loss=1.01e-5]
Training Fold 3:  41%|████      | 41/100 [00:20&lt;00:29,  2.03 epochs/s, Training Loss=1.38e-5, Validation Loss=1.44e-5, Best Loss=1.01e-5]
Training Fold 3:  42%|████▏     | 42/100 [00:20&lt;00:29,  1.98 epochs/s, Training Loss=1.38e-5, Validation Loss=1.44e-5, Best Loss=1.01e-5]
Training Fold 3:  42%|████▏     | 42/100 [00:21&lt;00:29,  1.98 epochs/s, Training Loss=1.46e-5, Validation Loss=1.33e-5, Best Loss=1.01e-5]
Training Fold 3:  43%|████▎     | 43/100 [00:21&lt;00:28,  2.02 epochs/s, Training Loss=1.46e-5, Validation Loss=1.33e-5, Best Loss=1.01e-5]
Training Fold 3:  43%|████▎     | 43/100 [00:21&lt;00:28,  2.02 epochs/s, Training Loss=1.32e-5, Validation Loss=1.19e-5, Best Loss=1.01e-5]
Training Fold 3:  44%|████▍     | 44/100 [00:21&lt;00:27,  2.02 epochs/s, Training Loss=1.32e-5, Validation Loss=1.19e-5, Best Loss=1.01e-5]
Training Fold 3:  44%|████▍     | 44/100 [00:22&lt;00:27,  2.02 epochs/s, Training Loss=1.37e-5, Validation Loss=1.38e-5, Best Loss=1.01e-5]
Training Fold 3:  45%|████▌     | 45/100 [00:22&lt;00:27,  2.03 epochs/s, Training Loss=1.37e-5, Validation Loss=1.38e-5, Best Loss=1.01e-5]
Training Fold 3:  45%|████▌     | 45/100 [00:22&lt;00:27,  2.03 epochs/s, Training Loss=1.43e-5, Validation Loss=1.34e-5, Best Loss=1.01e-5]
Training Fold 3:  46%|████▌     | 46/100 [00:22&lt;00:28,  1.92 epochs/s, Training Loss=1.43e-5, Validation Loss=1.34e-5, Best Loss=1.01e-5]
Training Fold 3:  46%|████▌     | 46/100 [00:23&lt;00:28,  1.92 epochs/s, Training Loss=1.3e-5, Validation Loss=1.27e-5, Best Loss=1.01e-5]
Training Fold 3:  47%|████▋     | 47/100 [00:23&lt;00:27,  1.92 epochs/s, Training Loss=1.3e-5, Validation Loss=1.27e-5, Best Loss=1.01e-5]
Training Fold 3:  47%|████▋     | 47/100 [00:23&lt;00:27,  1.92 epochs/s, Training Loss=1.29e-5, Validation Loss=1.25e-5, Best Loss=1.01e-5]
Training Fold 3:  48%|████▊     | 48/100 [00:23&lt;00:27,  1.92 epochs/s, Training Loss=1.29e-5, Validation Loss=1.25e-5, Best Loss=1.01e-5]
Training Fold 3:  48%|████▊     | 48/100 [00:24&lt;00:27,  1.92 epochs/s, Training Loss=1.35e-5, Validation Loss=1.32e-5, Best Loss=1.01e-5]
Training Fold 3:  49%|████▉     | 49/100 [00:24&lt;00:26,  1.93 epochs/s, Training Loss=1.35e-5, Validation Loss=1.32e-5, Best Loss=1.01e-5]
Training Fold 3:  49%|████▉     | 49/100 [00:24&lt;00:26,  1.93 epochs/s, Training Loss=1.27e-5, Validation Loss=1.38e-5, Best Loss=1.01e-5]
Training Fold 3:  50%|█████     | 50/100 [00:24&lt;00:25,  1.93 epochs/s, Training Loss=1.27e-5, Validation Loss=1.38e-5, Best Loss=1.01e-5]
Training Fold 3:  50%|█████     | 50/100 [00:25&lt;00:25,  1.93 epochs/s, Training Loss=1.2e-5, Validation Loss=1.09e-5, Best Loss=1.01e-5]
Training Fold 3:  51%|█████     | 51/100 [00:25&lt;00:25,  1.89 epochs/s, Training Loss=1.2e-5, Validation Loss=1.09e-5, Best Loss=1.01e-5]
Training Fold 3:  51%|█████     | 51/100 [00:25&lt;00:25,  1.89 epochs/s, Training Loss=1.35e-5, Validation Loss=1.26e-5, Best Loss=1.01e-5]
Training Fold 3:  52%|█████▏    | 52/100 [00:25&lt;00:24,  1.94 epochs/s, Training Loss=1.35e-5, Validation Loss=1.26e-5, Best Loss=1.01e-5]
Training Fold 3:  52%|█████▏    | 52/100 [00:26&lt;00:24,  1.94 epochs/s, Training Loss=1.29e-5, Validation Loss=1.4e-5, Best Loss=1.01e-5]
Training Fold 3:  53%|█████▎    | 53/100 [00:26&lt;00:23,  1.97 epochs/s, Training Loss=1.29e-5, Validation Loss=1.4e-5, Best Loss=1.01e-5]
Training Fold 3:  53%|█████▎    | 53/100 [00:26&lt;00:23,  1.97 epochs/s, Training Loss=1.61e-5, Validation Loss=1.71e-5, Best Loss=1.01e-5]
Training Fold 3:  54%|█████▍    | 54/100 [00:26&lt;00:23,  1.94 epochs/s, Training Loss=1.61e-5, Validation Loss=1.71e-5, Best Loss=1.01e-5]
Training Fold 3:  54%|█████▍    | 54/100 [00:27&lt;00:23,  1.94 epochs/s, Training Loss=1.33e-5, Validation Loss=1.28e-5, Best Loss=1.01e-5]
Training Fold 3:  55%|█████▌    | 55/100 [00:27&lt;00:22,  2.00 epochs/s, Training Loss=1.33e-5, Validation Loss=1.28e-5, Best Loss=1.01e-5]
Training Fold 3:  55%|█████▌    | 55/100 [00:27&lt;00:22,  2.00 epochs/s, Training Loss=2.01e-5, Validation Loss=1.62e-5, Best Loss=1.01e-5]
Training Fold 3:  56%|█████▌    | 56/100 [00:27&lt;00:21,  2.00 epochs/s, Training Loss=2.01e-5, Validation Loss=1.62e-5, Best Loss=1.01e-5]
Training Fold 3:  56%|█████▌    | 56/100 [00:28&lt;00:21,  2.00 epochs/s, Training Loss=1.38e-5, Validation Loss=1.37e-5, Best Loss=1.01e-5]
Training Fold 3:  57%|█████▋    | 57/100 [00:28&lt;00:21,  2.02 epochs/s, Training Loss=1.38e-5, Validation Loss=1.37e-5, Best Loss=1.01e-5]
Training Fold 3:  57%|█████▋    | 57/100 [00:28&lt;00:21,  2.02 epochs/s, Training Loss=1.19e-5, Validation Loss=1.12e-5, Best Loss=1.01e-5]
Training Fold 3:  58%|█████▊    | 58/100 [00:28&lt;00:20,  2.01 epochs/s, Training Loss=1.19e-5, Validation Loss=1.12e-5, Best Loss=1.01e-5]
Training Fold 3:  58%|█████▊    | 58/100 [00:29&lt;00:20,  2.01 epochs/s, Training Loss=1.38e-5, Validation Loss=1.56e-5, Best Loss=1.01e-5]
Training Fold 3:  59%|█████▉    | 59/100 [00:29&lt;00:20,  2.03 epochs/s, Training Loss=1.38e-5, Validation Loss=1.56e-5, Best Loss=1.01e-5]
Training Fold 3:  59%|█████▉    | 59/100 [00:29&lt;00:20,  2.03 epochs/s, Training Loss=1.11e-5, Validation Loss=1.08e-5, Best Loss=1.01e-5]
Training Fold 3:  60%|██████    | 60/100 [00:29&lt;00:19,  2.03 epochs/s, Training Loss=1.11e-5, Validation Loss=1.08e-5, Best Loss=1.01e-5]
Training Fold 3:  60%|██████    | 60/100 [00:30&lt;00:19,  2.03 epochs/s, Training Loss=1.27e-5, Validation Loss=1.36e-5, Best Loss=1.01e-5]
Training Fold 3:  61%|██████    | 61/100 [00:30&lt;00:18,  2.05 epochs/s, Training Loss=1.27e-5, Validation Loss=1.36e-5, Best Loss=1.01e-5]
Training Fold 3:  61%|██████    | 61/100 [00:30&lt;00:18,  2.05 epochs/s, Training Loss=1.35e-5, Validation Loss=1.24e-5, Best Loss=1.01e-5]
Training Fold 3:  62%|██████▏   | 62/100 [00:30&lt;00:18,  2.07 epochs/s, Training Loss=1.35e-5, Validation Loss=1.24e-5, Best Loss=1.01e-5]
Training Fold 3:  62%|██████▏   | 62/100 [00:31&lt;00:18,  2.07 epochs/s, Training Loss=1.4e-5, Validation Loss=1.47e-5, Best Loss=1.01e-5]
Training Fold 3:  63%|██████▎   | 63/100 [00:31&lt;00:17,  2.06 epochs/s, Training Loss=1.4e-5, Validation Loss=1.47e-5, Best Loss=1.01e-5]
Training Fold 3:  63%|██████▎   | 63/100 [00:31&lt;00:17,  2.06 epochs/s, Training Loss=1.23e-5, Validation Loss=1.29e-5, Best Loss=1.01e-5]
Training Fold 3:  64%|██████▍   | 64/100 [00:31&lt;00:17,  2.05 epochs/s, Training Loss=1.23e-5, Validation Loss=1.29e-5, Best Loss=1.01e-5]
Training Fold 3:  64%|██████▍   | 64/100 [00:32&lt;00:17,  2.05 epochs/s, Training Loss=1.23e-5, Validation Loss=1.4e-5, Best Loss=1.01e-5]
Training Fold 3:  65%|██████▌   | 65/100 [00:32&lt;00:17,  2.03 epochs/s, Training Loss=1.23e-5, Validation Loss=1.4e-5, Best Loss=1.01e-5]
Training Fold 3:  65%|██████▌   | 65/100 [00:32&lt;00:17,  2.03 epochs/s, Training Loss=1.23e-5, Validation Loss=1.15e-5, Best Loss=1.01e-5]
Training Fold 3:  66%|██████▌   | 66/100 [00:32&lt;00:17,  2.00 epochs/s, Training Loss=1.23e-5, Validation Loss=1.15e-5, Best Loss=1.01e-5]
Training Fold 3:  66%|██████▌   | 66/100 [00:33&lt;00:17,  2.00 epochs/s, Training Loss=1.15e-5, Validation Loss=1.13e-5, Best Loss=1.01e-5]
Training Fold 3:  67%|██████▋   | 67/100 [00:33&lt;00:16,  2.00 epochs/s, Training Loss=1.15e-5, Validation Loss=1.13e-5, Best Loss=1.01e-5]
Training Fold 3:  67%|██████▋   | 67/100 [00:33&lt;00:16,  2.00 epochs/s, Training Loss=1.11e-5, Validation Loss=1.15e-5, Best Loss=1.01e-5]
Training Fold 3:  68%|██████▊   | 68/100 [00:33&lt;00:15,  2.01 epochs/s, Training Loss=1.11e-5, Validation Loss=1.15e-5, Best Loss=1.01e-5]
Training Fold 3:  68%|██████▊   | 68/100 [00:34&lt;00:15,  2.01 epochs/s, Training Loss=1.27e-5, Validation Loss=1.13e-5, Best Loss=1.01e-5]
Training Fold 3:  69%|██████▉   | 69/100 [00:34&lt;00:15,  2.06 epochs/s, Training Loss=1.27e-5, Validation Loss=1.13e-5, Best Loss=1.01e-5]
Training Fold 3:  69%|██████▉   | 69/100 [00:34&lt;00:15,  2.06 epochs/s, Training Loss=1.11e-5, Validation Loss=1.11e-5, Best Loss=1.01e-5]
Training Fold 3:  70%|███████   | 70/100 [00:34&lt;00:14,  2.05 epochs/s, Training Loss=1.11e-5, Validation Loss=1.11e-5, Best Loss=1.01e-5]
Training Fold 3:  70%|███████   | 70/100 [00:35&lt;00:14,  2.05 epochs/s, Training Loss=1.1e-5, Validation Loss=1.02e-5, Best Loss=1.01e-5]
Training Fold 3:  71%|███████   | 71/100 [00:35&lt;00:14,  2.03 epochs/s, Training Loss=1.1e-5, Validation Loss=1.02e-5, Best Loss=1.01e-5]
Training Fold 3:  71%|███████   | 71/100 [00:35&lt;00:14,  2.03 epochs/s, Training Loss=1.13e-5, Validation Loss=1.08e-5, Best Loss=1.01e-5]
Training Fold 3:  72%|███████▏  | 72/100 [00:35&lt;00:13,  2.02 epochs/s, Training Loss=1.13e-5, Validation Loss=1.08e-5, Best Loss=1.01e-5]
Training Fold 3:  72%|███████▏  | 72/100 [00:36&lt;00:13,  2.02 epochs/s, Training Loss=1.06e-5, Validation Loss=1.07e-5, Best Loss=1.01e-5]
Training Fold 3:  73%|███████▎  | 73/100 [00:36&lt;00:13,  2.04 epochs/s, Training Loss=1.06e-5, Validation Loss=1.07e-5, Best Loss=1.01e-5]
Training Fold 3:  73%|███████▎  | 73/100 [00:36&lt;00:13,  2.04 epochs/s, Training Loss=2.94e-5, Validation Loss=3.03e-5, Best Loss=1.01e-5]
Training Fold 3:  74%|███████▍  | 74/100 [00:36&lt;00:12,  2.00 epochs/s, Training Loss=2.94e-5, Validation Loss=3.03e-5, Best Loss=1.01e-5]
Training Fold 3:  74%|███████▍  | 74/100 [00:37&lt;00:12,  2.00 epochs/s, Training Loss=1.13e-5, Validation Loss=1.23e-5, Best Loss=1.01e-5]
Training Fold 3:  75%|███████▌  | 75/100 [00:37&lt;00:12,  1.99 epochs/s, Training Loss=1.13e-5, Validation Loss=1.23e-5, Best Loss=1.01e-5]
Training Fold 3:  75%|███████▌  | 75/100 [00:37&lt;00:12,  1.99 epochs/s, Training Loss=1.1e-5, Validation Loss=1.19e-5, Best Loss=1.01e-5]
Training Fold 3:  76%|███████▌  | 76/100 [00:37&lt;00:11,  2.01 epochs/s, Training Loss=1.1e-5, Validation Loss=1.19e-5, Best Loss=1.01e-5]
Training Fold 3:  76%|███████▌  | 76/100 [00:38&lt;00:11,  2.01 epochs/s, Training Loss=1.15e-5, Validation Loss=1.19e-5, Best Loss=1.01e-5]
Training Fold 3:  77%|███████▋  | 77/100 [00:38&lt;00:11,  1.99 epochs/s, Training Loss=1.15e-5, Validation Loss=1.19e-5, Best Loss=1.01e-5]
Training Fold 3:  77%|███████▋  | 77/100 [00:38&lt;00:11,  1.99 epochs/s, Training Loss=1.12e-5, Validation Loss=1.21e-5, Best Loss=1.01e-5]
Training Fold 3:  78%|███████▊  | 78/100 [00:38&lt;00:10,  2.01 epochs/s, Training Loss=1.12e-5, Validation Loss=1.21e-5, Best Loss=1.01e-5]
Training Fold 3:  78%|███████▊  | 78/100 [00:39&lt;00:10,  2.01 epochs/s, Training Loss=1.05e-5, Validation Loss=1.18e-5, Best Loss=1.01e-5]
Training Fold 3:  79%|███████▉  | 79/100 [00:39&lt;00:10,  2.02 epochs/s, Training Loss=1.05e-5, Validation Loss=1.18e-5, Best Loss=1.01e-5]
Training Fold 3:  79%|███████▉  | 79/100 [00:39&lt;00:10,  2.02 epochs/s, Training Loss=1.16e-5, Validation Loss=1.11e-5, Best Loss=1.01e-5]
Training Fold 3:  80%|████████  | 80/100 [00:39&lt;00:09,  2.03 epochs/s, Training Loss=1.16e-5, Validation Loss=1.11e-5, Best Loss=1.01e-5]
Training Fold 3:  80%|████████  | 80/100 [00:40&lt;00:09,  2.03 epochs/s, Training Loss=1.15e-5, Validation Loss=1.19e-5, Best Loss=1.01e-5]
Training Fold 3:  81%|████████  | 81/100 [00:40&lt;00:09,  2.04 epochs/s, Training Loss=1.15e-5, Validation Loss=1.19e-5, Best Loss=1.01e-5]
Training Fold 3:  81%|████████  | 81/100 [00:40&lt;00:09,  2.04 epochs/s, Training Loss=1.15e-5, Validation Loss=1.16e-5, Best Loss=1.01e-5]
Training Fold 3:  82%|████████▏ | 82/100 [00:40&lt;00:09,  1.96 epochs/s, Training Loss=1.15e-5, Validation Loss=1.16e-5, Best Loss=1.01e-5]
Training Fold 3:  82%|████████▏ | 82/100 [00:41&lt;00:09,  1.96 epochs/s, Training Loss=1.02e-5, Validation Loss=1.15e-5, Best Loss=1.01e-5]
Training Fold 3:  83%|████████▎ | 83/100 [00:41&lt;00:08,  1.95 epochs/s, Training Loss=1.02e-5, Validation Loss=1.15e-5, Best Loss=1.01e-5]
Training Fold 3:  83%|████████▎ | 83/100 [00:41&lt;00:08,  1.95 epochs/s, Training Loss=1.2e-5, Validation Loss=1.16e-5, Best Loss=1.01e-5]
Training Fold 3:  84%|████████▍ | 84/100 [00:41&lt;00:08,  1.97 epochs/s, Training Loss=1.2e-5, Validation Loss=1.16e-5, Best Loss=1.01e-5]
Training Fold 3:  84%|████████▍ | 84/100 [00:42&lt;00:08,  1.97 epochs/s, Training Loss=1.3e-5, Validation Loss=1.37e-5, Best Loss=1.01e-5]
Training Fold 3:  85%|████████▌ | 85/100 [00:42&lt;00:07,  1.98 epochs/s, Training Loss=1.3e-5, Validation Loss=1.37e-5, Best Loss=1.01e-5]
Training Fold 3:  85%|████████▌ | 85/100 [00:42&lt;00:07,  1.98 epochs/s, Training Loss=1.09e-5, Validation Loss=1.18e-5, Best Loss=1.01e-5]
Training Fold 3:  86%|████████▌ | 86/100 [00:42&lt;00:07,  1.98 epochs/s, Training Loss=1.09e-5, Validation Loss=1.18e-5, Best Loss=1.01e-5]
Training Fold 3:  86%|████████▌ | 86/100 [00:43&lt;00:07,  1.98 epochs/s, Training Loss=1.34e-5, Validation Loss=1.27e-5, Best Loss=1.01e-5]
Training Fold 3:  87%|████████▋ | 87/100 [00:43&lt;00:06,  2.02 epochs/s, Training Loss=1.34e-5, Validation Loss=1.27e-5, Best Loss=1.01e-5]
Training Fold 3:  87%|████████▋ | 87/100 [00:43&lt;00:06,  2.02 epochs/s, Training Loss=1.06e-5, Validation Loss=1.16e-5, Best Loss=1.01e-5]
Training Fold 3:  88%|████████▊ | 88/100 [00:43&lt;00:06,  1.99 epochs/s, Training Loss=1.06e-5, Validation Loss=1.16e-5, Best Loss=1.01e-5]
Training Fold 3:  88%|████████▊ | 88/100 [00:44&lt;00:06,  1.99 epochs/s, Training Loss=1.12e-5, Validation Loss=1.17e-5, Best Loss=1.01e-5]
Training Fold 3:  89%|████████▉ | 89/100 [00:44&lt;00:05,  2.01 epochs/s, Training Loss=1.12e-5, Validation Loss=1.17e-5, Best Loss=1.01e-5]
Training Fold 3:  89%|████████▉ | 89/100 [00:44&lt;00:05,  2.01 epochs/s, Training Loss=1.05e-5, Validation Loss=1.16e-5, Best Loss=1.01e-5]
Training Fold 3:  90%|█████████ | 90/100 [00:44&lt;00:04,  2.01 epochs/s, Training Loss=1.05e-5, Validation Loss=1.16e-5, Best Loss=1.01e-5]
Training Fold 3:  90%|█████████ | 90/100 [00:45&lt;00:04,  2.01 epochs/s, Training Loss=1.33e-5, Validation Loss=1.42e-5, Best Loss=1.01e-5]
Training Fold 3:  91%|█████████ | 91/100 [00:45&lt;00:04,  2.03 epochs/s, Training Loss=1.33e-5, Validation Loss=1.42e-5, Best Loss=1.01e-5]
Training Fold 3:  91%|█████████ | 91/100 [00:45&lt;00:04,  2.03 epochs/s, Training Loss=1.29e-5, Validation Loss=1.16e-5, Best Loss=1.01e-5]
Training Fold 3:  92%|█████████▏| 92/100 [00:45&lt;00:04,  1.99 epochs/s, Training Loss=1.29e-5, Validation Loss=1.16e-5, Best Loss=1.01e-5]
Training Fold 3:  92%|█████████▏| 92/100 [00:46&lt;00:04,  1.99 epochs/s, Training Loss=1.81e-5, Validation Loss=1.67e-5, Best Loss=1.01e-5]
Training Fold 3:  93%|█████████▎| 93/100 [00:46&lt;00:03,  1.97 epochs/s, Training Loss=1.81e-5, Validation Loss=1.67e-5, Best Loss=1.01e-5]
Training Fold 3:  93%|█████████▎| 93/100 [00:46&lt;00:03,  1.97 epochs/s, Training Loss=1.28e-5, Validation Loss=1.3e-5, Best Loss=1.01e-5]
Training Fold 3:  94%|█████████▍| 94/100 [00:46&lt;00:02,  2.00 epochs/s, Training Loss=1.28e-5, Validation Loss=1.3e-5, Best Loss=1.01e-5]
Training Fold 3:  94%|█████████▍| 94/100 [00:47&lt;00:02,  2.00 epochs/s, Training Loss=1.17e-5, Validation Loss=1.18e-5, Best Loss=1.01e-5]
Training Fold 3:  95%|█████████▌| 95/100 [00:47&lt;00:02,  2.02 epochs/s, Training Loss=1.17e-5, Validation Loss=1.18e-5, Best Loss=1.01e-5]
Training Fold 3:  95%|█████████▌| 95/100 [00:47&lt;00:02,  2.02 epochs/s, Training Loss=1.3e-5, Validation Loss=1.35e-5, Best Loss=1.01e-5]
Training Fold 3:  96%|█████████▌| 96/100 [00:47&lt;00:02,  1.92 epochs/s, Training Loss=1.3e-5, Validation Loss=1.35e-5, Best Loss=1.01e-5]
Training Fold 3:  96%|█████████▌| 96/100 [00:48&lt;00:02,  1.92 epochs/s, Training Loss=1.3e-5, Validation Loss=1.29e-5, Best Loss=1.01e-5]
Training Fold 3:  97%|█████████▋| 97/100 [00:48&lt;00:01,  1.94 epochs/s, Training Loss=1.3e-5, Validation Loss=1.29e-5, Best Loss=1.01e-5]
Training Fold 3:  97%|█████████▋| 97/100 [00:48&lt;00:01,  1.94 epochs/s, Training Loss=1.09e-5, Validation Loss=1.12e-5, Best Loss=1.01e-5]
Training Fold 3:  98%|█████████▊| 98/100 [00:48&lt;00:01,  1.94 epochs/s, Training Loss=1.09e-5, Validation Loss=1.12e-5, Best Loss=1.01e-5]
Training Fold 3:  98%|█████████▊| 98/100 [00:49&lt;00:01,  1.94 epochs/s, Training Loss=1.33e-5, Validation Loss=1.45e-5, Best Loss=1.01e-5]
Training Fold 3:  99%|█████████▉| 99/100 [00:49&lt;00:00,  1.99 epochs/s, Training Loss=1.33e-5, Validation Loss=1.45e-5, Best Loss=1.01e-5]
Training Fold 3:  99%|█████████▉| 99/100 [00:49&lt;00:00,  1.99 epochs/s, Training Loss=1.09e-5, Validation Loss=1.14e-5, Best Loss=1.01e-5]
Training Fold 3: 100%|██████████| 100/100 [00:49&lt;00:00,  2.01 epochs/s, Training Loss=1.09e-5, Validation Loss=1.14e-5, Best Loss=1.01e-5]
Training Fold 3: 100%|██████████| 100/100 [00:49&lt;00:00,  2.01 epochs/s, Training Loss=1.09e-5, Validation Loss=1.14e-5, Best Loss=1.01e-5]

  0%|          | 0/100 [00:00&lt;?, ? epochs/s]
Training Fold 4:   0%|          | 0/100 [00:00&lt;?, ? epochs/s]
Training Fold 4:   0%|          | 0/100 [00:00&lt;?, ? epochs/s, Training Loss=1.11e-5, Validation Loss=1.22e-5, Best Loss=1.01e-5]
Training Fold 4:   1%|          | 1/100 [00:00&lt;00:47,  2.08 epochs/s, Training Loss=1.11e-5, Validation Loss=1.22e-5, Best Loss=1.01e-5]
Training Fold 4:   1%|          | 1/100 [00:01&lt;00:47,  2.08 epochs/s, Training Loss=9.9e-6, Validation Loss=1.06e-5, Best Loss=1.01e-5]
Training Fold 4:   2%|▏         | 2/100 [00:01&lt;00:49,  1.98 epochs/s, Training Loss=9.9e-6, Validation Loss=1.06e-5, Best Loss=1.01e-5]
Training Fold 4:   2%|▏         | 2/100 [00:01&lt;00:49,  1.98 epochs/s, Training Loss=1.05e-5, Validation Loss=1.08e-5, Best Loss=1.01e-5]
Training Fold 4:   3%|▎         | 3/100 [00:01&lt;00:51,  1.90 epochs/s, Training Loss=1.05e-5, Validation Loss=1.08e-5, Best Loss=1.01e-5]
Training Fold 4:   3%|▎         | 3/100 [00:02&lt;00:51,  1.90 epochs/s, Training Loss=9.52e-6, Validation Loss=1.05e-5, Best Loss=1.01e-5]
Training Fold 4:   4%|▍         | 4/100 [00:02&lt;00:49,  1.94 epochs/s, Training Loss=9.52e-6, Validation Loss=1.05e-5, Best Loss=1.01e-5]
Training Fold 4:   4%|▍         | 4/100 [00:02&lt;00:49,  1.94 epochs/s, Training Loss=1.01e-5, Validation Loss=1.01e-5, Best Loss=1.01e-5]
Training Fold 4:   5%|▌         | 5/100 [00:02&lt;00:49,  1.92 epochs/s, Training Loss=1.01e-5, Validation Loss=1.01e-5, Best Loss=1.01e-5]
Training Fold 4:   5%|▌         | 5/100 [00:03&lt;00:49,  1.92 epochs/s, Training Loss=1.81e-5, Validation Loss=1.76e-5, Best Loss=1.01e-5]
Training Fold 4:   6%|▌         | 6/100 [00:03&lt;00:48,  1.94 epochs/s, Training Loss=1.81e-5, Validation Loss=1.76e-5, Best Loss=1.01e-5]
Training Fold 4:   6%|▌         | 6/100 [00:03&lt;00:48,  1.94 epochs/s, Training Loss=1.49e-5, Validation Loss=1.73e-5, Best Loss=1.01e-5]
Training Fold 4:   7%|▋         | 7/100 [00:03&lt;00:46,  2.02 epochs/s, Training Loss=1.49e-5, Validation Loss=1.73e-5, Best Loss=1.01e-5]
Training Fold 4:   7%|▋         | 7/100 [00:04&lt;00:46,  2.02 epochs/s, Training Loss=1.12e-5, Validation Loss=1.32e-5, Best Loss=1.01e-5]
Training Fold 4:   8%|▊         | 8/100 [00:04&lt;00:45,  2.02 epochs/s, Training Loss=1.12e-5, Validation Loss=1.32e-5, Best Loss=1.01e-5]
Training Fold 4:   8%|▊         | 8/100 [00:04&lt;00:45,  2.02 epochs/s, Training Loss=9.82e-6, Validation Loss=1.06e-5, Best Loss=1.01e-5]
Training Fold 4:   9%|▉         | 9/100 [00:04&lt;00:44,  2.04 epochs/s, Training Loss=9.82e-6, Validation Loss=1.06e-5, Best Loss=1.01e-5]
Training Fold 4:   9%|▉         | 9/100 [00:05&lt;00:44,  2.04 epochs/s, Training Loss=1.21e-5, Validation Loss=1.28e-5, Best Loss=1.01e-5]
Training Fold 4:  10%|█         | 10/100 [00:05&lt;00:45,  1.96 epochs/s, Training Loss=1.21e-5, Validation Loss=1.28e-5, Best Loss=1.01e-5]
Training Fold 4:  10%|█         | 10/100 [00:05&lt;00:45,  1.96 epochs/s, Training Loss=1.07e-5, Validation Loss=1.14e-5, Best Loss=1.01e-5]
Training Fold 4:  11%|█         | 11/100 [00:05&lt;00:45,  1.94 epochs/s, Training Loss=1.07e-5, Validation Loss=1.14e-5, Best Loss=1.01e-5]
Training Fold 4:  11%|█         | 11/100 [00:06&lt;00:45,  1.94 epochs/s, Training Loss=1.02e-5, Validation Loss=1.07e-5, Best Loss=1.01e-5]
Training Fold 4:  12%|█▏        | 12/100 [00:06&lt;00:44,  1.96 epochs/s, Training Loss=1.02e-5, Validation Loss=1.07e-5, Best Loss=1.01e-5]
Training Fold 4:  12%|█▏        | 12/100 [00:06&lt;00:44,  1.96 epochs/s, Training Loss=1.18e-5, Validation Loss=1.31e-5, Best Loss=1.01e-5]
Training Fold 4:  13%|█▎        | 13/100 [00:06&lt;00:43,  1.99 epochs/s, Training Loss=1.18e-5, Validation Loss=1.31e-5, Best Loss=1.01e-5]
Training Fold 4:  13%|█▎        | 13/100 [00:07&lt;00:43,  1.99 epochs/s, Training Loss=1.04e-5, Validation Loss=1.19e-5, Best Loss=1.01e-5]
Training Fold 4:  14%|█▍        | 14/100 [00:07&lt;00:43,  1.98 epochs/s, Training Loss=1.04e-5, Validation Loss=1.19e-5, Best Loss=1.01e-5]
Training Fold 4:  14%|█▍        | 14/100 [00:07&lt;00:43,  1.98 epochs/s, Training Loss=1.08e-5, Validation Loss=1.22e-5, Best Loss=1.01e-5]
Training Fold 4:  15%|█▌        | 15/100 [00:07&lt;00:42,  2.00 epochs/s, Training Loss=1.08e-5, Validation Loss=1.22e-5, Best Loss=1.01e-5]
Training Fold 4:  15%|█▌        | 15/100 [00:08&lt;00:42,  2.00 epochs/s, Training Loss=9.66e-6, Validation Loss=1.04e-5, Best Loss=1.01e-5]
Training Fold 4:  16%|█▌        | 16/100 [00:08&lt;00:41,  2.03 epochs/s, Training Loss=9.66e-6, Validation Loss=1.04e-5, Best Loss=1.01e-5]
Training Fold 4:  16%|█▌        | 16/100 [00:08&lt;00:41,  2.03 epochs/s, Training Loss=9.41e-6, Validation Loss=1.05e-5, Best Loss=1.01e-5]
Training Fold 4:  17%|█▋        | 17/100 [00:08&lt;00:40,  2.03 epochs/s, Training Loss=9.41e-6, Validation Loss=1.05e-5, Best Loss=1.01e-5]
Training Fold 4:  17%|█▋        | 17/100 [00:09&lt;00:40,  2.03 epochs/s, Training Loss=9.19e-6, Validation Loss=1.08e-5, Best Loss=1.01e-5]
Training Fold 4:  18%|█▊        | 18/100 [00:09&lt;00:40,  2.01 epochs/s, Training Loss=9.19e-6, Validation Loss=1.08e-5, Best Loss=1.01e-5]
Training Fold 4:  18%|█▊        | 18/100 [00:09&lt;00:40,  2.01 epochs/s, Training Loss=9.72e-6, Validation Loss=1.1e-5, Best Loss=1.01e-5]
Training Fold 4:  19%|█▉        | 19/100 [00:09&lt;00:40,  2.01 epochs/s, Training Loss=9.72e-6, Validation Loss=1.1e-5, Best Loss=1.01e-5]
Training Fold 4:  19%|█▉        | 19/100 [00:10&lt;00:40,  2.01 epochs/s, Training Loss=9.33e-6, Validation Loss=1.1e-5, Best Loss=1.01e-5]
Training Fold 4:  20%|██        | 20/100 [00:10&lt;00:40,  1.98 epochs/s, Training Loss=9.33e-6, Validation Loss=1.1e-5, Best Loss=1.01e-5]
Training Fold 4:  20%|██        | 20/100 [00:10&lt;00:40,  1.98 epochs/s, Training Loss=1e-5, Validation Loss=1.15e-5, Best Loss=1.01e-5]
Training Fold 4:  21%|██        | 21/100 [00:10&lt;00:39,  1.99 epochs/s, Training Loss=1e-5, Validation Loss=1.15e-5, Best Loss=1.01e-5]
Training Fold 4:  21%|██        | 21/100 [00:11&lt;00:39,  1.99 epochs/s, Training Loss=9.48e-6, Validation Loss=1.13e-5, Best Loss=1.01e-5]
Training Fold 4:  22%|██▏       | 22/100 [00:11&lt;00:39,  1.98 epochs/s, Training Loss=9.48e-6, Validation Loss=1.13e-5, Best Loss=1.01e-5]
Training Fold 4:  22%|██▏       | 22/100 [00:11&lt;00:39,  1.98 epochs/s, Training Loss=9.86e-6, Validation Loss=1.2e-5, Best Loss=1.01e-5]
Training Fold 4:  23%|██▎       | 23/100 [00:11&lt;00:39,  1.96 epochs/s, Training Loss=9.86e-6, Validation Loss=1.2e-5, Best Loss=1.01e-5]
Training Fold 4:  23%|██▎       | 23/100 [00:12&lt;00:39,  1.96 epochs/s, Training Loss=1.06e-5, Validation Loss=1.3e-5, Best Loss=1.01e-5]
Training Fold 4:  24%|██▍       | 24/100 [00:12&lt;00:38,  1.99 epochs/s, Training Loss=1.06e-5, Validation Loss=1.3e-5, Best Loss=1.01e-5]
Training Fold 4:  24%|██▍       | 24/100 [00:12&lt;00:38,  1.99 epochs/s, Training Loss=1.1e-5, Validation Loss=1.16e-5, Best Loss=1.01e-5]
Training Fold 4:  25%|██▌       | 25/100 [00:12&lt;00:38,  1.97 epochs/s, Training Loss=1.1e-5, Validation Loss=1.16e-5, Best Loss=1.01e-5]
Training Fold 4:  25%|██▌       | 25/100 [00:13&lt;00:38,  1.97 epochs/s, Training Loss=1.43e-5, Validation Loss=1.59e-5, Best Loss=1.01e-5]
Training Fold 4:  26%|██▌       | 26/100 [00:13&lt;00:37,  2.00 epochs/s, Training Loss=1.43e-5, Validation Loss=1.59e-5, Best Loss=1.01e-5]
Training Fold 4:  26%|██▌       | 26/100 [00:13&lt;00:37,  2.00 epochs/s, Training Loss=8.76e-6, Validation Loss=1.02e-5, Best Loss=1.01e-5]
Training Fold 4:  27%|██▋       | 27/100 [00:13&lt;00:36,  2.02 epochs/s, Training Loss=8.76e-6, Validation Loss=1.02e-5, Best Loss=1.01e-5]
Training Fold 4:  27%|██▋       | 27/100 [00:14&lt;00:36,  2.02 epochs/s, Training Loss=9.19e-6, Validation Loss=1.06e-5, Best Loss=1.01e-5]
Training Fold 4:  28%|██▊       | 28/100 [00:14&lt;00:35,  2.03 epochs/s, Training Loss=9.19e-6, Validation Loss=1.06e-5, Best Loss=1.01e-5]
Training Fold 4:  28%|██▊       | 28/100 [00:14&lt;00:35,  2.03 epochs/s, Training Loss=9.76e-6, Validation Loss=1.16e-5, Best Loss=1.01e-5]
Training Fold 4:  29%|██▉       | 29/100 [00:14&lt;00:35,  2.03 epochs/s, Training Loss=9.76e-6, Validation Loss=1.16e-5, Best Loss=1.01e-5]
Training Fold 4:  29%|██▉       | 29/100 [00:15&lt;00:35,  2.03 epochs/s, Training Loss=8.61e-6, Validation Loss=1.08e-5, Best Loss=1.01e-5]
Training Fold 4:  30%|███       | 30/100 [00:15&lt;00:34,  2.01 epochs/s, Training Loss=8.61e-6, Validation Loss=1.08e-5, Best Loss=1.01e-5]
Training Fold 4:  30%|███       | 30/100 [00:15&lt;00:34,  2.01 epochs/s, Training Loss=1.04e-5, Validation Loss=1.28e-5, Best Loss=1.01e-5]
Training Fold 4:  31%|███       | 31/100 [00:15&lt;00:34,  2.03 epochs/s, Training Loss=1.04e-5, Validation Loss=1.28e-5, Best Loss=1.01e-5]
Training Fold 4:  31%|███       | 31/100 [00:16&lt;00:34,  2.03 epochs/s, Training Loss=8.69e-6, Validation Loss=1.07e-5, Best Loss=1.01e-5]
Training Fold 4:  32%|███▏      | 32/100 [00:16&lt;00:34,  1.99 epochs/s, Training Loss=8.69e-6, Validation Loss=1.07e-5, Best Loss=1.01e-5]
Training Fold 4:  32%|███▏      | 32/100 [00:16&lt;00:34,  1.99 epochs/s, Training Loss=8.83e-6, Validation Loss=1.06e-5, Best Loss=1.01e-5]
Training Fold 4:  33%|███▎      | 33/100 [00:16&lt;00:33,  1.98 epochs/s, Training Loss=8.83e-6, Validation Loss=1.06e-5, Best Loss=1.01e-5]
Training Fold 4:  33%|███▎      | 33/100 [00:17&lt;00:33,  1.98 epochs/s, Training Loss=8.98e-6, Validation Loss=1.09e-5, Best Loss=1.01e-5]
Training Fold 4:  34%|███▍      | 34/100 [00:17&lt;00:33,  1.97 epochs/s, Training Loss=8.98e-6, Validation Loss=1.09e-5, Best Loss=1.01e-5]
Training Fold 4:  34%|███▍      | 34/100 [00:17&lt;00:33,  1.97 epochs/s, Training Loss=9.18e-6, Validation Loss=1.17e-5, Best Loss=1.01e-5]
Training Fold 4:  35%|███▌      | 35/100 [00:17&lt;00:32,  2.02 epochs/s, Training Loss=9.18e-6, Validation Loss=1.17e-5, Best Loss=1.01e-5]
Training Fold 4:  35%|███▌      | 35/100 [00:18&lt;00:32,  2.02 epochs/s, Training Loss=8.43e-6, Validation Loss=1.06e-5, Best Loss=1.01e-5]
Training Fold 4:  36%|███▌      | 36/100 [00:18&lt;00:32,  1.99 epochs/s, Training Loss=8.43e-6, Validation Loss=1.06e-5, Best Loss=1.01e-5]
Training Fold 4:  36%|███▌      | 36/100 [00:18&lt;00:32,  1.99 epochs/s, Training Loss=8.78e-6, Validation Loss=1.18e-5, Best Loss=1.01e-5]
Training Fold 4:  37%|███▋      | 37/100 [00:18&lt;00:31,  1.99 epochs/s, Training Loss=8.78e-6, Validation Loss=1.18e-5, Best Loss=1.01e-5]
Training Fold 4:  37%|███▋      | 37/100 [00:19&lt;00:31,  1.99 epochs/s, Training Loss=9.5e-6, Validation Loss=1.13e-5, Best Loss=1.01e-5]
Training Fold 4:  38%|███▊      | 38/100 [00:19&lt;00:31,  1.99 epochs/s, Training Loss=9.5e-6, Validation Loss=1.13e-5, Best Loss=1.01e-5]
Training Fold 4:  38%|███▊      | 38/100 [00:19&lt;00:31,  1.99 epochs/s, Training Loss=1.07e-5, Validation Loss=1.13e-5, Best Loss=1.01e-5]
Training Fold 4:  39%|███▉      | 39/100 [00:19&lt;00:30,  1.98 epochs/s, Training Loss=1.07e-5, Validation Loss=1.13e-5, Best Loss=1.01e-5]
Training Fold 4:  39%|███▉      | 39/100 [00:20&lt;00:30,  1.98 epochs/s, Training Loss=1.05e-5, Validation Loss=1.28e-5, Best Loss=1.01e-5]
Training Fold 4:  40%|████      | 40/100 [00:20&lt;00:30,  1.96 epochs/s, Training Loss=1.05e-5, Validation Loss=1.28e-5, Best Loss=1.01e-5]
Training Fold 4:  40%|████      | 40/100 [00:20&lt;00:30,  1.96 epochs/s, Training Loss=8.93e-6, Validation Loss=1.1e-5, Best Loss=1.01e-5]
Training Fold 4:  41%|████      | 41/100 [00:20&lt;00:29,  1.98 epochs/s, Training Loss=8.93e-6, Validation Loss=1.1e-5, Best Loss=1.01e-5]
Training Fold 4:  41%|████      | 41/100 [00:21&lt;00:29,  1.98 epochs/s, Training Loss=8.97e-6, Validation Loss=1.13e-5, Best Loss=1.01e-5]
Training Fold 4:  42%|████▏     | 42/100 [00:21&lt;00:29,  1.98 epochs/s, Training Loss=8.97e-6, Validation Loss=1.13e-5, Best Loss=1.01e-5]
Training Fold 4:  42%|████▏     | 42/100 [00:21&lt;00:29,  1.98 epochs/s, Training Loss=8.97e-6, Validation Loss=1.06e-5, Best Loss=1.01e-5]
Training Fold 4:  43%|████▎     | 43/100 [00:21&lt;00:27,  2.04 epochs/s, Training Loss=8.97e-6, Validation Loss=1.06e-5, Best Loss=1.01e-5]
Training Fold 4:  43%|████▎     | 43/100 [00:22&lt;00:27,  2.04 epochs/s, Training Loss=1.23e-5, Validation Loss=1.3e-5, Best Loss=1.01e-5]
Training Fold 4:  44%|████▍     | 44/100 [00:22&lt;00:27,  2.06 epochs/s, Training Loss=1.23e-5, Validation Loss=1.3e-5, Best Loss=1.01e-5]
Training Fold 4:  44%|████▍     | 44/100 [00:22&lt;00:27,  2.06 epochs/s, Training Loss=9.61e-6, Validation Loss=1.21e-5, Best Loss=1.01e-5]
Training Fold 4:  45%|████▌     | 45/100 [00:22&lt;00:27,  2.04 epochs/s, Training Loss=9.61e-6, Validation Loss=1.21e-5, Best Loss=1.01e-5]
Training Fold 4:  45%|████▌     | 45/100 [00:23&lt;00:27,  2.04 epochs/s, Training Loss=9.53e-6, Validation Loss=1.13e-5, Best Loss=1.01e-5]
Training Fold 4:  46%|████▌     | 46/100 [00:23&lt;00:26,  2.02 epochs/s, Training Loss=9.53e-6, Validation Loss=1.13e-5, Best Loss=1.01e-5]
Training Fold 4:  46%|████▌     | 46/100 [00:23&lt;00:26,  2.02 epochs/s, Training Loss=8.57e-6, Validation Loss=1.17e-5, Best Loss=1.01e-5]
Training Fold 4:  47%|████▋     | 47/100 [00:23&lt;00:26,  2.02 epochs/s, Training Loss=8.57e-6, Validation Loss=1.17e-5, Best Loss=1.01e-5]
Training Fold 4:  47%|████▋     | 47/100 [00:24&lt;00:26,  2.02 epochs/s, Training Loss=2.47e-5, Validation Loss=2.67e-5, Best Loss=1.01e-5]
Training Fold 4:  48%|████▊     | 48/100 [00:24&lt;00:26,  1.99 epochs/s, Training Loss=2.47e-5, Validation Loss=2.67e-5, Best Loss=1.01e-5]
Training Fold 4:  48%|████▊     | 48/100 [00:24&lt;00:26,  1.99 epochs/s, Training Loss=8.85e-6, Validation Loss=1.11e-5, Best Loss=1.01e-5]
Training Fold 4:  49%|████▉     | 49/100 [00:24&lt;00:25,  2.00 epochs/s, Training Loss=8.85e-6, Validation Loss=1.11e-5, Best Loss=1.01e-5]
Training Fold 4:  49%|████▉     | 49/100 [00:25&lt;00:25,  2.00 epochs/s, Training Loss=8.38e-6, Validation Loss=1.06e-5, Best Loss=1.01e-5]
Training Fold 4:  50%|█████     | 50/100 [00:25&lt;00:24,  2.05 epochs/s, Training Loss=8.38e-6, Validation Loss=1.06e-5, Best Loss=1.01e-5]
Training Fold 4:  50%|█████     | 50/100 [00:25&lt;00:24,  2.05 epochs/s, Training Loss=9.32e-6, Validation Loss=1.13e-5, Best Loss=1.01e-5]
Training Fold 4:  51%|█████     | 51/100 [00:25&lt;00:24,  2.03 epochs/s, Training Loss=9.32e-6, Validation Loss=1.13e-5, Best Loss=1.01e-5]
Training Fold 4:  51%|█████     | 51/100 [00:26&lt;00:24,  2.03 epochs/s, Training Loss=1.15e-5, Validation Loss=1.42e-5, Best Loss=1.01e-5]
Training Fold 4:  52%|█████▏    | 52/100 [00:26&lt;00:23,  2.02 epochs/s, Training Loss=1.15e-5, Validation Loss=1.42e-5, Best Loss=1.01e-5]
Training Fold 4:  52%|█████▏    | 52/100 [00:26&lt;00:23,  2.02 epochs/s, Training Loss=7.98e-6, Validation Loss=1.07e-5, Best Loss=1.01e-5]
Training Fold 4:  53%|█████▎    | 53/100 [00:26&lt;00:23,  2.04 epochs/s, Training Loss=7.98e-6, Validation Loss=1.07e-5, Best Loss=1.01e-5]
Training Fold 4:  53%|█████▎    | 53/100 [00:27&lt;00:23,  2.04 epochs/s, Training Loss=8.77e-6, Validation Loss=1.12e-5, Best Loss=1.01e-5]
Training Fold 4:  54%|█████▍    | 54/100 [00:27&lt;00:22,  2.01 epochs/s, Training Loss=8.77e-6, Validation Loss=1.12e-5, Best Loss=1.01e-5]
Training Fold 4:  54%|█████▍    | 54/100 [00:27&lt;00:22,  2.01 epochs/s, Training Loss=8.37e-6, Validation Loss=1.14e-5, Best Loss=1.01e-5]
Training Fold 4:  55%|█████▌    | 55/100 [00:27&lt;00:22,  2.04 epochs/s, Training Loss=8.37e-6, Validation Loss=1.14e-5, Best Loss=1.01e-5]
Training Fold 4:  55%|█████▌    | 55/100 [00:27&lt;00:22,  2.04 epochs/s, Training Loss=9e-6, Validation Loss=1.2e-5, Best Loss=1.01e-5]
Training Fold 4:  56%|█████▌    | 56/100 [00:27&lt;00:21,  2.05 epochs/s, Training Loss=9e-6, Validation Loss=1.2e-5, Best Loss=1.01e-5]
Training Fold 4:  56%|█████▌    | 56/100 [00:28&lt;00:21,  2.05 epochs/s, Training Loss=9.35e-6, Validation Loss=1.18e-5, Best Loss=1.01e-5]
Training Fold 4:  57%|█████▋    | 57/100 [00:28&lt;00:20,  2.05 epochs/s, Training Loss=9.35e-6, Validation Loss=1.18e-5, Best Loss=1.01e-5]
Training Fold 4:  57%|█████▋    | 57/100 [00:28&lt;00:20,  2.05 epochs/s, Training Loss=7.06e-5, Validation Loss=7.42e-5, Best Loss=1.01e-5]
Training Fold 4:  58%|█████▊    | 58/100 [00:28&lt;00:20,  2.07 epochs/s, Training Loss=7.06e-5, Validation Loss=7.42e-5, Best Loss=1.01e-5]
Training Fold 4:  58%|█████▊    | 58/100 [00:29&lt;00:20,  2.07 epochs/s, Training Loss=9.3e-6, Validation Loss=1.06e-5, Best Loss=1.01e-5]
Training Fold 4:  59%|█████▉    | 59/100 [00:29&lt;00:20,  2.03 epochs/s, Training Loss=9.3e-6, Validation Loss=1.06e-5, Best Loss=1.01e-5]
Training Fold 4:  59%|█████▉    | 59/100 [00:29&lt;00:20,  2.03 epochs/s, Training Loss=9.77e-6, Validation Loss=1.18e-5, Best Loss=1.01e-5]
Training Fold 4:  60%|██████    | 60/100 [00:29&lt;00:19,  2.06 epochs/s, Training Loss=9.77e-6, Validation Loss=1.18e-5, Best Loss=1.01e-5]
Training Fold 4:  60%|██████    | 60/100 [00:30&lt;00:19,  2.06 epochs/s, Training Loss=8.57e-6, Validation Loss=1.06e-5, Best Loss=1.01e-5]
Training Fold 4:  61%|██████    | 61/100 [00:30&lt;00:18,  2.06 epochs/s, Training Loss=8.57e-6, Validation Loss=1.06e-5, Best Loss=1.01e-5]
Training Fold 4:  61%|██████    | 61/100 [00:30&lt;00:18,  2.06 epochs/s, Training Loss=8.63e-6, Validation Loss=1.09e-5, Best Loss=1.01e-5]
Training Fold 4:  62%|██████▏   | 62/100 [00:30&lt;00:18,  2.05 epochs/s, Training Loss=8.63e-6, Validation Loss=1.09e-5, Best Loss=1.01e-5]
Training Fold 4:  62%|██████▏   | 62/100 [00:31&lt;00:18,  2.05 epochs/s, Training Loss=1.29e-5, Validation Loss=1.62e-5, Best Loss=1.01e-5]
Training Fold 4:  63%|██████▎   | 63/100 [00:31&lt;00:18,  2.03 epochs/s, Training Loss=1.29e-5, Validation Loss=1.62e-5, Best Loss=1.01e-5]
Training Fold 4:  63%|██████▎   | 63/100 [00:31&lt;00:18,  2.03 epochs/s, Training Loss=8.1e-6, Validation Loss=1.12e-5, Best Loss=1.01e-5]
Training Fold 4:  64%|██████▍   | 64/100 [00:31&lt;00:17,  2.01 epochs/s, Training Loss=8.1e-6, Validation Loss=1.12e-5, Best Loss=1.01e-5]
Training Fold 4:  64%|██████▍   | 64/100 [00:32&lt;00:17,  2.01 epochs/s, Training Loss=8.98e-6, Validation Loss=1.1e-5, Best Loss=1.01e-5]
Training Fold 4:  65%|██████▌   | 65/100 [00:32&lt;00:17,  2.01 epochs/s, Training Loss=8.98e-6, Validation Loss=1.1e-5, Best Loss=1.01e-5]
Training Fold 4:  65%|██████▌   | 65/100 [00:32&lt;00:17,  2.01 epochs/s, Training Loss=1.02e-5, Validation Loss=1.24e-5, Best Loss=1.01e-5]
Training Fold 4:  66%|██████▌   | 66/100 [00:32&lt;00:16,  2.03 epochs/s, Training Loss=1.02e-5, Validation Loss=1.24e-5, Best Loss=1.01e-5]
Training Fold 4:  66%|██████▌   | 66/100 [00:33&lt;00:16,  2.03 epochs/s, Training Loss=9.53e-6, Validation Loss=1.26e-5, Best Loss=1.01e-5]
Training Fold 4:  67%|██████▋   | 67/100 [00:33&lt;00:16,  1.97 epochs/s, Training Loss=9.53e-6, Validation Loss=1.26e-5, Best Loss=1.01e-5]
Training Fold 4:  67%|██████▋   | 67/100 [00:33&lt;00:16,  1.97 epochs/s, Training Loss=8.62e-6, Validation Loss=1.12e-5, Best Loss=1.01e-5]
Training Fold 4:  68%|██████▊   | 68/100 [00:33&lt;00:16,  1.93 epochs/s, Training Loss=8.62e-6, Validation Loss=1.12e-5, Best Loss=1.01e-5]
Training Fold 4:  68%|██████▊   | 68/100 [00:34&lt;00:16,  1.93 epochs/s, Training Loss=4.96e-5, Validation Loss=5.26e-5, Best Loss=1.01e-5]
Training Fold 4:  69%|██████▉   | 69/100 [00:34&lt;00:15,  1.94 epochs/s, Training Loss=4.96e-5, Validation Loss=5.26e-5, Best Loss=1.01e-5]
Training Fold 4:  69%|██████▉   | 69/100 [00:35&lt;00:15,  1.94 epochs/s, Training Loss=1.03e-5, Validation Loss=1.35e-5, Best Loss=1.01e-5]
Training Fold 4:  70%|███████   | 70/100 [00:35&lt;00:15,  1.93 epochs/s, Training Loss=1.03e-5, Validation Loss=1.35e-5, Best Loss=1.01e-5]
Training Fold 4:  70%|███████   | 70/100 [00:35&lt;00:15,  1.93 epochs/s, Training Loss=9.24e-6, Validation Loss=1.25e-5, Best Loss=1.01e-5]
Training Fold 4:  71%|███████   | 71/100 [00:35&lt;00:14,  1.96 epochs/s, Training Loss=9.24e-6, Validation Loss=1.25e-5, Best Loss=1.01e-5]
Training Fold 4:  71%|███████   | 71/100 [00:36&lt;00:14,  1.96 epochs/s, Training Loss=9.03e-6, Validation Loss=1.17e-5, Best Loss=1.01e-5]
Training Fold 4:  72%|███████▏  | 72/100 [00:36&lt;00:14,  1.96 epochs/s, Training Loss=9.03e-6, Validation Loss=1.17e-5, Best Loss=1.01e-5]
Training Fold 4:  72%|███████▏  | 72/100 [00:36&lt;00:14,  1.96 epochs/s, Training Loss=9.02e-6, Validation Loss=1.21e-5, Best Loss=1.01e-5]
Training Fold 4:  73%|███████▎  | 73/100 [00:36&lt;00:13,  1.98 epochs/s, Training Loss=9.02e-6, Validation Loss=1.21e-5, Best Loss=1.01e-5]
Training Fold 4:  73%|███████▎  | 73/100 [00:37&lt;00:13,  1.98 epochs/s, Training Loss=1.13e-5, Validation Loss=1.53e-5, Best Loss=1.01e-5]
Training Fold 4:  74%|███████▍  | 74/100 [00:37&lt;00:13,  1.95 epochs/s, Training Loss=1.13e-5, Validation Loss=1.53e-5, Best Loss=1.01e-5]
Training Fold 4:  74%|███████▍  | 74/100 [00:37&lt;00:13,  1.95 epochs/s, Training Loss=7.76e-6, Validation Loss=1.1e-5, Best Loss=1.01e-5]
Training Fold 4:  75%|███████▌  | 75/100 [00:37&lt;00:12,  1.95 epochs/s, Training Loss=7.76e-6, Validation Loss=1.1e-5, Best Loss=1.01e-5]
Training Fold 4:  75%|███████▌  | 75/100 [00:38&lt;00:12,  1.95 epochs/s, Training Loss=7.39e-6, Validation Loss=1.09e-5, Best Loss=1.01e-5]
Training Fold 4:  76%|███████▌  | 76/100 [00:38&lt;00:12,  1.96 epochs/s, Training Loss=7.39e-6, Validation Loss=1.09e-5, Best Loss=1.01e-5]
Training Fold 4:  76%|███████▌  | 76/100 [00:38&lt;00:12,  1.96 epochs/s, Training Loss=8.38e-6, Validation Loss=1.13e-5, Best Loss=1.01e-5]
Training Fold 4:  77%|███████▋  | 77/100 [00:38&lt;00:11,  1.97 epochs/s, Training Loss=8.38e-6, Validation Loss=1.13e-5, Best Loss=1.01e-5]
Training Fold 4:  77%|███████▋  | 77/100 [00:39&lt;00:11,  1.97 epochs/s, Training Loss=7.43e-6, Validation Loss=1.1e-5, Best Loss=1.01e-5]
Training Fold 4:  78%|███████▊  | 78/100 [00:39&lt;00:10,  2.00 epochs/s, Training Loss=7.43e-6, Validation Loss=1.1e-5, Best Loss=1.01e-5]
Training Fold 4:  78%|███████▊  | 78/100 [00:39&lt;00:10,  2.00 epochs/s, Training Loss=8.33e-6, Validation Loss=1.17e-5, Best Loss=1.01e-5]
Training Fold 4:  79%|███████▉  | 79/100 [00:39&lt;00:10,  1.98 epochs/s, Training Loss=8.33e-6, Validation Loss=1.17e-5, Best Loss=1.01e-5]
Training Fold 4:  79%|███████▉  | 79/100 [00:40&lt;00:10,  1.98 epochs/s, Training Loss=1.36e-5, Validation Loss=1.84e-5, Best Loss=1.01e-5]
Training Fold 4:  80%|████████  | 80/100 [00:40&lt;00:10,  1.96 epochs/s, Training Loss=1.36e-5, Validation Loss=1.84e-5, Best Loss=1.01e-5]
Training Fold 4:  80%|████████  | 80/100 [00:40&lt;00:10,  1.96 epochs/s, Training Loss=7.61e-6, Validation Loss=1.11e-5, Best Loss=1.01e-5]
Training Fold 4:  81%|████████  | 81/100 [00:40&lt;00:09,  2.00 epochs/s, Training Loss=7.61e-6, Validation Loss=1.11e-5, Best Loss=1.01e-5]
Training Fold 4:  81%|████████  | 81/100 [00:41&lt;00:09,  2.00 epochs/s, Training Loss=8.13e-6, Validation Loss=1.12e-5, Best Loss=1.01e-5]
Training Fold 4:  82%|████████▏ | 82/100 [00:41&lt;00:09,  1.99 epochs/s, Training Loss=8.13e-6, Validation Loss=1.12e-5, Best Loss=1.01e-5]
Training Fold 4:  82%|████████▏ | 82/100 [00:41&lt;00:09,  1.99 epochs/s, Training Loss=8.77e-6, Validation Loss=1.2e-5, Best Loss=1.01e-5]
Training Fold 4:  83%|████████▎ | 83/100 [00:41&lt;00:08,  2.03 epochs/s, Training Loss=8.77e-6, Validation Loss=1.2e-5, Best Loss=1.01e-5]
Training Fold 4:  83%|████████▎ | 83/100 [00:42&lt;00:08,  2.03 epochs/s, Training Loss=7.25e-6, Validation Loss=1.07e-5, Best Loss=1.01e-5]
Training Fold 4:  84%|████████▍ | 84/100 [00:42&lt;00:07,  2.02 epochs/s, Training Loss=7.25e-6, Validation Loss=1.07e-5, Best Loss=1.01e-5]
Training Fold 4:  84%|████████▍ | 84/100 [00:42&lt;00:07,  2.02 epochs/s, Training Loss=8.31e-6, Validation Loss=1.17e-5, Best Loss=1.01e-5]
Training Fold 4:  85%|████████▌ | 85/100 [00:42&lt;00:07,  2.01 epochs/s, Training Loss=8.31e-6, Validation Loss=1.17e-5, Best Loss=1.01e-5]
Training Fold 4:  85%|████████▌ | 85/100 [00:43&lt;00:07,  2.01 epochs/s, Training Loss=7.49e-6, Validation Loss=1.12e-5, Best Loss=1.01e-5]
Training Fold 4:  86%|████████▌ | 86/100 [00:43&lt;00:06,  2.00 epochs/s, Training Loss=7.49e-6, Validation Loss=1.12e-5, Best Loss=1.01e-5]
Training Fold 4:  86%|████████▌ | 86/100 [00:43&lt;00:06,  2.00 epochs/s, Training Loss=9.18e-6, Validation Loss=1.3e-5, Best Loss=1.01e-5]
Training Fold 4:  87%|████████▋ | 87/100 [00:43&lt;00:06,  2.04 epochs/s, Training Loss=9.18e-6, Validation Loss=1.3e-5, Best Loss=1.01e-5]
Training Fold 4:  87%|████████▋ | 87/100 [00:44&lt;00:06,  2.04 epochs/s, Training Loss=7.37e-6, Validation Loss=1.07e-5, Best Loss=1.01e-5]
Training Fold 4:  88%|████████▊ | 88/100 [00:44&lt;00:05,  2.01 epochs/s, Training Loss=7.37e-6, Validation Loss=1.07e-5, Best Loss=1.01e-5]
Training Fold 4:  88%|████████▊ | 88/100 [00:44&lt;00:05,  2.01 epochs/s, Training Loss=9.25e-6, Validation Loss=1.34e-5, Best Loss=1.01e-5]
Training Fold 4:  89%|████████▉ | 89/100 [00:44&lt;00:05,  1.99 epochs/s, Training Loss=9.25e-6, Validation Loss=1.34e-5, Best Loss=1.01e-5]
Training Fold 4:  89%|████████▉ | 89/100 [00:45&lt;00:05,  1.99 epochs/s, Training Loss=8.26e-6, Validation Loss=1.22e-5, Best Loss=1.01e-5]
Training Fold 4:  90%|█████████ | 90/100 [00:45&lt;00:05,  1.98 epochs/s, Training Loss=8.26e-6, Validation Loss=1.22e-5, Best Loss=1.01e-5]
Training Fold 4:  90%|█████████ | 90/100 [00:45&lt;00:05,  1.98 epochs/s, Training Loss=8.26e-6, Validation Loss=1.13e-5, Best Loss=1.01e-5]
Training Fold 4:  91%|█████████ | 91/100 [00:45&lt;00:04,  1.96 epochs/s, Training Loss=8.26e-6, Validation Loss=1.13e-5, Best Loss=1.01e-5]
Training Fold 4:  91%|█████████ | 91/100 [00:46&lt;00:04,  1.96 epochs/s, Training Loss=8.41e-6, Validation Loss=1.18e-5, Best Loss=1.01e-5]
Training Fold 4:  92%|█████████▏| 92/100 [00:46&lt;00:04,  1.95 epochs/s, Training Loss=8.41e-6, Validation Loss=1.18e-5, Best Loss=1.01e-5]
Training Fold 4:  92%|█████████▏| 92/100 [00:46&lt;00:04,  1.95 epochs/s, Training Loss=7.54e-6, Validation Loss=1.09e-5, Best Loss=1.01e-5]
Training Fold 4:  93%|█████████▎| 93/100 [00:46&lt;00:03,  1.99 epochs/s, Training Loss=7.54e-6, Validation Loss=1.09e-5, Best Loss=1.01e-5]
Training Fold 4:  93%|█████████▎| 93/100 [00:47&lt;00:03,  1.99 epochs/s, Training Loss=1.24e-5, Validation Loss=1.4e-5, Best Loss=1.01e-5]
Training Fold 4:  94%|█████████▍| 94/100 [00:47&lt;00:03,  1.98 epochs/s, Training Loss=1.24e-5, Validation Loss=1.4e-5, Best Loss=1.01e-5]
Training Fold 4:  94%|█████████▍| 94/100 [00:47&lt;00:03,  1.98 epochs/s, Training Loss=8.72e-6, Validation Loss=1.11e-5, Best Loss=1.01e-5]
Training Fold 4:  95%|█████████▌| 95/100 [00:47&lt;00:02,  2.02 epochs/s, Training Loss=8.72e-6, Validation Loss=1.11e-5, Best Loss=1.01e-5]
Training Fold 4:  95%|█████████▌| 95/100 [00:48&lt;00:02,  2.02 epochs/s, Training Loss=8.8e-6, Validation Loss=1.2e-5, Best Loss=1.01e-5]
Training Fold 4:  96%|█████████▌| 96/100 [00:48&lt;00:02,  1.99 epochs/s, Training Loss=8.8e-6, Validation Loss=1.2e-5, Best Loss=1.01e-5]
Training Fold 4:  96%|█████████▌| 96/100 [00:48&lt;00:02,  1.99 epochs/s, Training Loss=7.55e-6, Validation Loss=1.17e-5, Best Loss=1.01e-5]
Training Fold 4:  97%|█████████▋| 97/100 [00:48&lt;00:01,  2.01 epochs/s, Training Loss=7.55e-6, Validation Loss=1.17e-5, Best Loss=1.01e-5]
Training Fold 4:  97%|█████████▋| 97/100 [00:49&lt;00:01,  2.01 epochs/s, Training Loss=7.52e-6, Validation Loss=1.08e-5, Best Loss=1.01e-5]
Training Fold 4:  98%|█████████▊| 98/100 [00:49&lt;00:01,  1.96 epochs/s, Training Loss=7.52e-6, Validation Loss=1.08e-5, Best Loss=1.01e-5]
Training Fold 4:  98%|█████████▊| 98/100 [00:49&lt;00:01,  1.96 epochs/s, Training Loss=8.89e-6, Validation Loss=1.25e-5, Best Loss=1.01e-5]
Training Fold 4:  99%|█████████▉| 99/100 [00:49&lt;00:00,  1.98 epochs/s, Training Loss=8.89e-6, Validation Loss=1.25e-5, Best Loss=1.01e-5]
Training Fold 4:  99%|█████████▉| 99/100 [00:50&lt;00:00,  1.98 epochs/s, Training Loss=7.65e-6, Validation Loss=1.14e-5, Best Loss=1.01e-5]
Training Fold 4: 100%|██████████| 100/100 [00:50&lt;00:00,  2.02 epochs/s, Training Loss=7.65e-6, Validation Loss=1.14e-5, Best Loss=1.01e-5]
Training Fold 4: 100%|██████████| 100/100 [00:50&lt;00:00,  2.00 epochs/s, Training Loss=7.65e-6, Validation Loss=1.14e-5, Best Loss=1.01e-5]

  0%|          | 0/100 [00:00&lt;?, ? epochs/s]
Training Fold 5:   0%|          | 0/100 [00:00&lt;?, ? epochs/s]
Training Fold 5:   0%|          | 0/100 [00:00&lt;?, ? epochs/s, Training Loss=1.05e-5, Validation Loss=7.88e-6, Best Loss=7.88e-6]
Training Fold 5:   1%|          | 1/100 [00:00&lt;00:47,  2.10 epochs/s, Training Loss=1.05e-5, Validation Loss=7.88e-6, Best Loss=7.88e-6]
Training Fold 5:   1%|          | 1/100 [00:01&lt;00:47,  2.10 epochs/s, Training Loss=8.65e-6, Validation Loss=7.24e-6, Best Loss=7.24e-6]
Training Fold 5:   2%|▏         | 2/100 [00:01&lt;00:49,  1.98 epochs/s, Training Loss=8.65e-6, Validation Loss=7.24e-6, Best Loss=7.24e-6]
Training Fold 5:   2%|▏         | 2/100 [00:01&lt;00:49,  1.98 epochs/s, Training Loss=1.07e-5, Validation Loss=1.05e-5, Best Loss=7.24e-6]
Training Fold 5:   3%|▎         | 3/100 [00:01&lt;00:48,  2.00 epochs/s, Training Loss=1.07e-5, Validation Loss=1.05e-5, Best Loss=7.24e-6]
Training Fold 5:   3%|▎         | 3/100 [00:02&lt;00:48,  2.00 epochs/s, Training Loss=8.93e-6, Validation Loss=7.4e-6, Best Loss=7.24e-6]
Training Fold 5:   4%|▍         | 4/100 [00:02&lt;00:48,  1.99 epochs/s, Training Loss=8.93e-6, Validation Loss=7.4e-6, Best Loss=7.24e-6]
Training Fold 5:   4%|▍         | 4/100 [00:02&lt;00:48,  1.99 epochs/s, Training Loss=8.74e-6, Validation Loss=8e-6, Best Loss=7.24e-6]
Training Fold 5:   5%|▌         | 5/100 [00:02&lt;00:46,  2.03 epochs/s, Training Loss=8.74e-6, Validation Loss=8e-6, Best Loss=7.24e-6]
Training Fold 5:   5%|▌         | 5/100 [00:02&lt;00:46,  2.03 epochs/s, Training Loss=9.42e-6, Validation Loss=8.63e-6, Best Loss=7.24e-6]
Training Fold 5:   6%|▌         | 6/100 [00:02&lt;00:45,  2.05 epochs/s, Training Loss=9.42e-6, Validation Loss=8.63e-6, Best Loss=7.24e-6]
Training Fold 5:   6%|▌         | 6/100 [00:03&lt;00:45,  2.05 epochs/s, Training Loss=1.01e-5, Validation Loss=9.37e-6, Best Loss=7.24e-6]
Training Fold 5:   7%|▋         | 7/100 [00:03&lt;00:46,  1.99 epochs/s, Training Loss=1.01e-5, Validation Loss=9.37e-6, Best Loss=7.24e-6]
Training Fold 5:   7%|▋         | 7/100 [00:03&lt;00:46,  1.99 epochs/s, Training Loss=8.54e-6, Validation Loss=7.43e-6, Best Loss=7.24e-6]
Training Fold 5:   8%|▊         | 8/100 [00:03&lt;00:46,  1.98 epochs/s, Training Loss=8.54e-6, Validation Loss=7.43e-6, Best Loss=7.24e-6]
Training Fold 5:   8%|▊         | 8/100 [00:04&lt;00:46,  1.98 epochs/s, Training Loss=1.08e-5, Validation Loss=1.12e-5, Best Loss=7.24e-6]
Training Fold 5:   9%|▉         | 9/100 [00:04&lt;00:46,  1.98 epochs/s, Training Loss=1.08e-5, Validation Loss=1.12e-5, Best Loss=7.24e-6]
Training Fold 5:   9%|▉         | 9/100 [00:05&lt;00:46,  1.98 epochs/s, Training Loss=9.2e-6, Validation Loss=9.11e-6, Best Loss=7.24e-6]
Training Fold 5:  10%|█         | 10/100 [00:05&lt;00:46,  1.95 epochs/s, Training Loss=9.2e-6, Validation Loss=9.11e-6, Best Loss=7.24e-6]
Training Fold 5:  10%|█         | 10/100 [00:05&lt;00:46,  1.95 epochs/s, Training Loss=8.23e-6, Validation Loss=8.3e-6, Best Loss=7.24e-6]
Training Fold 5:  11%|█         | 11/100 [00:05&lt;00:45,  1.96 epochs/s, Training Loss=8.23e-6, Validation Loss=8.3e-6, Best Loss=7.24e-6]
Training Fold 5:  11%|█         | 11/100 [00:06&lt;00:45,  1.96 epochs/s, Training Loss=1e-5, Validation Loss=9.5e-6, Best Loss=7.24e-6]
Training Fold 5:  12%|█▏        | 12/100 [00:06&lt;00:45,  1.95 epochs/s, Training Loss=1e-5, Validation Loss=9.5e-6, Best Loss=7.24e-6]
Training Fold 5:  12%|█▏        | 12/100 [00:06&lt;00:45,  1.95 epochs/s, Training Loss=9.88e-6, Validation Loss=8.61e-6, Best Loss=7.24e-6]
Training Fold 5:  13%|█▎        | 13/100 [00:06&lt;00:44,  1.96 epochs/s, Training Loss=9.88e-6, Validation Loss=8.61e-6, Best Loss=7.24e-6]
Training Fold 5:  13%|█▎        | 13/100 [00:07&lt;00:44,  1.96 epochs/s, Training Loss=1.51e-5, Validation Loss=1.54e-5, Best Loss=7.24e-6]
Training Fold 5:  14%|█▍        | 14/100 [00:07&lt;00:43,  1.96 epochs/s, Training Loss=1.51e-5, Validation Loss=1.54e-5, Best Loss=7.24e-6]
Training Fold 5:  14%|█▍        | 14/100 [00:07&lt;00:43,  1.96 epochs/s, Training Loss=8.55e-6, Validation Loss=8.44e-6, Best Loss=7.24e-6]
Training Fold 5:  15%|█▌        | 15/100 [00:07&lt;00:43,  1.94 epochs/s, Training Loss=8.55e-6, Validation Loss=8.44e-6, Best Loss=7.24e-6]
Training Fold 5:  15%|█▌        | 15/100 [00:08&lt;00:43,  1.94 epochs/s, Training Loss=8.13e-6, Validation Loss=8.08e-6, Best Loss=7.24e-6]
Training Fold 5:  16%|█▌        | 16/100 [00:08&lt;00:42,  1.96 epochs/s, Training Loss=8.13e-6, Validation Loss=8.08e-6, Best Loss=7.24e-6]
Training Fold 5:  16%|█▌        | 16/100 [00:08&lt;00:42,  1.96 epochs/s, Training Loss=7.29e-6, Validation Loss=7.58e-6, Best Loss=7.24e-6]
Training Fold 5:  17%|█▋        | 17/100 [00:08&lt;00:42,  1.93 epochs/s, Training Loss=7.29e-6, Validation Loss=7.58e-6, Best Loss=7.24e-6]
Training Fold 5:  17%|█▋        | 17/100 [00:09&lt;00:42,  1.93 epochs/s, Training Loss=8.21e-6, Validation Loss=8.65e-6, Best Loss=7.24e-6]
Training Fold 5:  18%|█▊        | 18/100 [00:09&lt;00:42,  1.94 epochs/s, Training Loss=8.21e-6, Validation Loss=8.65e-6, Best Loss=7.24e-6]
Training Fold 5:  18%|█▊        | 18/100 [00:09&lt;00:42,  1.94 epochs/s, Training Loss=8.51e-6, Validation Loss=8.71e-6, Best Loss=7.24e-6]
Training Fold 5:  19%|█▉        | 19/100 [00:09&lt;00:41,  1.93 epochs/s, Training Loss=8.51e-6, Validation Loss=8.71e-6, Best Loss=7.24e-6]
Training Fold 5:  19%|█▉        | 19/100 [00:10&lt;00:41,  1.93 epochs/s, Training Loss=8.58e-6, Validation Loss=7.76e-6, Best Loss=7.24e-6]
Training Fold 5:  20%|██        | 20/100 [00:10&lt;00:40,  1.95 epochs/s, Training Loss=8.58e-6, Validation Loss=7.76e-6, Best Loss=7.24e-6]
Training Fold 5:  20%|██        | 20/100 [00:10&lt;00:40,  1.95 epochs/s, Training Loss=7.71e-6, Validation Loss=8.87e-6, Best Loss=7.24e-6]
Training Fold 5:  21%|██        | 21/100 [00:10&lt;00:40,  1.93 epochs/s, Training Loss=7.71e-6, Validation Loss=8.87e-6, Best Loss=7.24e-6]
Training Fold 5:  21%|██        | 21/100 [00:11&lt;00:40,  1.93 epochs/s, Training Loss=8.13e-6, Validation Loss=8.06e-6, Best Loss=7.24e-6]
Training Fold 5:  22%|██▏       | 22/100 [00:11&lt;00:40,  1.95 epochs/s, Training Loss=8.13e-6, Validation Loss=8.06e-6, Best Loss=7.24e-6]
Training Fold 5:  22%|██▏       | 22/100 [00:11&lt;00:40,  1.95 epochs/s, Training Loss=2.82e-5, Validation Loss=2.6e-5, Best Loss=7.24e-6]
Training Fold 5:  23%|██▎       | 23/100 [00:11&lt;00:39,  1.94 epochs/s, Training Loss=2.82e-5, Validation Loss=2.6e-5, Best Loss=7.24e-6]
Training Fold 5:  23%|██▎       | 23/100 [00:12&lt;00:39,  1.94 epochs/s, Training Loss=1.16e-5, Validation Loss=1.08e-5, Best Loss=7.24e-6]
Training Fold 5:  24%|██▍       | 24/100 [00:12&lt;00:39,  1.94 epochs/s, Training Loss=1.16e-5, Validation Loss=1.08e-5, Best Loss=7.24e-6]
Training Fold 5:  24%|██▍       | 24/100 [00:12&lt;00:39,  1.94 epochs/s, Training Loss=9.62e-6, Validation Loss=1.01e-5, Best Loss=7.24e-6]
Training Fold 5:  25%|██▌       | 25/100 [00:12&lt;00:38,  1.96 epochs/s, Training Loss=9.62e-6, Validation Loss=1.01e-5, Best Loss=7.24e-6]
Training Fold 5:  25%|██▌       | 25/100 [00:13&lt;00:38,  1.96 epochs/s, Training Loss=8.79e-6, Validation Loss=8.38e-6, Best Loss=7.24e-6]
Training Fold 5:  26%|██▌       | 26/100 [00:13&lt;00:37,  1.97 epochs/s, Training Loss=8.79e-6, Validation Loss=8.38e-6, Best Loss=7.24e-6]
Training Fold 5:  26%|██▌       | 26/100 [00:13&lt;00:37,  1.97 epochs/s, Training Loss=9.37e-6, Validation Loss=9.16e-6, Best Loss=7.24e-6]
Training Fold 5:  27%|██▋       | 27/100 [00:13&lt;00:37,  1.96 epochs/s, Training Loss=9.37e-6, Validation Loss=9.16e-6, Best Loss=7.24e-6]
Training Fold 5:  27%|██▋       | 27/100 [00:14&lt;00:37,  1.96 epochs/s, Training Loss=9.65e-6, Validation Loss=9.28e-6, Best Loss=7.24e-6]
Training Fold 5:  28%|██▊       | 28/100 [00:14&lt;00:36,  1.97 epochs/s, Training Loss=9.65e-6, Validation Loss=9.28e-6, Best Loss=7.24e-6]
Training Fold 5:  28%|██▊       | 28/100 [00:14&lt;00:36,  1.97 epochs/s, Training Loss=8.2e-6, Validation Loss=8.76e-6, Best Loss=7.24e-6]
Training Fold 5:  29%|██▉       | 29/100 [00:14&lt;00:36,  1.96 epochs/s, Training Loss=8.2e-6, Validation Loss=8.76e-6, Best Loss=7.24e-6]
Training Fold 5:  29%|██▉       | 29/100 [00:15&lt;00:36,  1.96 epochs/s, Training Loss=8.88e-6, Validation Loss=9.18e-6, Best Loss=7.24e-6]
Training Fold 5:  30%|███       | 30/100 [00:15&lt;00:35,  1.96 epochs/s, Training Loss=8.88e-6, Validation Loss=9.18e-6, Best Loss=7.24e-6]
Training Fold 5:  30%|███       | 30/100 [00:15&lt;00:35,  1.96 epochs/s, Training Loss=8.07e-6, Validation Loss=8.03e-6, Best Loss=7.24e-6]
Training Fold 5:  31%|███       | 31/100 [00:15&lt;00:35,  1.93 epochs/s, Training Loss=8.07e-6, Validation Loss=8.03e-6, Best Loss=7.24e-6]
Training Fold 5:  31%|███       | 31/100 [00:16&lt;00:35,  1.93 epochs/s, Training Loss=9.08e-6, Validation Loss=8.29e-6, Best Loss=7.24e-6]
Training Fold 5:  32%|███▏      | 32/100 [00:16&lt;00:35,  1.90 epochs/s, Training Loss=9.08e-6, Validation Loss=8.29e-6, Best Loss=7.24e-6]
Training Fold 5:  32%|███▏      | 32/100 [00:16&lt;00:35,  1.90 epochs/s, Training Loss=2.58e-5, Validation Loss=2.63e-5, Best Loss=7.24e-6]
Training Fold 5:  33%|███▎      | 33/100 [00:16&lt;00:35,  1.90 epochs/s, Training Loss=2.58e-5, Validation Loss=2.63e-5, Best Loss=7.24e-6]
Training Fold 5:  33%|███▎      | 33/100 [00:17&lt;00:35,  1.90 epochs/s, Training Loss=9.11e-6, Validation Loss=9.45e-6, Best Loss=7.24e-6]
Training Fold 5:  34%|███▍      | 34/100 [00:17&lt;00:33,  1.94 epochs/s, Training Loss=9.11e-6, Validation Loss=9.45e-6, Best Loss=7.24e-6]
Training Fold 5:  34%|███▍      | 34/100 [00:17&lt;00:33,  1.94 epochs/s, Training Loss=8.52e-6, Validation Loss=1.06e-5, Best Loss=7.24e-6]
Training Fold 5:  35%|███▌      | 35/100 [00:17&lt;00:33,  1.94 epochs/s, Training Loss=8.52e-6, Validation Loss=1.06e-5, Best Loss=7.24e-6]
Training Fold 5:  35%|███▌      | 35/100 [00:18&lt;00:33,  1.94 epochs/s, Training Loss=1.29e-5, Validation Loss=1.49e-5, Best Loss=7.24e-6]
Training Fold 5:  36%|███▌      | 36/100 [00:18&lt;00:32,  1.97 epochs/s, Training Loss=1.29e-5, Validation Loss=1.49e-5, Best Loss=7.24e-6]
Training Fold 5:  36%|███▌      | 36/100 [00:18&lt;00:32,  1.97 epochs/s, Training Loss=1.05e-5, Validation Loss=1.22e-5, Best Loss=7.24e-6]
Training Fold 5:  37%|███▋      | 37/100 [00:18&lt;00:31,  1.97 epochs/s, Training Loss=1.05e-5, Validation Loss=1.22e-5, Best Loss=7.24e-6]
Training Fold 5:  37%|███▋      | 37/100 [00:19&lt;00:31,  1.97 epochs/s, Training Loss=8.49e-6, Validation Loss=1.09e-5, Best Loss=7.24e-6]
Training Fold 5:  38%|███▊      | 38/100 [00:19&lt;00:31,  1.97 epochs/s, Training Loss=8.49e-6, Validation Loss=1.09e-5, Best Loss=7.24e-6]
Training Fold 5:  38%|███▊      | 38/100 [00:19&lt;00:31,  1.97 epochs/s, Training Loss=7.56e-6, Validation Loss=7.97e-6, Best Loss=7.24e-6]
Training Fold 5:  39%|███▉      | 39/100 [00:19&lt;00:32,  1.89 epochs/s, Training Loss=7.56e-6, Validation Loss=7.97e-6, Best Loss=7.24e-6]
Training Fold 5:  39%|███▉      | 39/100 [00:20&lt;00:32,  1.89 epochs/s, Training Loss=9.49e-6, Validation Loss=8.68e-6, Best Loss=7.24e-6]
Training Fold 5:  40%|████      | 40/100 [00:20&lt;00:31,  1.88 epochs/s, Training Loss=9.49e-6, Validation Loss=8.68e-6, Best Loss=7.24e-6]
Training Fold 5:  40%|████      | 40/100 [00:21&lt;00:31,  1.88 epochs/s, Training Loss=7.79e-6, Validation Loss=9.97e-6, Best Loss=7.24e-6]
Training Fold 5:  41%|████      | 41/100 [00:21&lt;00:31,  1.88 epochs/s, Training Loss=7.79e-6, Validation Loss=9.97e-6, Best Loss=7.24e-6]
Training Fold 5:  41%|████      | 41/100 [00:21&lt;00:31,  1.88 epochs/s, Training Loss=2.36e-5, Validation Loss=2.42e-5, Best Loss=7.24e-6]
Training Fold 5:  42%|████▏     | 42/100 [00:21&lt;00:30,  1.89 epochs/s, Training Loss=2.36e-5, Validation Loss=2.42e-5, Best Loss=7.24e-6]
Training Fold 5:  42%|████▏     | 42/100 [00:22&lt;00:30,  1.89 epochs/s, Training Loss=9.95e-6, Validation Loss=9.36e-6, Best Loss=7.24e-6]
Training Fold 5:  43%|████▎     | 43/100 [00:22&lt;00:29,  1.90 epochs/s, Training Loss=9.95e-6, Validation Loss=9.36e-6, Best Loss=7.24e-6]
Training Fold 5:  43%|████▎     | 43/100 [00:22&lt;00:29,  1.90 epochs/s, Training Loss=1.16e-5, Validation Loss=1.35e-5, Best Loss=7.24e-6]
Training Fold 5:  44%|████▍     | 44/100 [00:22&lt;00:29,  1.90 epochs/s, Training Loss=1.16e-5, Validation Loss=1.35e-5, Best Loss=7.24e-6]
Training Fold 5:  44%|████▍     | 44/100 [00:23&lt;00:29,  1.90 epochs/s, Training Loss=7.61e-6, Validation Loss=8.38e-6, Best Loss=7.24e-6]
Training Fold 5:  45%|████▌     | 45/100 [00:23&lt;00:28,  1.92 epochs/s, Training Loss=7.61e-6, Validation Loss=8.38e-6, Best Loss=7.24e-6]
Training Fold 5:  45%|████▌     | 45/100 [00:23&lt;00:28,  1.92 epochs/s, Training Loss=7.49e-6, Validation Loss=9.17e-6, Best Loss=7.24e-6]
Training Fold 5:  46%|████▌     | 46/100 [00:23&lt;00:27,  1.93 epochs/s, Training Loss=7.49e-6, Validation Loss=9.17e-6, Best Loss=7.24e-6]
Training Fold 5:  46%|████▌     | 46/100 [00:24&lt;00:27,  1.93 epochs/s, Training Loss=7.16e-6, Validation Loss=8.59e-6, Best Loss=7.24e-6]
Training Fold 5:  47%|████▋     | 47/100 [00:24&lt;00:27,  1.92 epochs/s, Training Loss=7.16e-6, Validation Loss=8.59e-6, Best Loss=7.24e-6]
Training Fold 5:  47%|████▋     | 47/100 [00:24&lt;00:27,  1.92 epochs/s, Training Loss=8.27e-6, Validation Loss=9.89e-6, Best Loss=7.24e-6]
Training Fold 5:  48%|████▊     | 48/100 [00:24&lt;00:27,  1.91 epochs/s, Training Loss=8.27e-6, Validation Loss=9.89e-6, Best Loss=7.24e-6]
Training Fold 5:  48%|████▊     | 48/100 [00:25&lt;00:27,  1.91 epochs/s, Training Loss=9.11e-6, Validation Loss=1.09e-5, Best Loss=7.24e-6]
Training Fold 5:  49%|████▉     | 49/100 [00:25&lt;00:26,  1.96 epochs/s, Training Loss=9.11e-6, Validation Loss=1.09e-5, Best Loss=7.24e-6]
Training Fold 5:  49%|████▉     | 49/100 [00:25&lt;00:26,  1.96 epochs/s, Training Loss=7.65e-6, Validation Loss=8.76e-6, Best Loss=7.24e-6]
Training Fold 5:  50%|█████     | 50/100 [00:25&lt;00:25,  1.98 epochs/s, Training Loss=7.65e-6, Validation Loss=8.76e-6, Best Loss=7.24e-6]
Training Fold 5:  50%|█████     | 50/100 [00:26&lt;00:25,  1.98 epochs/s, Training Loss=7.11e-6, Validation Loss=9.04e-6, Best Loss=7.24e-6]
Training Fold 5:  51%|█████     | 51/100 [00:26&lt;00:25,  1.95 epochs/s, Training Loss=7.11e-6, Validation Loss=9.04e-6, Best Loss=7.24e-6]
Training Fold 5:  51%|█████     | 51/100 [00:26&lt;00:25,  1.95 epochs/s, Training Loss=6.98e-6, Validation Loss=8.62e-6, Best Loss=7.24e-6]
Training Fold 5:  52%|█████▏    | 52/100 [00:26&lt;00:24,  1.96 epochs/s, Training Loss=6.98e-6, Validation Loss=8.62e-6, Best Loss=7.24e-6]
Training Fold 5:  52%|█████▏    | 52/100 [00:27&lt;00:24,  1.96 epochs/s, Training Loss=1.3e-5, Validation Loss=1.52e-5, Best Loss=7.24e-6]
Training Fold 5:  53%|█████▎    | 53/100 [00:27&lt;00:24,  1.94 epochs/s, Training Loss=1.3e-5, Validation Loss=1.52e-5, Best Loss=7.24e-6]
Training Fold 5:  53%|█████▎    | 53/100 [00:27&lt;00:24,  1.94 epochs/s, Training Loss=7.92e-6, Validation Loss=1.06e-5, Best Loss=7.24e-6]
Training Fold 5:  54%|█████▍    | 54/100 [00:27&lt;00:23,  1.94 epochs/s, Training Loss=7.92e-6, Validation Loss=1.06e-5, Best Loss=7.24e-6]
Training Fold 5:  54%|█████▍    | 54/100 [00:28&lt;00:23,  1.94 epochs/s, Training Loss=7.61e-6, Validation Loss=8.84e-6, Best Loss=7.24e-6]
Training Fold 5:  55%|█████▌    | 55/100 [00:28&lt;00:22,  1.96 epochs/s, Training Loss=7.61e-6, Validation Loss=8.84e-6, Best Loss=7.24e-6]
Training Fold 5:  55%|█████▌    | 55/100 [00:28&lt;00:22,  1.96 epochs/s, Training Loss=8.13e-6, Validation Loss=9.54e-6, Best Loss=7.24e-6]
Training Fold 5:  56%|█████▌    | 56/100 [00:28&lt;00:22,  1.96 epochs/s, Training Loss=8.13e-6, Validation Loss=9.54e-6, Best Loss=7.24e-6]
Training Fold 5:  56%|█████▌    | 56/100 [00:29&lt;00:22,  1.96 epochs/s, Training Loss=8.76e-6, Validation Loss=1.01e-5, Best Loss=7.24e-6]
Training Fold 5:  57%|█████▋    | 57/100 [00:29&lt;00:22,  1.95 epochs/s, Training Loss=8.76e-6, Validation Loss=1.01e-5, Best Loss=7.24e-6]
Training Fold 5:  57%|█████▋    | 57/100 [00:29&lt;00:22,  1.95 epochs/s, Training Loss=7.8e-6, Validation Loss=1.05e-5, Best Loss=7.24e-6]
Training Fold 5:  58%|█████▊    | 58/100 [00:29&lt;00:22,  1.89 epochs/s, Training Loss=7.8e-6, Validation Loss=1.05e-5, Best Loss=7.24e-6]
Training Fold 5:  58%|█████▊    | 58/100 [00:30&lt;00:22,  1.89 epochs/s, Training Loss=7.11e-6, Validation Loss=9.32e-6, Best Loss=7.24e-6]
Training Fold 5:  59%|█████▉    | 59/100 [00:30&lt;00:27,  1.47 epochs/s, Training Loss=7.11e-6, Validation Loss=9.32e-6, Best Loss=7.24e-6]
Training Fold 5:  59%|█████▉    | 59/100 [00:31&lt;00:27,  1.47 epochs/s, Training Loss=2.39e-5, Validation Loss=2.47e-5, Best Loss=7.24e-6]
Training Fold 5:  60%|██████    | 60/100 [00:31&lt;00:25,  1.57 epochs/s, Training Loss=2.39e-5, Validation Loss=2.47e-5, Best Loss=7.24e-6]
Training Fold 5:  60%|██████    | 60/100 [00:32&lt;00:25,  1.57 epochs/s, Training Loss=8.81e-6, Validation Loss=1.03e-5, Best Loss=7.24e-6]
Training Fold 5:  61%|██████    | 61/100 [00:32&lt;00:24,  1.57 epochs/s, Training Loss=8.81e-6, Validation Loss=1.03e-5, Best Loss=7.24e-6]
Training Fold 5:  61%|██████    | 61/100 [00:32&lt;00:24,  1.57 epochs/s, Training Loss=1.6e-5, Validation Loss=1.85e-5, Best Loss=7.24e-6]
Training Fold 5:  62%|██████▏   | 62/100 [00:32&lt;00:23,  1.61 epochs/s, Training Loss=1.6e-5, Validation Loss=1.85e-5, Best Loss=7.24e-6]
Training Fold 5:  62%|██████▏   | 62/100 [00:33&lt;00:23,  1.61 epochs/s, Training Loss=7.74e-6, Validation Loss=8.84e-6, Best Loss=7.24e-6]
Training Fold 5:  63%|██████▎   | 63/100 [00:33&lt;00:23,  1.57 epochs/s, Training Loss=7.74e-6, Validation Loss=8.84e-6, Best Loss=7.24e-6]
Training Fold 5:  63%|██████▎   | 63/100 [00:34&lt;00:23,  1.57 epochs/s, Training Loss=7.48e-6, Validation Loss=9.38e-6, Best Loss=7.24e-6]
Training Fold 5:  64%|██████▍   | 64/100 [00:34&lt;00:25,  1.43 epochs/s, Training Loss=7.48e-6, Validation Loss=9.38e-6, Best Loss=7.24e-6]
Training Fold 5:  64%|██████▍   | 64/100 [00:34&lt;00:25,  1.43 epochs/s, Training Loss=7.58e-6, Validation Loss=9.2e-6, Best Loss=7.24e-6]
Training Fold 5:  65%|██████▌   | 65/100 [00:34&lt;00:23,  1.51 epochs/s, Training Loss=7.58e-6, Validation Loss=9.2e-6, Best Loss=7.24e-6]
Training Fold 5:  65%|██████▌   | 65/100 [00:35&lt;00:23,  1.51 epochs/s, Training Loss=7.16e-6, Validation Loss=9.26e-6, Best Loss=7.24e-6]
Training Fold 5:  66%|██████▌   | 66/100 [00:35&lt;00:21,  1.60 epochs/s, Training Loss=7.16e-6, Validation Loss=9.26e-6, Best Loss=7.24e-6]
Training Fold 5:  66%|██████▌   | 66/100 [00:36&lt;00:21,  1.60 epochs/s, Training Loss=6.52e-6, Validation Loss=8.16e-6, Best Loss=7.24e-6]
Training Fold 5:  67%|██████▋   | 67/100 [00:36&lt;00:23,  1.41 epochs/s, Training Loss=6.52e-6, Validation Loss=8.16e-6, Best Loss=7.24e-6]
Training Fold 5:  67%|██████▋   | 67/100 [00:37&lt;00:23,  1.41 epochs/s, Training Loss=9.04e-6, Validation Loss=1.28e-5, Best Loss=7.24e-6]
Training Fold 5:  68%|██████▊   | 68/100 [00:37&lt;00:26,  1.23 epochs/s, Training Loss=9.04e-6, Validation Loss=1.28e-5, Best Loss=7.24e-6]
Training Fold 5:  68%|██████▊   | 68/100 [00:37&lt;00:26,  1.23 epochs/s, Training Loss=7.14e-6, Validation Loss=9.34e-6, Best Loss=7.24e-6]
Training Fold 5:  69%|██████▉   | 69/100 [00:37&lt;00:22,  1.36 epochs/s, Training Loss=7.14e-6, Validation Loss=9.34e-6, Best Loss=7.24e-6]
Training Fold 5:  69%|██████▉   | 69/100 [00:38&lt;00:22,  1.36 epochs/s, Training Loss=7.44e-6, Validation Loss=8.84e-6, Best Loss=7.24e-6]
Training Fold 5:  70%|███████   | 70/100 [00:38&lt;00:20,  1.46 epochs/s, Training Loss=7.44e-6, Validation Loss=8.84e-6, Best Loss=7.24e-6]
Training Fold 5:  70%|███████   | 70/100 [00:38&lt;00:20,  1.46 epochs/s, Training Loss=6.97e-6, Validation Loss=8.86e-6, Best Loss=7.24e-6]
Training Fold 5:  71%|███████   | 71/100 [00:38&lt;00:19,  1.52 epochs/s, Training Loss=6.97e-6, Validation Loss=8.86e-6, Best Loss=7.24e-6]
Training Fold 5:  71%|███████   | 71/100 [00:39&lt;00:19,  1.52 epochs/s, Training Loss=1.19e-5, Validation Loss=1.53e-5, Best Loss=7.24e-6]
Training Fold 5:  72%|███████▏  | 72/100 [00:39&lt;00:19,  1.44 epochs/s, Training Loss=1.19e-5, Validation Loss=1.53e-5, Best Loss=7.24e-6]
Training Fold 5:  72%|███████▏  | 72/100 [00:40&lt;00:19,  1.44 epochs/s, Training Loss=7.19e-6, Validation Loss=9.23e-6, Best Loss=7.24e-6]
Training Fold 5:  73%|███████▎  | 73/100 [00:40&lt;00:18,  1.46 epochs/s, Training Loss=7.19e-6, Validation Loss=9.23e-6, Best Loss=7.24e-6]
Training Fold 5:  73%|███████▎  | 73/100 [00:41&lt;00:18,  1.46 epochs/s, Training Loss=6.52e-6, Validation Loss=8.92e-6, Best Loss=7.24e-6]
Training Fold 5:  74%|███████▍  | 74/100 [00:41&lt;00:18,  1.39 epochs/s, Training Loss=6.52e-6, Validation Loss=8.92e-6, Best Loss=7.24e-6]
Training Fold 5:  74%|███████▍  | 74/100 [00:41&lt;00:18,  1.39 epochs/s, Training Loss=6.34e-6, Validation Loss=8.9e-6, Best Loss=7.24e-6]
Training Fold 5:  75%|███████▌  | 75/100 [00:41&lt;00:17,  1.47 epochs/s, Training Loss=6.34e-6, Validation Loss=8.9e-6, Best Loss=7.24e-6]
Training Fold 5:  75%|███████▌  | 75/100 [00:42&lt;00:17,  1.47 epochs/s, Training Loss=8e-6, Validation Loss=9.99e-6, Best Loss=7.24e-6]
Training Fold 5:  76%|███████▌  | 76/100 [00:42&lt;00:15,  1.54 epochs/s, Training Loss=8e-6, Validation Loss=9.99e-6, Best Loss=7.24e-6]
Training Fold 5:  76%|███████▌  | 76/100 [00:42&lt;00:15,  1.54 epochs/s, Training Loss=1.03e-5, Validation Loss=1.19e-5, Best Loss=7.24e-6]
Training Fold 5:  77%|███████▋  | 77/100 [00:42&lt;00:14,  1.59 epochs/s, Training Loss=1.03e-5, Validation Loss=1.19e-5, Best Loss=7.24e-6]
Training Fold 5:  77%|███████▋  | 77/100 [00:43&lt;00:14,  1.59 epochs/s, Training Loss=8.13e-6, Validation Loss=1.02e-5, Best Loss=7.24e-6]
Training Fold 5:  78%|███████▊  | 78/100 [00:43&lt;00:13,  1.67 epochs/s, Training Loss=8.13e-6, Validation Loss=1.02e-5, Best Loss=7.24e-6]
Training Fold 5:  78%|███████▊  | 78/100 [00:44&lt;00:13,  1.67 epochs/s, Training Loss=8.52e-6, Validation Loss=1e-5, Best Loss=7.24e-6]
Training Fold 5:  79%|███████▉  | 79/100 [00:44&lt;00:12,  1.69 epochs/s, Training Loss=8.52e-6, Validation Loss=1e-5, Best Loss=7.24e-6]
Training Fold 5:  79%|███████▉  | 79/100 [00:44&lt;00:12,  1.69 epochs/s, Training Loss=7.1e-6, Validation Loss=8.58e-6, Best Loss=7.24e-6]
Training Fold 5:  80%|████████  | 80/100 [00:44&lt;00:11,  1.74 epochs/s, Training Loss=7.1e-6, Validation Loss=8.58e-6, Best Loss=7.24e-6]
Training Fold 5:  80%|████████  | 80/100 [00:45&lt;00:11,  1.74 epochs/s, Training Loss=6.81e-6, Validation Loss=9.23e-6, Best Loss=7.24e-6]
Training Fold 5:  81%|████████  | 81/100 [00:45&lt;00:10,  1.77 epochs/s, Training Loss=6.81e-6, Validation Loss=9.23e-6, Best Loss=7.24e-6]
Training Fold 5:  81%|████████  | 81/100 [00:45&lt;00:10,  1.77 epochs/s, Training Loss=6.79e-6, Validation Loss=9.37e-6, Best Loss=7.24e-6]
Training Fold 5:  82%|████████▏ | 82/100 [00:45&lt;00:10,  1.76 epochs/s, Training Loss=6.79e-6, Validation Loss=9.37e-6, Best Loss=7.24e-6]
Training Fold 5:  82%|████████▏ | 82/100 [00:46&lt;00:10,  1.76 epochs/s, Training Loss=6.82e-6, Validation Loss=8.77e-6, Best Loss=7.24e-6]
Training Fold 5:  83%|████████▎ | 83/100 [00:46&lt;00:09,  1.72 epochs/s, Training Loss=6.82e-6, Validation Loss=8.77e-6, Best Loss=7.24e-6]
Training Fold 5:  83%|████████▎ | 83/100 [00:46&lt;00:09,  1.72 epochs/s, Training Loss=8.9e-6, Validation Loss=9.54e-6, Best Loss=7.24e-6]
Training Fold 5:  84%|████████▍ | 84/100 [00:46&lt;00:09,  1.77 epochs/s, Training Loss=8.9e-6, Validation Loss=9.54e-6, Best Loss=7.24e-6]
Training Fold 5:  84%|████████▍ | 84/100 [00:47&lt;00:09,  1.77 epochs/s, Training Loss=1e-5, Validation Loss=1.13e-5, Best Loss=7.24e-6]
Training Fold 5:  85%|████████▌ | 85/100 [00:47&lt;00:08,  1.80 epochs/s, Training Loss=1e-5, Validation Loss=1.13e-5, Best Loss=7.24e-6]
Training Fold 5:  85%|████████▌ | 85/100 [00:47&lt;00:08,  1.80 epochs/s, Training Loss=8.05e-6, Validation Loss=1.17e-5, Best Loss=7.24e-6]
Training Fold 5:  86%|████████▌ | 86/100 [00:47&lt;00:07,  1.82 epochs/s, Training Loss=8.05e-6, Validation Loss=1.17e-5, Best Loss=7.24e-6]
Training Fold 5:  86%|████████▌ | 86/100 [00:48&lt;00:07,  1.82 epochs/s, Training Loss=7.36e-6, Validation Loss=9.45e-6, Best Loss=7.24e-6]
Training Fold 5:  87%|████████▋ | 87/100 [00:48&lt;00:07,  1.81 epochs/s, Training Loss=7.36e-6, Validation Loss=9.45e-6, Best Loss=7.24e-6]
Training Fold 5:  87%|████████▋ | 87/100 [00:48&lt;00:07,  1.81 epochs/s, Training Loss=6.86e-6, Validation Loss=7.97e-6, Best Loss=7.24e-6]
Training Fold 5:  88%|████████▊ | 88/100 [00:48&lt;00:06,  1.84 epochs/s, Training Loss=6.86e-6, Validation Loss=7.97e-6, Best Loss=7.24e-6]
Training Fold 5:  88%|████████▊ | 88/100 [00:49&lt;00:06,  1.84 epochs/s, Training Loss=6.92e-6, Validation Loss=8.43e-6, Best Loss=7.24e-6]
Training Fold 5:  89%|████████▉ | 89/100 [00:49&lt;00:05,  1.85 epochs/s, Training Loss=6.92e-6, Validation Loss=8.43e-6, Best Loss=7.24e-6]
Training Fold 5:  89%|████████▉ | 89/100 [00:50&lt;00:05,  1.85 epochs/s, Training Loss=6.24e-6, Validation Loss=8.17e-6, Best Loss=7.24e-6]
Training Fold 5:  90%|█████████ | 90/100 [00:50&lt;00:05,  1.86 epochs/s, Training Loss=6.24e-6, Validation Loss=8.17e-6, Best Loss=7.24e-6]
Training Fold 5:  90%|█████████ | 90/100 [00:50&lt;00:05,  1.86 epochs/s, Training Loss=1.28e-5, Validation Loss=1.3e-5, Best Loss=7.24e-6]
Training Fold 5:  91%|█████████ | 91/100 [00:50&lt;00:04,  1.85 epochs/s, Training Loss=1.28e-5, Validation Loss=1.3e-5, Best Loss=7.24e-6]
Training Fold 5:  91%|█████████ | 91/100 [00:51&lt;00:04,  1.85 epochs/s, Training Loss=6.41e-6, Validation Loss=8.02e-6, Best Loss=7.24e-6]
Training Fold 5:  92%|█████████▏| 92/100 [00:51&lt;00:04,  1.87 epochs/s, Training Loss=6.41e-6, Validation Loss=8.02e-6, Best Loss=7.24e-6]
Training Fold 5:  92%|█████████▏| 92/100 [00:51&lt;00:04,  1.87 epochs/s, Training Loss=6.85e-6, Validation Loss=9.05e-6, Best Loss=7.24e-6]
Training Fold 5:  93%|█████████▎| 93/100 [00:51&lt;00:03,  1.89 epochs/s, Training Loss=6.85e-6, Validation Loss=9.05e-6, Best Loss=7.24e-6]
Training Fold 5:  93%|█████████▎| 93/100 [00:52&lt;00:03,  1.89 epochs/s, Training Loss=1.05e-5, Validation Loss=1.37e-5, Best Loss=7.24e-6]
Training Fold 5:  94%|█████████▍| 94/100 [00:52&lt;00:03,  1.89 epochs/s, Training Loss=1.05e-5, Validation Loss=1.37e-5, Best Loss=7.24e-6]
Training Fold 5:  94%|█████████▍| 94/100 [00:52&lt;00:03,  1.89 epochs/s, Training Loss=7.39e-6, Validation Loss=9.88e-6, Best Loss=7.24e-6]
Training Fold 5:  95%|█████████▌| 95/100 [00:52&lt;00:02,  1.92 epochs/s, Training Loss=7.39e-6, Validation Loss=9.88e-6, Best Loss=7.24e-6]
Training Fold 5:  95%|█████████▌| 95/100 [00:53&lt;00:02,  1.92 epochs/s, Training Loss=6.25e-6, Validation Loss=8.82e-6, Best Loss=7.24e-6]
Training Fold 5:  96%|█████████▌| 96/100 [00:53&lt;00:02,  1.92 epochs/s, Training Loss=6.25e-6, Validation Loss=8.82e-6, Best Loss=7.24e-6]
Training Fold 5:  96%|█████████▌| 96/100 [00:53&lt;00:02,  1.92 epochs/s, Training Loss=6.87e-6, Validation Loss=9.02e-6, Best Loss=7.24e-6]
Training Fold 5:  97%|█████████▋| 97/100 [00:53&lt;00:01,  1.90 epochs/s, Training Loss=6.87e-6, Validation Loss=9.02e-6, Best Loss=7.24e-6]
Training Fold 5:  97%|█████████▋| 97/100 [00:54&lt;00:01,  1.90 epochs/s, Training Loss=6.77e-6, Validation Loss=8.52e-6, Best Loss=7.24e-6]
Training Fold 5:  98%|█████████▊| 98/100 [00:54&lt;00:01,  1.88 epochs/s, Training Loss=6.77e-6, Validation Loss=8.52e-6, Best Loss=7.24e-6]
Training Fold 5:  98%|█████████▊| 98/100 [00:54&lt;00:01,  1.88 epochs/s, Training Loss=6.85e-6, Validation Loss=9.12e-6, Best Loss=7.24e-6]
Training Fold 5:  99%|█████████▉| 99/100 [00:54&lt;00:00,  1.86 epochs/s, Training Loss=6.85e-6, Validation Loss=9.12e-6, Best Loss=7.24e-6]
Training Fold 5:  99%|█████████▉| 99/100 [00:55&lt;00:00,  1.86 epochs/s, Training Loss=1.74e-5, Validation Loss=1.97e-5, Best Loss=7.24e-6]
Training Fold 5: 100%|██████████| 100/100 [00:55&lt;00:00,  1.89 epochs/s, Training Loss=1.74e-5, Validation Loss=1.97e-5, Best Loss=7.24e-6]
Training Fold 5: 100%|██████████| 100/100 [00:55&lt;00:00,  1.81 epochs/s, Training Loss=1.74e-5, Validation Loss=1.97e-5, Best Loss=7.24e-6]

  0%|          | 0/100 [00:00&lt;?, ? epochs/s]
Training Fold 6:   0%|          | 0/100 [00:00&lt;?, ? epochs/s]
Training Fold 6:   0%|          | 0/100 [00:00&lt;?, ? epochs/s, Training Loss=1.07e-5, Validation Loss=1.18e-5, Best Loss=7.24e-6]
Training Fold 6:   1%|          | 1/100 [00:00&lt;00:49,  2.00 epochs/s, Training Loss=1.07e-5, Validation Loss=1.18e-5, Best Loss=7.24e-6]
Training Fold 6:   1%|          | 1/100 [00:01&lt;00:49,  2.00 epochs/s, Training Loss=7.08e-6, Validation Loss=8.08e-6, Best Loss=7.24e-6]
Training Fold 6:   2%|▏         | 2/100 [00:01&lt;00:51,  1.91 epochs/s, Training Loss=7.08e-6, Validation Loss=8.08e-6, Best Loss=7.24e-6]
Training Fold 6:   2%|▏         | 2/100 [00:01&lt;00:51,  1.91 epochs/s, Training Loss=1.68e-5, Validation Loss=1.87e-5, Best Loss=7.24e-6]
Training Fold 6:   3%|▎         | 3/100 [00:01&lt;00:51,  1.89 epochs/s, Training Loss=1.68e-5, Validation Loss=1.87e-5, Best Loss=7.24e-6]
Training Fold 6:   3%|▎         | 3/100 [00:02&lt;00:51,  1.89 epochs/s, Training Loss=8.33e-6, Validation Loss=8.25e-6, Best Loss=7.24e-6]
Training Fold 6:   4%|▍         | 4/100 [00:02&lt;00:50,  1.92 epochs/s, Training Loss=8.33e-6, Validation Loss=8.25e-6, Best Loss=7.24e-6]
Training Fold 6:   4%|▍         | 4/100 [00:02&lt;00:50,  1.92 epochs/s, Training Loss=5.96e-6, Validation Loss=7.35e-6, Best Loss=7.24e-6]
Training Fold 6:   5%|▌         | 5/100 [00:02&lt;00:50,  1.88 epochs/s, Training Loss=5.96e-6, Validation Loss=7.35e-6, Best Loss=7.24e-6]
Training Fold 6:   5%|▌         | 5/100 [00:03&lt;00:50,  1.88 epochs/s, Training Loss=1.17e-5, Validation Loss=1.33e-5, Best Loss=7.24e-6]
Training Fold 6:   6%|▌         | 6/100 [00:03&lt;00:50,  1.86 epochs/s, Training Loss=1.17e-5, Validation Loss=1.33e-5, Best Loss=7.24e-6]
Training Fold 6:   6%|▌         | 6/100 [00:03&lt;00:50,  1.86 epochs/s, Training Loss=6.22e-6, Validation Loss=7.69e-6, Best Loss=7.24e-6]
Training Fold 6:   7%|▋         | 7/100 [00:03&lt;00:51,  1.82 epochs/s, Training Loss=6.22e-6, Validation Loss=7.69e-6, Best Loss=7.24e-6]
Training Fold 6:   7%|▋         | 7/100 [00:04&lt;00:51,  1.82 epochs/s, Training Loss=8.88e-6, Validation Loss=1e-5, Best Loss=7.24e-6]
Training Fold 6:   8%|▊         | 8/100 [00:04&lt;00:49,  1.84 epochs/s, Training Loss=8.88e-6, Validation Loss=1e-5, Best Loss=7.24e-6]
Training Fold 6:   8%|▊         | 8/100 [00:04&lt;00:49,  1.84 epochs/s, Training Loss=1.09e-5, Validation Loss=1.2e-5, Best Loss=7.24e-6]
Training Fold 6:   9%|▉         | 9/100 [00:04&lt;00:51,  1.76 epochs/s, Training Loss=1.09e-5, Validation Loss=1.2e-5, Best Loss=7.24e-6]
Training Fold 6:   9%|▉         | 9/100 [00:05&lt;00:51,  1.76 epochs/s, Training Loss=6.38e-6, Validation Loss=8.21e-6, Best Loss=7.24e-6]
Training Fold 6:  10%|█         | 10/100 [00:05&lt;00:55,  1.62 epochs/s, Training Loss=6.38e-6, Validation Loss=8.21e-6, Best Loss=7.24e-6]
Training Fold 6:  10%|█         | 10/100 [00:06&lt;00:55,  1.62 epochs/s, Training Loss=6.74e-6, Validation Loss=8.2e-6, Best Loss=7.24e-6]
Training Fold 6:  11%|█         | 11/100 [00:06&lt;00:56,  1.56 epochs/s, Training Loss=6.74e-6, Validation Loss=8.2e-6, Best Loss=7.24e-6]
Training Fold 6:  11%|█         | 11/100 [00:06&lt;00:56,  1.56 epochs/s, Training Loss=6.64e-6, Validation Loss=8.74e-6, Best Loss=7.24e-6]
Training Fold 6:  12%|█▏        | 12/100 [00:06&lt;00:55,  1.59 epochs/s, Training Loss=6.64e-6, Validation Loss=8.74e-6, Best Loss=7.24e-6]
Training Fold 6:  12%|█▏        | 12/100 [00:07&lt;00:55,  1.59 epochs/s, Training Loss=6.53e-6, Validation Loss=8.71e-6, Best Loss=7.24e-6]
Training Fold 6:  13%|█▎        | 13/100 [00:07&lt;00:52,  1.66 epochs/s, Training Loss=6.53e-6, Validation Loss=8.71e-6, Best Loss=7.24e-6]
Training Fold 6:  13%|█▎        | 13/100 [00:08&lt;00:52,  1.66 epochs/s, Training Loss=6.6e-6, Validation Loss=8.31e-6, Best Loss=7.24e-6]
Training Fold 6:  14%|█▍        | 14/100 [00:08&lt;00:51,  1.68 epochs/s, Training Loss=6.6e-6, Validation Loss=8.31e-6, Best Loss=7.24e-6]
Training Fold 6:  14%|█▍        | 14/100 [00:08&lt;00:51,  1.68 epochs/s, Training Loss=8.25e-6, Validation Loss=9.19e-6, Best Loss=7.24e-6]
Training Fold 6:  15%|█▌        | 15/100 [00:08&lt;00:49,  1.73 epochs/s, Training Loss=8.25e-6, Validation Loss=9.19e-6, Best Loss=7.24e-6]
Training Fold 6:  15%|█▌        | 15/100 [00:09&lt;00:49,  1.73 epochs/s, Training Loss=6.87e-6, Validation Loss=8.75e-6, Best Loss=7.24e-6]
Training Fold 6:  16%|█▌        | 16/100 [00:09&lt;00:49,  1.71 epochs/s, Training Loss=6.87e-6, Validation Loss=8.75e-6, Best Loss=7.24e-6]
Training Fold 6:  16%|█▌        | 16/100 [00:09&lt;00:49,  1.71 epochs/s, Training Loss=7.41e-6, Validation Loss=9.36e-6, Best Loss=7.24e-6]
Training Fold 6:  17%|█▋        | 17/100 [00:09&lt;00:47,  1.75 epochs/s, Training Loss=7.41e-6, Validation Loss=9.36e-6, Best Loss=7.24e-6]
Training Fold 6:  17%|█▋        | 17/100 [00:10&lt;00:47,  1.75 epochs/s, Training Loss=5.91e-6, Validation Loss=7.76e-6, Best Loss=7.24e-6]
Training Fold 6:  18%|█▊        | 18/100 [00:10&lt;00:46,  1.76 epochs/s, Training Loss=5.91e-6, Validation Loss=7.76e-6, Best Loss=7.24e-6]
Training Fold 6:  18%|█▊        | 18/100 [00:10&lt;00:46,  1.76 epochs/s, Training Loss=9.79e-6, Validation Loss=9.44e-6, Best Loss=7.24e-6]
Training Fold 6:  19%|█▉        | 19/100 [00:10&lt;00:46,  1.75 epochs/s, Training Loss=9.79e-6, Validation Loss=9.44e-6, Best Loss=7.24e-6]
Training Fold 6:  19%|█▉        | 19/100 [00:11&lt;00:46,  1.75 epochs/s, Training Loss=6.6e-6, Validation Loss=8.47e-6, Best Loss=7.24e-6]
Training Fold 6:  20%|██        | 20/100 [00:11&lt;00:45,  1.77 epochs/s, Training Loss=6.6e-6, Validation Loss=8.47e-6, Best Loss=7.24e-6]
Training Fold 6:  20%|██        | 20/100 [00:11&lt;00:45,  1.77 epochs/s, Training Loss=6.5e-6, Validation Loss=8.64e-6, Best Loss=7.24e-6]
Training Fold 6:  21%|██        | 21/100 [00:11&lt;00:44,  1.79 epochs/s, Training Loss=6.5e-6, Validation Loss=8.64e-6, Best Loss=7.24e-6]
Training Fold 6:  21%|██        | 21/100 [00:12&lt;00:44,  1.79 epochs/s, Training Loss=5.78e-6, Validation Loss=8.06e-6, Best Loss=7.24e-6]
Training Fold 6:  22%|██▏       | 22/100 [00:12&lt;00:43,  1.78 epochs/s, Training Loss=5.78e-6, Validation Loss=8.06e-6, Best Loss=7.24e-6]
Training Fold 6:  22%|██▏       | 22/100 [00:13&lt;00:43,  1.78 epochs/s, Training Loss=5.87e-6, Validation Loss=8.04e-6, Best Loss=7.24e-6]
Training Fold 6:  23%|██▎       | 23/100 [00:13&lt;00:43,  1.76 epochs/s, Training Loss=5.87e-6, Validation Loss=8.04e-6, Best Loss=7.24e-6]
Training Fold 6:  23%|██▎       | 23/100 [00:13&lt;00:43,  1.76 epochs/s, Training Loss=9.16e-6, Validation Loss=1.12e-5, Best Loss=7.24e-6]
Training Fold 6:  24%|██▍       | 24/100 [00:13&lt;00:43,  1.75 epochs/s, Training Loss=9.16e-6, Validation Loss=1.12e-5, Best Loss=7.24e-6]
Training Fold 6:  24%|██▍       | 24/100 [00:14&lt;00:43,  1.75 epochs/s, Training Loss=5.84e-6, Validation Loss=7.96e-6, Best Loss=7.24e-6]
Training Fold 6:  25%|██▌       | 25/100 [00:14&lt;00:41,  1.80 epochs/s, Training Loss=5.84e-6, Validation Loss=7.96e-6, Best Loss=7.24e-6]
Training Fold 6:  25%|██▌       | 25/100 [00:14&lt;00:41,  1.80 epochs/s, Training Loss=6.36e-6, Validation Loss=8.4e-6, Best Loss=7.24e-6]
Training Fold 6:  26%|██▌       | 26/100 [00:14&lt;00:41,  1.78 epochs/s, Training Loss=6.36e-6, Validation Loss=8.4e-6, Best Loss=7.24e-6]
Training Fold 6:  26%|██▌       | 26/100 [00:15&lt;00:41,  1.78 epochs/s, Training Loss=6.32e-6, Validation Loss=7.95e-6, Best Loss=7.24e-6]
Training Fold 6:  27%|██▋       | 27/100 [00:15&lt;00:46,  1.57 epochs/s, Training Loss=6.32e-6, Validation Loss=7.95e-6, Best Loss=7.24e-6]
Training Fold 6:  27%|██▋       | 27/100 [00:16&lt;00:46,  1.57 epochs/s, Training Loss=2.04e-5, Validation Loss=2.2e-5, Best Loss=7.24e-6]
Training Fold 6:  28%|██▊       | 28/100 [00:16&lt;00:43,  1.64 epochs/s, Training Loss=2.04e-5, Validation Loss=2.2e-5, Best Loss=7.24e-6]
Training Fold 6:  28%|██▊       | 28/100 [00:16&lt;00:43,  1.64 epochs/s, Training Loss=1.12e-5, Validation Loss=1.34e-5, Best Loss=7.24e-6]
Training Fold 6:  29%|██▉       | 29/100 [00:16&lt;00:42,  1.67 epochs/s, Training Loss=1.12e-5, Validation Loss=1.34e-5, Best Loss=7.24e-6]
Training Fold 6:  29%|██▉       | 29/100 [00:17&lt;00:42,  1.67 epochs/s, Training Loss=7.75e-6, Validation Loss=9.71e-6, Best Loss=7.24e-6]
Training Fold 6:  30%|███       | 30/100 [00:17&lt;00:42,  1.66 epochs/s, Training Loss=7.75e-6, Validation Loss=9.71e-6, Best Loss=7.24e-6]
Training Fold 6:  30%|███       | 30/100 [00:17&lt;00:42,  1.66 epochs/s, Training Loss=6.85e-6, Validation Loss=9.16e-6, Best Loss=7.24e-6]
Training Fold 6:  31%|███       | 31/100 [00:17&lt;00:41,  1.66 epochs/s, Training Loss=6.85e-6, Validation Loss=9.16e-6, Best Loss=7.24e-6]
Training Fold 6:  31%|███       | 31/100 [00:18&lt;00:41,  1.66 epochs/s, Training Loss=8.39e-6, Validation Loss=9.66e-6, Best Loss=7.24e-6]
Training Fold 6:  32%|███▏      | 32/100 [00:18&lt;00:40,  1.67 epochs/s, Training Loss=8.39e-6, Validation Loss=9.66e-6, Best Loss=7.24e-6]
Training Fold 6:  32%|███▏      | 32/100 [00:19&lt;00:40,  1.67 epochs/s, Training Loss=6.42e-6, Validation Loss=8.27e-6, Best Loss=7.24e-6]
Training Fold 6:  33%|███▎      | 33/100 [00:19&lt;00:40,  1.66 epochs/s, Training Loss=6.42e-6, Validation Loss=8.27e-6, Best Loss=7.24e-6]
Training Fold 6:  33%|███▎      | 33/100 [00:19&lt;00:40,  1.66 epochs/s, Training Loss=6.17e-6, Validation Loss=8.64e-6, Best Loss=7.24e-6]
Training Fold 6:  34%|███▍      | 34/100 [00:19&lt;00:39,  1.67 epochs/s, Training Loss=6.17e-6, Validation Loss=8.64e-6, Best Loss=7.24e-6]
Training Fold 6:  34%|███▍      | 34/100 [00:20&lt;00:39,  1.67 epochs/s, Training Loss=5.89e-6, Validation Loss=8.32e-6, Best Loss=7.24e-6]
Training Fold 6:  35%|███▌      | 35/100 [00:20&lt;00:40,  1.61 epochs/s, Training Loss=5.89e-6, Validation Loss=8.32e-6, Best Loss=7.24e-6]
Training Fold 6:  35%|███▌      | 35/100 [00:21&lt;00:40,  1.61 epochs/s, Training Loss=7e-6, Validation Loss=1e-5, Best Loss=7.24e-6]
Training Fold 6:  36%|███▌      | 36/100 [00:21&lt;00:39,  1.62 epochs/s, Training Loss=7e-6, Validation Loss=1e-5, Best Loss=7.24e-6]
Training Fold 6:  36%|███▌      | 36/100 [00:21&lt;00:39,  1.62 epochs/s, Training Loss=6.83e-6, Validation Loss=9.06e-6, Best Loss=7.24e-6]
Training Fold 6:  37%|███▋      | 37/100 [00:21&lt;00:39,  1.59 epochs/s, Training Loss=6.83e-6, Validation Loss=9.06e-6, Best Loss=7.24e-6]
Training Fold 6:  37%|███▋      | 37/100 [00:22&lt;00:39,  1.59 epochs/s, Training Loss=6.22e-6, Validation Loss=8.91e-6, Best Loss=7.24e-6]
Training Fold 6:  38%|███▊      | 38/100 [00:22&lt;00:38,  1.63 epochs/s, Training Loss=6.22e-6, Validation Loss=8.91e-6, Best Loss=7.24e-6]
Training Fold 6:  38%|███▊      | 38/100 [00:22&lt;00:38,  1.63 epochs/s, Training Loss=9.55e-6, Validation Loss=1.16e-5, Best Loss=7.24e-6]
Training Fold 6:  39%|███▉      | 39/100 [00:22&lt;00:36,  1.66 epochs/s, Training Loss=9.55e-6, Validation Loss=1.16e-5, Best Loss=7.24e-6]
Training Fold 6:  39%|███▉      | 39/100 [00:23&lt;00:36,  1.66 epochs/s, Training Loss=6.11e-6, Validation Loss=8.45e-6, Best Loss=7.24e-6]
Training Fold 6:  40%|████      | 40/100 [00:23&lt;00:36,  1.66 epochs/s, Training Loss=6.11e-6, Validation Loss=8.45e-6, Best Loss=7.24e-6]
Training Fold 6:  40%|████      | 40/100 [00:24&lt;00:36,  1.66 epochs/s, Training Loss=5.59e-6, Validation Loss=8.36e-6, Best Loss=7.24e-6]
Training Fold 6:  41%|████      | 41/100 [00:24&lt;00:35,  1.65 epochs/s, Training Loss=5.59e-6, Validation Loss=8.36e-6, Best Loss=7.24e-6]
Training Fold 6:  41%|████      | 41/100 [00:24&lt;00:35,  1.65 epochs/s, Training Loss=9.16e-6, Validation Loss=1.08e-5, Best Loss=7.24e-6]
Training Fold 6:  42%|████▏     | 42/100 [00:24&lt;00:34,  1.67 epochs/s, Training Loss=9.16e-6, Validation Loss=1.08e-5, Best Loss=7.24e-6]
Training Fold 6:  42%|████▏     | 42/100 [00:25&lt;00:34,  1.67 epochs/s, Training Loss=7.59e-6, Validation Loss=9.53e-6, Best Loss=7.24e-6]
Training Fold 6:  43%|████▎     | 43/100 [00:25&lt;00:34,  1.66 epochs/s, Training Loss=7.59e-6, Validation Loss=9.53e-6, Best Loss=7.24e-6]
Training Fold 6:  43%|████▎     | 43/100 [00:25&lt;00:34,  1.66 epochs/s, Training Loss=6.32e-6, Validation Loss=8.95e-6, Best Loss=7.24e-6]
Training Fold 6:  44%|████▍     | 44/100 [00:25&lt;00:33,  1.66 epochs/s, Training Loss=6.32e-6, Validation Loss=8.95e-6, Best Loss=7.24e-6]
Training Fold 6:  44%|████▍     | 44/100 [00:26&lt;00:33,  1.66 epochs/s, Training Loss=7.02e-6, Validation Loss=9.85e-6, Best Loss=7.24e-6]
Training Fold 6:  45%|████▌     | 45/100 [00:26&lt;00:33,  1.64 epochs/s, Training Loss=7.02e-6, Validation Loss=9.85e-6, Best Loss=7.24e-6]
Training Fold 6:  45%|████▌     | 45/100 [00:27&lt;00:33,  1.64 epochs/s, Training Loss=7.31e-6, Validation Loss=8.6e-6, Best Loss=7.24e-6]
Training Fold 6:  46%|████▌     | 46/100 [00:27&lt;00:32,  1.66 epochs/s, Training Loss=7.31e-6, Validation Loss=8.6e-6, Best Loss=7.24e-6]
Training Fold 6:  46%|████▌     | 46/100 [00:27&lt;00:32,  1.66 epochs/s, Training Loss=6.83e-6, Validation Loss=1e-5, Best Loss=7.24e-6]
Training Fold 6:  47%|████▋     | 47/100 [00:27&lt;00:31,  1.68 epochs/s, Training Loss=6.83e-6, Validation Loss=1e-5, Best Loss=7.24e-6]
Training Fold 6:  47%|████▋     | 47/100 [00:28&lt;00:31,  1.68 epochs/s, Training Loss=7.19e-6, Validation Loss=1.02e-5, Best Loss=7.24e-6]
Training Fold 6:  48%|████▊     | 48/100 [00:28&lt;00:31,  1.67 epochs/s, Training Loss=7.19e-6, Validation Loss=1.02e-5, Best Loss=7.24e-6]
Training Fold 6:  48%|████▊     | 48/100 [00:28&lt;00:31,  1.67 epochs/s, Training Loss=5.49e-6, Validation Loss=8.1e-6, Best Loss=7.24e-6]
Training Fold 6:  49%|████▉     | 49/100 [00:28&lt;00:30,  1.70 epochs/s, Training Loss=5.49e-6, Validation Loss=8.1e-6, Best Loss=7.24e-6]
Training Fold 6:  49%|████▉     | 49/100 [00:29&lt;00:30,  1.70 epochs/s, Training Loss=5.83e-6, Validation Loss=8.25e-6, Best Loss=7.24e-6]
Training Fold 6:  50%|█████     | 50/100 [00:29&lt;00:29,  1.69 epochs/s, Training Loss=5.83e-6, Validation Loss=8.25e-6, Best Loss=7.24e-6]
Training Fold 6:  50%|█████     | 50/100 [00:29&lt;00:29,  1.69 epochs/s, Training Loss=6.45e-6, Validation Loss=9.22e-6, Best Loss=7.24e-6]
Training Fold 6:  51%|█████     | 51/100 [00:29&lt;00:28,  1.70 epochs/s, Training Loss=6.45e-6, Validation Loss=9.22e-6, Best Loss=7.24e-6]
Training Fold 6:  51%|█████     | 51/100 [00:30&lt;00:28,  1.70 epochs/s, Training Loss=6.07e-6, Validation Loss=9.15e-6, Best Loss=7.24e-6]
Training Fold 6:  52%|█████▏    | 52/100 [00:30&lt;00:28,  1.70 epochs/s, Training Loss=6.07e-6, Validation Loss=9.15e-6, Best Loss=7.24e-6]
Training Fold 6:  52%|█████▏    | 52/100 [00:31&lt;00:28,  1.70 epochs/s, Training Loss=5.95e-6, Validation Loss=8.98e-6, Best Loss=7.24e-6]
Training Fold 6:  53%|█████▎    | 53/100 [00:31&lt;00:28,  1.68 epochs/s, Training Loss=5.95e-6, Validation Loss=8.98e-6, Best Loss=7.24e-6]
Training Fold 6:  53%|█████▎    | 53/100 [00:31&lt;00:28,  1.68 epochs/s, Training Loss=6.58e-6, Validation Loss=8.67e-6, Best Loss=7.24e-6]
Training Fold 6:  54%|█████▍    | 54/100 [00:31&lt;00:27,  1.67 epochs/s, Training Loss=6.58e-6, Validation Loss=8.67e-6, Best Loss=7.24e-6]
Training Fold 6:  54%|█████▍    | 54/100 [00:32&lt;00:27,  1.67 epochs/s, Training Loss=5.99e-6, Validation Loss=8.7e-6, Best Loss=7.24e-6]
Training Fold 6:  55%|█████▌    | 55/100 [00:32&lt;00:27,  1.66 epochs/s, Training Loss=5.99e-6, Validation Loss=8.7e-6, Best Loss=7.24e-6]
Training Fold 6:  55%|█████▌    | 55/100 [00:32&lt;00:27,  1.66 epochs/s, Training Loss=1.51e-5, Validation Loss=1.6e-5, Best Loss=7.24e-6]
Training Fold 6:  56%|█████▌    | 56/100 [00:32&lt;00:26,  1.68 epochs/s, Training Loss=1.51e-5, Validation Loss=1.6e-5, Best Loss=7.24e-6]
Training Fold 6:  56%|█████▌    | 56/100 [00:33&lt;00:26,  1.68 epochs/s, Training Loss=7.95e-6, Validation Loss=1.07e-5, Best Loss=7.24e-6]
Training Fold 6:  57%|█████▋    | 57/100 [00:33&lt;00:25,  1.66 epochs/s, Training Loss=7.95e-6, Validation Loss=1.07e-5, Best Loss=7.24e-6]
Training Fold 6:  57%|█████▋    | 57/100 [00:34&lt;00:25,  1.66 epochs/s, Training Loss=6.11e-6, Validation Loss=9.2e-6, Best Loss=7.24e-6]
Training Fold 6:  58%|█████▊    | 58/100 [00:34&lt;00:25,  1.67 epochs/s, Training Loss=6.11e-6, Validation Loss=9.2e-6, Best Loss=7.24e-6]
Training Fold 6:  58%|█████▊    | 58/100 [00:34&lt;00:25,  1.67 epochs/s, Training Loss=5.5e-6, Validation Loss=8.35e-6, Best Loss=7.24e-6]
Training Fold 6:  59%|█████▉    | 59/100 [00:34&lt;00:24,  1.69 epochs/s, Training Loss=5.5e-6, Validation Loss=8.35e-6, Best Loss=7.24e-6]
Training Fold 6:  59%|█████▉    | 59/100 [00:35&lt;00:24,  1.69 epochs/s, Training Loss=6.04e-6, Validation Loss=8.52e-6, Best Loss=7.24e-6]
Training Fold 6:  60%|██████    | 60/100 [00:35&lt;00:23,  1.73 epochs/s, Training Loss=6.04e-6, Validation Loss=8.52e-6, Best Loss=7.24e-6]
Training Fold 6:  60%|██████    | 60/100 [00:35&lt;00:23,  1.73 epochs/s, Training Loss=7.49e-6, Validation Loss=1.03e-5, Best Loss=7.24e-6]
Training Fold 6:  61%|██████    | 61/100 [00:35&lt;00:23,  1.67 epochs/s, Training Loss=7.49e-6, Validation Loss=1.03e-5, Best Loss=7.24e-6]
Training Fold 6:  61%|██████    | 61/100 [00:36&lt;00:23,  1.67 epochs/s, Training Loss=5.35e-6, Validation Loss=8.32e-6, Best Loss=7.24e-6]
Training Fold 6:  62%|██████▏   | 62/100 [00:36&lt;00:22,  1.67 epochs/s, Training Loss=5.35e-6, Validation Loss=8.32e-6, Best Loss=7.24e-6]
Training Fold 6:  62%|██████▏   | 62/100 [00:37&lt;00:22,  1.67 epochs/s, Training Loss=9.31e-6, Validation Loss=1.34e-5, Best Loss=7.24e-6]
Training Fold 6:  63%|██████▎   | 63/100 [00:37&lt;00:21,  1.69 epochs/s, Training Loss=9.31e-6, Validation Loss=1.34e-5, Best Loss=7.24e-6]
Training Fold 6:  63%|██████▎   | 63/100 [00:37&lt;00:21,  1.69 epochs/s, Training Loss=7.28e-6, Validation Loss=1.03e-5, Best Loss=7.24e-6]
Training Fold 6:  64%|██████▍   | 64/100 [00:37&lt;00:20,  1.74 epochs/s, Training Loss=7.28e-6, Validation Loss=1.03e-5, Best Loss=7.24e-6]
Training Fold 6:  64%|██████▍   | 64/100 [00:38&lt;00:20,  1.74 epochs/s, Training Loss=7.08e-6, Validation Loss=9.78e-6, Best Loss=7.24e-6]
Training Fold 6:  65%|██████▌   | 65/100 [00:38&lt;00:20,  1.71 epochs/s, Training Loss=7.08e-6, Validation Loss=9.78e-6, Best Loss=7.24e-6]
Training Fold 6:  65%|██████▌   | 65/100 [00:38&lt;00:20,  1.71 epochs/s, Training Loss=6.47e-6, Validation Loss=8.84e-6, Best Loss=7.24e-6]
Training Fold 6:  66%|██████▌   | 66/100 [00:38&lt;00:20,  1.68 epochs/s, Training Loss=6.47e-6, Validation Loss=8.84e-6, Best Loss=7.24e-6]
Training Fold 6:  66%|██████▌   | 66/100 [00:39&lt;00:20,  1.68 epochs/s, Training Loss=5.48e-6, Validation Loss=8.75e-6, Best Loss=7.24e-6]
Training Fold 6:  67%|██████▋   | 67/100 [00:39&lt;00:19,  1.67 epochs/s, Training Loss=5.48e-6, Validation Loss=8.75e-6, Best Loss=7.24e-6]
Training Fold 6:  67%|██████▋   | 67/100 [00:40&lt;00:19,  1.67 epochs/s, Training Loss=5.81e-6, Validation Loss=9.34e-6, Best Loss=7.24e-6]
Training Fold 6:  68%|██████▊   | 68/100 [00:40&lt;00:19,  1.66 epochs/s, Training Loss=5.81e-6, Validation Loss=9.34e-6, Best Loss=7.24e-6]
Training Fold 6:  68%|██████▊   | 68/100 [00:40&lt;00:19,  1.66 epochs/s, Training Loss=5.64e-6, Validation Loss=8.8e-6, Best Loss=7.24e-6]
Training Fold 6:  69%|██████▉   | 69/100 [00:40&lt;00:18,  1.71 epochs/s, Training Loss=5.64e-6, Validation Loss=8.8e-6, Best Loss=7.24e-6]
Training Fold 6:  69%|██████▉   | 69/100 [00:41&lt;00:18,  1.71 epochs/s, Training Loss=5.61e-6, Validation Loss=8.77e-6, Best Loss=7.24e-6]
Training Fold 6:  70%|███████   | 70/100 [00:41&lt;00:17,  1.74 epochs/s, Training Loss=5.61e-6, Validation Loss=8.77e-6, Best Loss=7.24e-6]
Training Fold 6:  70%|███████   | 70/100 [00:41&lt;00:17,  1.74 epochs/s, Training Loss=5.59e-6, Validation Loss=8.73e-6, Best Loss=7.24e-6]
Training Fold 6:  71%|███████   | 71/100 [00:41&lt;00:16,  1.73 epochs/s, Training Loss=5.59e-6, Validation Loss=8.73e-6, Best Loss=7.24e-6]
Training Fold 6:  71%|███████   | 71/100 [00:42&lt;00:16,  1.73 epochs/s, Training Loss=5.2e-6, Validation Loss=8.27e-6, Best Loss=7.24e-6]
Training Fold 6:  72%|███████▏  | 72/100 [00:42&lt;00:15,  1.77 epochs/s, Training Loss=5.2e-6, Validation Loss=8.27e-6, Best Loss=7.24e-6]
Training Fold 6:  72%|███████▏  | 72/100 [00:42&lt;00:15,  1.77 epochs/s, Training Loss=4.96e-6, Validation Loss=8.29e-6, Best Loss=7.24e-6]
Training Fold 6:  73%|███████▎  | 73/100 [00:42&lt;00:15,  1.75 epochs/s, Training Loss=4.96e-6, Validation Loss=8.29e-6, Best Loss=7.24e-6]
Training Fold 6:  73%|███████▎  | 73/100 [00:43&lt;00:15,  1.75 epochs/s, Training Loss=8.42e-6, Validation Loss=1.1e-5, Best Loss=7.24e-6]
Training Fold 6:  74%|███████▍  | 74/100 [00:43&lt;00:15,  1.68 epochs/s, Training Loss=8.42e-6, Validation Loss=1.1e-5, Best Loss=7.24e-6]
Training Fold 6:  74%|███████▍  | 74/100 [00:44&lt;00:15,  1.68 epochs/s, Training Loss=7.01e-6, Validation Loss=8.77e-6, Best Loss=7.24e-6]
Training Fold 6:  75%|███████▌  | 75/100 [00:44&lt;00:14,  1.71 epochs/s, Training Loss=7.01e-6, Validation Loss=8.77e-6, Best Loss=7.24e-6]
Training Fold 6:  75%|███████▌  | 75/100 [00:44&lt;00:14,  1.71 epochs/s, Training Loss=7.68e-6, Validation Loss=1.05e-5, Best Loss=7.24e-6]
Training Fold 6:  76%|███████▌  | 76/100 [00:44&lt;00:14,  1.70 epochs/s, Training Loss=7.68e-6, Validation Loss=1.05e-5, Best Loss=7.24e-6]
Training Fold 6:  76%|███████▌  | 76/100 [00:45&lt;00:14,  1.70 epochs/s, Training Loss=5.92e-6, Validation Loss=8.56e-6, Best Loss=7.24e-6]
Training Fold 6:  77%|███████▋  | 77/100 [00:45&lt;00:13,  1.67 epochs/s, Training Loss=5.92e-6, Validation Loss=8.56e-6, Best Loss=7.24e-6]
Training Fold 6:  77%|███████▋  | 77/100 [00:45&lt;00:13,  1.67 epochs/s, Training Loss=6.28e-6, Validation Loss=8.92e-6, Best Loss=7.24e-6]
Training Fold 6:  78%|███████▊  | 78/100 [00:45&lt;00:13,  1.69 epochs/s, Training Loss=6.28e-6, Validation Loss=8.92e-6, Best Loss=7.24e-6]
Training Fold 6:  78%|███████▊  | 78/100 [00:46&lt;00:13,  1.69 epochs/s, Training Loss=8.65e-6, Validation Loss=1.2e-5, Best Loss=7.24e-6]
Training Fold 6:  79%|███████▉  | 79/100 [00:46&lt;00:12,  1.71 epochs/s, Training Loss=8.65e-6, Validation Loss=1.2e-5, Best Loss=7.24e-6]
Training Fold 6:  79%|███████▉  | 79/100 [00:47&lt;00:12,  1.71 epochs/s, Training Loss=5.45e-6, Validation Loss=8.73e-6, Best Loss=7.24e-6]
Training Fold 6:  80%|████████  | 80/100 [00:47&lt;00:11,  1.72 epochs/s, Training Loss=5.45e-6, Validation Loss=8.73e-6, Best Loss=7.24e-6]
Training Fold 6:  80%|████████  | 80/100 [00:47&lt;00:11,  1.72 epochs/s, Training Loss=5.68e-6, Validation Loss=8.52e-6, Best Loss=7.24e-6]
Training Fold 6:  81%|████████  | 81/100 [00:47&lt;00:11,  1.70 epochs/s, Training Loss=5.68e-6, Validation Loss=8.52e-6, Best Loss=7.24e-6]
Training Fold 6:  81%|████████  | 81/100 [00:48&lt;00:11,  1.70 epochs/s, Training Loss=6.17e-6, Validation Loss=9.13e-6, Best Loss=7.24e-6]
Training Fold 6:  82%|████████▏ | 82/100 [00:48&lt;00:10,  1.73 epochs/s, Training Loss=6.17e-6, Validation Loss=9.13e-6, Best Loss=7.24e-6]
Training Fold 6:  82%|████████▏ | 82/100 [00:48&lt;00:10,  1.73 epochs/s, Training Loss=5.91e-6, Validation Loss=9.42e-6, Best Loss=7.24e-6]
Training Fold 6:  83%|████████▎ | 83/100 [00:48&lt;00:09,  1.75 epochs/s, Training Loss=5.91e-6, Validation Loss=9.42e-6, Best Loss=7.24e-6]
Training Fold 6:  83%|████████▎ | 83/100 [00:49&lt;00:09,  1.75 epochs/s, Training Loss=1.51e-5, Validation Loss=1.81e-5, Best Loss=7.24e-6]
Training Fold 6:  84%|████████▍ | 84/100 [00:49&lt;00:09,  1.77 epochs/s, Training Loss=1.51e-5, Validation Loss=1.81e-5, Best Loss=7.24e-6]
Training Fold 6:  84%|████████▍ | 84/100 [00:49&lt;00:09,  1.77 epochs/s, Training Loss=1.24e-5, Validation Loss=1.62e-5, Best Loss=7.24e-6]
Training Fold 6:  85%|████████▌ | 85/100 [00:49&lt;00:08,  1.79 epochs/s, Training Loss=1.24e-5, Validation Loss=1.62e-5, Best Loss=7.24e-6]
Training Fold 6:  85%|████████▌ | 85/100 [00:50&lt;00:08,  1.79 epochs/s, Training Loss=9.95e-6, Validation Loss=1.28e-5, Best Loss=7.24e-6]
Training Fold 6:  86%|████████▌ | 86/100 [00:50&lt;00:07,  1.79 epochs/s, Training Loss=9.95e-6, Validation Loss=1.28e-5, Best Loss=7.24e-6]
Training Fold 6:  86%|████████▌ | 86/100 [00:50&lt;00:07,  1.79 epochs/s, Training Loss=4.82e-6, Validation Loss=8.35e-6, Best Loss=7.24e-6]
Training Fold 6:  87%|████████▋ | 87/100 [00:50&lt;00:07,  1.81 epochs/s, Training Loss=4.82e-6, Validation Loss=8.35e-6, Best Loss=7.24e-6]
Training Fold 6:  87%|████████▋ | 87/100 [00:51&lt;00:07,  1.81 epochs/s, Training Loss=5.2e-6, Validation Loss=8.57e-6, Best Loss=7.24e-6]
Training Fold 6:  88%|████████▊ | 88/100 [00:51&lt;00:06,  1.82 epochs/s, Training Loss=5.2e-6, Validation Loss=8.57e-6, Best Loss=7.24e-6]
Training Fold 6:  88%|████████▊ | 88/100 [00:52&lt;00:06,  1.82 epochs/s, Training Loss=5.45e-6, Validation Loss=8.97e-6, Best Loss=7.24e-6]
Training Fold 6:  89%|████████▉ | 89/100 [00:52&lt;00:06,  1.83 epochs/s, Training Loss=5.45e-6, Validation Loss=8.97e-6, Best Loss=7.24e-6]
Training Fold 6:  89%|████████▉ | 89/100 [00:52&lt;00:06,  1.83 epochs/s, Training Loss=5.18e-6, Validation Loss=8.46e-6, Best Loss=7.24e-6]
Training Fold 6:  90%|█████████ | 90/100 [00:52&lt;00:05,  1.84 epochs/s, Training Loss=5.18e-6, Validation Loss=8.46e-6, Best Loss=7.24e-6]
Training Fold 6:  90%|█████████ | 90/100 [00:53&lt;00:05,  1.84 epochs/s, Training Loss=7.63e-6, Validation Loss=1.07e-5, Best Loss=7.24e-6]
Training Fold 6:  91%|█████████ | 91/100 [00:53&lt;00:04,  1.87 epochs/s, Training Loss=7.63e-6, Validation Loss=1.07e-5, Best Loss=7.24e-6]
Training Fold 6:  91%|█████████ | 91/100 [00:53&lt;00:04,  1.87 epochs/s, Training Loss=4.97e-6, Validation Loss=8.58e-6, Best Loss=7.24e-6]
Training Fold 6:  92%|█████████▏| 92/100 [00:53&lt;00:04,  1.87 epochs/s, Training Loss=4.97e-6, Validation Loss=8.58e-6, Best Loss=7.24e-6]
Training Fold 6:  92%|█████████▏| 92/100 [00:54&lt;00:04,  1.87 epochs/s, Training Loss=5.7e-6, Validation Loss=8.81e-6, Best Loss=7.24e-6]
Training Fold 6:  93%|█████████▎| 93/100 [00:54&lt;00:03,  1.88 epochs/s, Training Loss=5.7e-6, Validation Loss=8.81e-6, Best Loss=7.24e-6]
Training Fold 6:  93%|█████████▎| 93/100 [00:54&lt;00:03,  1.88 epochs/s, Training Loss=5.98e-6, Validation Loss=9.87e-6, Best Loss=7.24e-6]
Training Fold 6:  94%|█████████▍| 94/100 [00:54&lt;00:03,  1.88 epochs/s, Training Loss=5.98e-6, Validation Loss=9.87e-6, Best Loss=7.24e-6]
Training Fold 6:  94%|█████████▍| 94/100 [00:55&lt;00:03,  1.88 epochs/s, Training Loss=5.64e-6, Validation Loss=9.24e-6, Best Loss=7.24e-6]
Training Fold 6:  95%|█████████▌| 95/100 [00:55&lt;00:02,  1.87 epochs/s, Training Loss=5.64e-6, Validation Loss=9.24e-6, Best Loss=7.24e-6]
Training Fold 6:  95%|█████████▌| 95/100 [00:55&lt;00:02,  1.87 epochs/s, Training Loss=4.85e-6, Validation Loss=8.51e-6, Best Loss=7.24e-6]
Training Fold 6:  96%|█████████▌| 96/100 [00:55&lt;00:02,  1.87 epochs/s, Training Loss=4.85e-6, Validation Loss=8.51e-6, Best Loss=7.24e-6]
Training Fold 6:  96%|█████████▌| 96/100 [00:56&lt;00:02,  1.87 epochs/s, Training Loss=5.45e-6, Validation Loss=9.09e-6, Best Loss=7.24e-6]
Training Fold 6:  97%|█████████▋| 97/100 [00:56&lt;00:01,  1.86 epochs/s, Training Loss=5.45e-6, Validation Loss=9.09e-6, Best Loss=7.24e-6]
Training Fold 6:  97%|█████████▋| 97/100 [00:56&lt;00:01,  1.86 epochs/s, Training Loss=7.33e-6, Validation Loss=9.23e-6, Best Loss=7.24e-6]
Training Fold 6:  98%|█████████▊| 98/100 [00:56&lt;00:01,  1.83 epochs/s, Training Loss=7.33e-6, Validation Loss=9.23e-6, Best Loss=7.24e-6]
Training Fold 6:  98%|█████████▊| 98/100 [00:57&lt;00:01,  1.83 epochs/s, Training Loss=5e-6, Validation Loss=8.67e-6, Best Loss=7.24e-6]
Training Fold 6:  99%|█████████▉| 99/100 [00:57&lt;00:00,  1.88 epochs/s, Training Loss=5e-6, Validation Loss=8.67e-6, Best Loss=7.24e-6]
Training Fold 6:  99%|█████████▉| 99/100 [00:57&lt;00:00,  1.88 epochs/s, Training Loss=8.74e-6, Validation Loss=1.08e-5, Best Loss=7.24e-6]
Training Fold 6: 100%|██████████| 100/100 [00:57&lt;00:00,  1.92 epochs/s, Training Loss=8.74e-6, Validation Loss=1.08e-5, Best Loss=7.24e-6]
Training Fold 6: 100%|██████████| 100/100 [00:57&lt;00:00,  1.73 epochs/s, Training Loss=8.74e-6, Validation Loss=1.08e-5, Best Loss=7.24e-6]

&lt;All keys matched successfully&gt;
</pre></div>
</div>
</section>
<section id="step-5-compare-the-predictions">
<h2>Step 5: Compare the predictions<a class="headerlink" href="#step-5-compare-the-predictions" title="Link to this heading">¶</a></h2>
<p>To ensure reproducibility, we have included the best performing model from our study.</p>
<p>Load the pre-trained model</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">base_path</span><span class="si">}</span><span class="s2">/KSL_MultiFold_SixFold.pth&quot;</span><span class="p">))</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>&lt;All keys matched successfully&gt;
</pre></div>
</div>
<p>Check the predictions</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">input_swir</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">fin_swir</span><span class="p">)</span>
<span class="n">input_mwir</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">fin_mwir</span><span class="p">)</span>
<span class="n">input_lwir</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">fin_lwir</span><span class="p">)</span>

<span class="c1"># Ensure the model is in evaluation mode</span>
<span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

<span class="c1"># Run the forward pass - no need to track gradients here</span>
<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="n">predictions</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_swir</span><span class="p">,</span> <span class="n">input_mwir</span><span class="p">,</span> <span class="n">input_lwir</span><span class="p">)</span>

<span class="c1"># Inverse scaler</span>
<span class="n">meas_</span> <span class="o">=</span> <span class="n">fin_y</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">1e3</span><span class="p">,</span> <span class="mf">1e1</span><span class="p">,</span> <span class="mf">1e3</span><span class="p">])[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:]</span>
<span class="n">pred_</span> <span class="o">=</span> <span class="n">predictions</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">1e3</span><span class="p">,</span> <span class="mf">1e1</span><span class="p">,</span> <span class="mf">1e3</span><span class="p">])[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:]</span>
</pre></div>
</div>
<p>Plot scatter</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">lowlims</span> <span class="o">=</span> <span class="p">[</span><span class="mi">130</span><span class="p">,</span> <span class="mf">1.75</span><span class="p">,</span> <span class="o">-</span><span class="mi">10</span><span class="p">]</span>
<span class="n">highlims</span> <span class="o">=</span> <span class="p">[</span><span class="mi">320</span><span class="p">,</span> <span class="mf">3.4</span><span class="p">,</span> <span class="mi">200</span><span class="p">]</span>
<span class="n">titles</span> <span class="o">=</span> <span class="p">[</span><span class="sa">r</span><span class="s2">&quot;Slowness&quot;</span><span class="p">,</span> <span class="sa">r</span><span class="s2">&quot;Density&quot;</span><span class="p">,</span> <span class="sa">r</span><span class="s2">&quot;Gamma-Ray&quot;</span><span class="p">]</span>
<span class="n">units</span> <span class="o">=</span> <span class="p">[</span><span class="sa">r</span><span class="s2">&quot;$\ \mu \mathrm{s.m^{-1}}$&quot;</span><span class="p">,</span> <span class="sa">r</span><span class="s2">&quot;$\ \mathrm{g.cm^{-3}}$&quot;</span><span class="p">,</span> <span class="s2">&quot;$\ \mathrm</span><span class="si">{API}</span><span class="s2">$&quot;</span><span class="p">]</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplot_mosaic</span><span class="p">([[</span><span class="s1">&#39;A)&#39;</span><span class="p">,</span> <span class="s1">&#39;B)&#39;</span><span class="p">,</span> <span class="s1">&#39;C)&#39;</span><span class="p">]],</span> <span class="n">layout</span><span class="o">=</span><span class="s1">&#39;constrained&#39;</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mf">2.2</span><span class="p">))</span>
<span class="n">props</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">boxstyle</span><span class="o">=</span><span class="s1">&#39;round&#39;</span><span class="p">,</span> <span class="n">facecolor</span><span class="o">=</span><span class="s1">&#39;lightblue&#39;</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s2">&quot;lightblue&quot;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>

<span class="c1"># Original Data</span>
<span class="n">label</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">axs</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
<span class="n">cax</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">axs</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">pred_</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
    <span class="n">meas</span> <span class="o">=</span> <span class="n">meas_</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span>
    <span class="n">pred</span> <span class="o">=</span> <span class="n">pred_</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span>
    <span class="n">ax</span> <span class="o">=</span> <span class="n">cax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>

    <span class="c1"># Compute Metric</span>
    <span class="n">metric</span> <span class="o">=</span> <span class="n">MeanSquaredError</span><span class="p">()</span>
    <span class="n">metricr2</span> <span class="o">=</span> <span class="n">R2Score</span><span class="p">()</span>
    <span class="n">metric</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">meas</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">pred</span><span class="p">))</span>
    <span class="n">metricr2</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">meas</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">pred</span><span class="p">))</span>
    <span class="n">rmse</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
    <span class="n">r2</span> <span class="o">=</span> <span class="n">metricr2</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

    <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">meas</span><span class="p">,</span> <span class="n">pred</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">label</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">loc</span><span class="o">=</span><span class="s1">&#39;left&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="s1">&#39;medium&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">titles</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>

    <span class="n">textstr</span> <span class="o">=</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">((</span>
    <span class="sa">r</span><span class="s1">&#39;$R^2=</span><span class="si">%.3f</span><span class="s1">$&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">r2</span><span class="p">,</span> <span class="p">),</span>
    <span class="sa">r</span><span class="s1">&#39;$RMSE=</span><span class="si">%.3f</span><span class="s1">$&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">rmse</span><span class="p">,</span> <span class="p">),</span>
    <span class="p">))</span>

    <span class="c1"># place a text box in upper left in axes coords</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.95</span><span class="p">,</span> <span class="n">textstr</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">ax</span><span class="o">.</span><span class="n">transAxes</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span>
            <span class="n">verticalalignment</span><span class="o">=</span><span class="s1">&#39;top&#39;</span><span class="p">,</span> <span class="n">bbox</span><span class="o">=</span><span class="n">props</span><span class="p">)</span>

    <span class="n">ax</span><span class="o">.</span><span class="n">axline</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">slope</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s2">&quot;r&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">([</span><span class="n">lowlims</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">highlims</span><span class="p">[</span><span class="n">i</span><span class="p">]])</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="n">lowlims</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">highlims</span><span class="p">[</span><span class="n">i</span><span class="p">]])</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Measured&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Predicted&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_aspect</span><span class="p">(</span><span class="s2">&quot;equal&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># sphinx_gallery_thumbnail_number = -1</span>
</pre></div>
</div>
<img src="../../_images/sphx_glr_04_VectorGeology_HyTorch_003.png" srcset="../../_images/sphx_glr_04_VectorGeology_HyTorch_003.png" alt="A), Slowness, B), Density, C), Gamma-Ray" class = "sphx-glr-single-img"/><p class="sphx-glr-timing"><strong>Total running time of the script:</strong> (5 minutes 15.254 seconds)</p>
<div class="sphx-glr-footer sphx-glr-footer-example docutils container" id="sphx-glr-download-examples-03-forward-engines-04-vectorgeology-hytorch-py">
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/ef2e6ff4683160fc5b8900c27d12283b/04_VectorGeology_HyTorch.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">04_VectorGeology_HyTorch.ipynb</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/cecedf3c99859d9c1481e435e63c7a4f/04_VectorGeology_HyTorch.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">04_VectorGeology_HyTorch.py</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</section>
</section>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
            <p class="logo"><a href="../../index.html">
              <img class="logo" src="../../_static/vector-logo.png" alt="Logo"/>
            </a></p>
<h1 class="logo"><a href="../../index.html">Vector Geology</a></h1>








<h3>Navigation</h3>
<p class="caption" role="heading"><span class="caption-text">Galleries</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../index.html">Vector Geology Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../external/external_examples.html">Bayesian Inference Theory</a></li>
</ul>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../01_readers/index.html">Readers and Parsers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_structural_modeling/index.html">Structural Modeling</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">GeoPhysics and Inversion</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="01_gravity_gradiometry_inversion_pgi.html">Inversion of Full Tensor Gravity Gradiometry Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="02_model_1_gempy_fw_gravity.html">Model 1 Forward Gravity</a></li>
<li class="toctree-l2"><a class="reference internal" href="03_HSI_To_Petrophysics.html">Predicting P-Wave Velocity from Hyperspectral Data</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Multiphysics property prediction from hyperspectral drill core data</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#step-1-filtering">Step 1: Filtering</a></li>
<li class="toctree-l3"><a class="reference internal" href="#step-2-extract-the-hyperspectral-data">Step 2: Extract the hyperspectral data</a></li>
<li class="toctree-l3"><a class="reference internal" href="#step-3-define-a-shuffled-train-validation-split">Step 3: Define a shuffled Train + Validation split</a></li>
<li class="toctree-l3"><a class="reference internal" href="#step-4-define-a-pytorch-model">Step 4: Define a <cite>pytorch</cite> model</a></li>
<li class="toctree-l3"><a class="reference internal" href="#training">Training</a></li>
<li class="toctree-l3"><a class="reference internal" href="#step-5-compare-the-predictions">Step 5: Compare the predictions</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../04_probabilistic_modeling/index.html">Probabilistic Modeling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../05_petrophysics/index.html">Petrophysical Data Integration and Modeling</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">User Guide</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../contributing.html">Contributing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../maintenance.html">Maintenance</a></li>
</ul>


<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>document.getElementById('searchbox').style.display = "block"</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2023-2024, Vector Geology Team.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 7.2.6</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.13</a>
      
      |
      <a href="../../_sources/examples/03_forward_engines/04_VectorGeology_HyTorch.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>